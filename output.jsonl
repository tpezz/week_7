{"url":"https://en.wikipedia.org/wiki/DeepSeek","title":"DeepSeek","content":"\n\n\n\nHangzhou DeepSeek Artificial Intelligence Co., Ltd.,[2][a] doing business as DeepSeek,[b] is a Chinese artificial intelligence company that develops large language models (LLMs). Based in Hangzhou, Zhejiang, it is owned and funded by the Chinese hedge fund High-Flyer. DeepSeek was founded in July 2023 by High-Flyer co-founder Liang Wenfeng, who also serves as the CEO for both companies. The company launched an eponymous chatbot alongside its DeepSeek-R1 model in January 2025.\n\nReleased under the MIT License, DeepSeek-R1 provides responses comparable to other contemporary large language models, such as OpenAI's GPT-4o and o1.[4] Its training cost is reported to be significantly lower than other LLMs. The company claims that it trained its V3 model for US$6 million compared to $100 million for OpenAI's GPT-4 in 2023,[5] and approximately one-tenth of the computing power used for Meta's comparable model, Llama 3.1.[5][6][7][8] DeepSeek's success against larger and more established rivals has been described as \"upending AI\".[9][10]\n\nDeepSeek's models are \"open weight\", which provides less freedom for modification than true open-source software.[11][12] The company reportedly recruits AI researchers from top Chinese universities[9] and hires from outside the computer science field to diversify its models' knowledge and abilities.[6]\n\nThe low cost of training and running the language model was attributed to Chinese firms' lack of access to Nvidia chipsets, which were restricted by the US as part of the ongoing trade war between the two countries. This breakthrough in reducing expenses while increasing efficiency and maintaining the model's performance in the AI industry sent \"shockwaves\" through the market. It threatened the dominance of AI leaders like Nvidia and contributed to the largest drop in US stock market history, with Nvidia alone losing $600 billion in market value.[13][14]\n\nIn February 2016, High-Flyer was co-founded by AI enthusiast Liang Wenfeng, who had been trading since the 2007–2008 financial crisis while attending Zhejiang University.[15]\n\nThe company began stock-trading using a GPU-dependent deep learning model on October 21, 2016. Prior to this, they used CPU-based models, mainly linear models. Most trading was driven by AI by the end of 2017.[16]\n\nIn 2019, Liang established High-Flyer as a hedge fund focused on developing and using AI trading algorithms. By 2021, High-Flyer exclusively used AI in trading,[17] often using Nvidia chips.[18]\n\nInitial computing cluster Fire-Flyer began construction in 2019 and finished in 2020, at a cost of 200 million yuan. It contained 1,100 GPUs interconnected at a rate of 200 Gbps. It was 'retired' after 1.5 years in operation.\n\nIn 2021, Liang began stockpiling Nvidia GPUs for an AI project.[18] According to 36Kr, Liang acquired 10,000 Nvidia A100 GPUs[19] before the United States restricted chip sales to China.[17] Computing cluster Fire-Flyer 2 began construction in 2021 with a budget of 1 billion yuan.[16]\n\nIt was reported that in 2022, Fire-Flyer 2's capacity had been used at over 96%, totaling 56.74 million GPU hours. 27% was used to support scientific computing outside the company.[16]\n\nDuring 2022, Fire-Flyer 2 had 5000 PCIe A100 GPUs in 625 nodes, each containing 8 GPUs. At the time, they exclusively used PCIe instead of the DGX version of A100, since at the time the models they trained could fit within a single 40 GB GPU VRAM, so there was no need for the higher bandwidth of DGX (i.e. they required only data parallelism but not model parallelism).[20] Later, they incorporated NVLinks and NCCL, to train larger models that required model parallelism.[21][22]\n\nOn 14 April 2023,[23] High-Flyer announced the start of an artificial general intelligence lab dedicated to research developing AI tools separate from High-Flyer's financial business.[24][25] Incorporated on 17 July 2023,[1] with High-Flyer as the investor and backer, the lab became its own company, DeepSeek.[17][26][25] Venture capital firms were reluctant to provide funding, as they considered it unlikely that the venture would be able to quickly generate an \"exit\".[17]\n\nOn 16 May 2023, the company Beijing DeepSeek Artificial Intelligence Basic Technology Research Company, Limited. was incorporated. It was later taken under 100% control of Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd, which was incorporated 2 months after.\n\nOn 2 November 2023, DeepSeek released its first model, DeepSeek Coder. On 29 November 2023, DeepSeek released the DeepSeek-LLM series of models.[27]: section 5  On 9 January 2024, they released 2 DeepSeek-MoE models (Base and Chat).[28] In April 2024, they released 3 DeepSeek-Math models: Base, Instruct, and RL.[29]\n\nDeepSeek-V2 was released in May 2024. In June 2024, the DeepSeek-Coder V2 series was released.[30]\n\nDeepSeek V2.5 was released in September and updated in December 2024.[31] On 20 November 2024, DeepSeek-R1-Lite-Preview became accessible via API and chat.[32][33] In December 2024, the company released the base model DeepSeek-V3-Base and the chat model DeepSeek-V3.[21]\n\nOn 20 January 2025, DeepSeek released the DeepSeek chatbot, based on the DeepSeek-R1 model, free of charge for iOS and Android; by 27 January, DeepSeek had surpassed ChatGPT as the most downloaded freeware app on the iOS App Store in the United States,[9] causing Nvidia's share price to drop by 18%.[34][35]\n\nBased in Hangzhou, Zhejiang, DeepSeek is owned and funded by the Chinese hedge fund High-Flyer co-founder Liang Wenfeng, who also serves as its CEO.\n\nAs of May 2024, Liang owned 84% of DeepSeek through two shell corporations.[note 1][36]\n\nDeepSeek is focused on research and has not detailed plans for commercialization.[37]\n\nThis allows its technology to avoid the most stringent provisions of China's AI regulations, such as requiring consumer-facing technology to comply with government controls on information.[6]\n\nDeepSeek's hiring preferences target technical abilities rather than work experience; most new hires are either recent university graduates or developers whose AI careers are less established.[25][6]\n\nLikewise, the company recruits individuals without any computer science background to help its technology understand more knowledge areas,[9] such as poetry and China's notoriously difficult college admissions exams (Gaokao).[6]\n\nHigh-Flyer/DeepSeek operates at least two computing clusters, Fire-Flyer (萤火一号) and Fire-Flyer 2 (萤火二号). Fire-Flyer 2 consists of co-designed software and hardware architecture. On the hardware side, Nvidia GPUs use 200 Gbps interconnects. The cluster is divided into two \"zones\", and the platform supports cross-zone tasks. The network topology was two fat trees, chosen for high bisection bandwidth. On the software side are:[22][16]\n\nAs of 2022, Fire-Flyer 2 had 5000 PCIe A100 GPUs in 625 nodes, each containing 8 GPUs.[20] They later incorporated NVLinks and NCCL, to train larger models that required model parallelism.[21][22]\n\nChat (with SFT)\n\nChat\n\nDeepSeek-V2-Lite, DeepSeek-V2-Lite-Chat\n\nDeepSeek-Coder-V2\n\nDeepSeek-V2.5\n\nDeepSeek-V3 (a chat model)\n\nDeepSeek-R1-Zero\n\nThe first DeepSeek models were essentially the same as Llama,[27] which were dense decoder-only Transformers. Later models incorporated Mixture of Experts, and then multi-head latent attention.[28][30]\n\nA decoder-only Transformer consists of multiple identical decoder layers. Each of these layers features two main components: an attention layer and a FeedForward network (FFN) layer.[30] In the attention layer, the traditional multi-head attention mechanism has been enhanced with multi-head latent attention. This update introduces compressed latent vectors to boost performance and reduce memory usage during inference.\n\nMeanwhile, the FFN layer adopts a variant of the mixture of experts (MoE) approach, effectively doubling the number of experts compared to standard implementations. It distinguishes between two types of experts: shared experts, which are always active to encapsulate general knowledge, and routed experts, where only a select few are activated to capture specialized information.\n\nDeepSeek's models are \"open weight\", which provides less freedom for modification than true open source software.[41][42]\n\nDeepSeek Coder is a series of 8 models, 4 pretrained (Base) and 4 instruction-finetuned (Instruct). They all have 16K context lengths. The model was made source-available under the DeepSeek License, which includes \"open and responsible downstream usage\" restrictions.[43]\n\nThe training program was:[44][45][46]\n\nThey were trained on clusters of A100 and H800 Nvidia GPUs, connected by InfiniBand, NVLink, NVSwitch.[44]\n\nThe DeepSeek-LLM series was released in November 2023. It has 7B and 67B parameters in both Base and Chat forms. DeepSeek's accompanying paper claimed benchmark results higher than Llama 2 and most open-source LLMs at the time.[27]: section 5  The model code is under the source-available DeepSeek License.[48]\n\nThe architecture was essentially the same as the Llama series. They used the pre-norm decoder-only Transformer with RMSNorm as the normalization, SwiGLU in the feedforward layers, rotary positional embedding (RoPE), and grouped-query attention (GQA). Both had vocabulary size 102,400 (byte-level BPE) and context length of 4096. They trained on 2 trillion tokens of English and Chinese text obtained by deduplicating the Common Crawl.[27]\n\nThe Chat versions of the two Base models was released concurrently, obtained by training Base by supervised finetuning (SFT) followed by direct policy optimization (DPO).[27]\n\nDeepSeek-MoE models (Base and Chat), each have 16B parameters (2.7B activated per token, 4K context length). The training was essentially the same as DeepSeek-LLM 7B, and was trained on a part of its training dataset. They claimed performance comparable to a 16B MoE as a 7B non-MoE. It is a variant of the standard sparsely-gated MoE, with \"shared experts\" that are always queried, and \"routed experts\" that might not be. They found this to help with expert balancing. In standard MoE, some experts can become overused, while others are rarely used, wasting space. Attempting to balance expert usage causes experts to replicate the same capacity. They proposed the shared experts to learn core capacities that are often used, and let the routed experts learn peripheral capacities that are rarely used.[28]\n\nDeepSeek-Math includes 3 models: Base, Instruct, and RL. Math was trained as follows:[29]\n\nIn May 2024, DeepSeek released the DeepSeek-V2 series. The series includes 4 models, 2 base models (DeepSeek-V2, DeepSeek-V2 Lite) and 2 chatbots (Chat). The two larger models were trained as follows:[50]\n\nThey opted for 2-staged RL, because they found that RL on reasoning data had \"unique characteristics\" different from RL on general data. For example, RL on reasoning could improve over more training steps.[50]\n\nThe two V2-Lite models were smaller, and trained similarly. DeepSeek-V2 Lite-Chat underwent only SFT, not RL. They trained the Lite version to help \"further research and development on MLA and DeepSeekMoE\".[50]\n\nArchitecturally, the V2 models were significantly different from the DeepSeek LLM series. They changed the standard attention mechanism by a low-rank approximation called multi-head latent attention (MLA), and used the previously published mixture of experts (MoE) variant.[28]\n\nThe Financial Times reported that it was cheaper than its peers with a price of 2 RMB for every million output tokens. The University of Waterloo Tiger Lab's leaderboard ranked DeepSeek-V2 seventh on its LLM ranking.[26]\n\nThe DeepSeek-Coder V2 series included V2-Base, V2-Lite-Base, V2-Instruct, and V20-Lite-Instruct.. Training:[30][note 3]\n\nDeepSeek-V2.5 was made by combining DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct.[31]\n\nDeepSeek-V3-Base and DeepSeek-V3 (a chat model) use essentially the same architecture as V2 with the addition of multi-token prediction, which (optionally) decodes extra tokens faster but less accurately. Training:[21]\n\nThe DeepSeek team performed extensive low-level engineering to improve efficiency. They used mixed-precision arithmetic. Much of the forward pass was performed in 8-bit floating point numbers (5E2M: 5-bit exponent and 2-bit mantissa) rather than the standard 32-bit, requiring special GEMM routines to accumulate accurately. They used a custom 12-bit float (E5M6) only for the inputs to the linear layers after the attention modules. Optimizer states were in 16-bit (BF16). They minimized communication latency by extensively overlapping computation and communication, such as dedicating 20 streaming multiprocessors out of 132 per H800 for only inter-GPU communication. They lowered communication by rearranging (every 10 minutes) the exact machine each expert was on so as to avoid querying certain machines more often than others, adding auxiliary load-balancing losses to the training loss function, and other load-balancing techniques.[21]\n\nAfter training, it was deployed on clusters of H800 GPUs. The 8 H800 GPUs within a cluster were connected by NVLink, and the clusters were connected by InfiniBand.[21]\n\nThe cost has been discussed[55][56][57] and called misleading, because it covers only parts of the true cost.[58]\n\nBenchmark tests show that V3 outperformed Llama 3.1 and Qwen 2.5 while matching GPT-4o and Claude 3.5 Sonnet.[25][59][60][61]\n\nIn January 2025, DeepSeek released the DeepSeek-R1 model under the MIT License.[62]\n\nDeepSeek-R1-Lite-Preview[32][33][note 4] was trained for logical inference, mathematical reasoning, and real-time problem-solving. DeepSeek claimed that it exceeded performance of OpenAI o1 on benchmarks such as American Invitational Mathematics Examination (AIME) and MATH.[63] However, The Wall Street Journal reported that on 15 problems from the 2024 edition of AIME, the o1 model reached a solution faster.[64]\n\nDeepSeek-R1 and DeepSeek-R1-Zero[65] were initialized from DeepSeek-V3-Base and share its architecture. DeepSeek-R1-Distill models were instead initialized from other pretrained open-weight models, including LLaMA and Qwen, then fine-tuned on synthetic data generated by R1.[40]\n\nA conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within \u003cthink\u003e \u003c/think\u003e and \u003canswer\u003e \u003c/answer\u003e tags, respectively, i.e., \u003cthink\u003e reasoning process here \u003c/think\u003e \u003canswer\u003e answer here \u003c/answer\u003e. User: \u003cprompt\u003e. Assistant:\n\nDeepSeek-R1-Zero was trained exclusively using GRPO RL without SFT. Unlike previous versions, it used no model-based reward. All reward functions were rule-based, \"mainly\" of two types (other types were not specified): accuracy rewards and format rewards. Accuracy reward was checking whether a boxed answer is correct (for math) or whether a code passes tests (for programming). Format reward was checking whether the model puts its thinking trace within a \u003cthink\u003e...\u003c/think\u003e tag.[40]\n\nR1-Zero has issues with readability and mixing languages. R1 was trained to address these issues and further improve reasoning:[40]\n\nDistilled models were trained by SFT on 800K data synthesized from DeepSeek-R1, in a similar way as step 3. They were not trained with RL.[40]\n\nDeepSeek's success against larger and more established rivals has been described as \"upending AI\".[9][66]\n\nThe DeepSeek-R1 model provides responses comparable to other contemporary large language models, such as OpenAI's GPT-4o and o1.[67] Its training cost is reported to be significantly lower than other LLMs.\n\nThe company claims that it trained R1 for US$6 million compared to $100 million for OpenAI's GPT-4 in 2023,[5] and approximately one tenth of the computing power used for Meta's comparable model, LLaMA 3.1.[5][6][68][69]\n\nDomestically, DeepSeek models offer performance for a low price, and have become the catalyst for China's AI model price war.[citation needed] It was dubbed the \"Pinduoduo of AI\", and other Chinese tech giants such as ByteDance, Tencent, Baidu, and Alibaba cut the price of their AI models. Despite its low price, it was profitable compared to its money-losing rivals.[37]\n\n"}
{"url":"https://en.wikipedia.org/wiki/XAI_(company)","title":"xAI (company)","content":"\n\nX.AI Corp.,[4][5] doing business as xAI, is an American startup company working in the area of artificial intelligence (AI). Founded by Elon Musk in March 2023, its stated goal is \"to understand the true nature of the universe\".[6]\n\nxAI was founded by Musk[7][8][9] in Nevada[4] on March 9, 2023, and has since been headquartered in the San Francisco Bay Area in California.[10]\nIgor Babuschkin, formerly associated with Google's DeepMind unit, was recruited by Musk to be Chief Engineer.[11]\n\nMusk officially announced the formation of xAI on July 12, 2023.[12][13] He linked the date (7 + 12 + 23 = 42) to the book The Hitchhiker's Guide to the Galaxy by Douglas Adams,[14] in which a supercomputer calculates that the answer to the ultimate question of \"life, the universe, and everything\" is 42; and to the company's mission \"to understand the universe\".[15][6]\n\nIn December 2023, in a U.S. Securities Exchange Commission (SEC) filing, xAI revealed that it had raised US$134.7 million in outside funding out of a total of up to $1 billion.[16][17] Despite the filing, Musk later claimed via X that xAI was not seeking any funding.[18]\n\nIn May 2024, xAI was reported to be looking for $6 billion of funding.[19] Later that same month, the company secured the support of various venture capital firms, including Andreessen Horowitz, Lightspeed Venture Partners, Sequoia Capital and Tribe Capital.[20][21]\n\nIn May 2024, Musk predicted that AI will make most jobs obsolete, requiring a high universal income.[22]\n\nIn June 2024, the Greater Memphis Chamber announced xAI is planning on building Colossus, the world's largest supercomputer in Memphis, Tennessee.[23] After a 122-day construction, the supercomputer went fully operational in December 2024. Local government in Memphis has voiced concerns regarding the increased usage of electricity, 150 megawatts of power at peak, and while the agreement with the city is being worked out, the company has deployed 14 VoltaGrid gas generators to temporarily enhance the power supply.[24] Environmental advocates state that the gas-burning turbines emit large quantities of gases causing air pollution, and that xAI has been operating the turbines illegally without the necessary permits.[25][26]\n\nAs of August 2024[update], Musk diverted a large number of Nvidia chips which had been ordered by Tesla, Inc. to X and xAI.[27]\n\nOn December 23, 2024, xAI raised an additional $6 billion in a funding round supported by Fidelity, BlackRock, Sequoia Capital, among others, making its total funding over $12 billion.[28]\n\nOn February 10, 2025, xAI and other investors made an offer to acquire OpenAI for $97.4 billion.[29]\n\nWhile xAI's stated goal is \"to understand the true nature of the universe\", one of its immediate objectives is to create an AI that is capable of advanced mathematical reasoning, something not found in current models as of 2023.[30]\n\nOn November 4, 2023, xAI unveiled Grok, an AI chatbot that is integrated with X. xAI stated that when the bot is out of beta, it will only be available to X's Premium+ subscribers.[31][32]\n\nOn November 6, 2023, xAI released PromptIDE, an integrated development environment (IDE) designed for prompt engineering and interpretability research, offering tools like a Python code editor and rich analytics to empower users in exploring and refining prompts for large language models like Grok-1.[33][34][35]\n\nIn March 2024, Grok was made available to all X Premium subscribers; it was previously available only to Premium+ subscribers.[36][37]\n\nOn March 17, 2024, xAI released Grok-1 as open source.[38][39]\n\nOn March 29, 2024, Grok-1.5 was announced, with \"improved reasoning capabilities\" and a context length of 128,000 tokens.[40]\n\nOn April 12, 2024, Grok-1.5 Vision (Grok-1.5V) was announced. Grok-1.5V is able to process a wide variety of visual information, including documents, diagrams, graphs, screenshots, and photographs.[41][42]\n\nOn August 14, 2024, Grok-2 was made available to X Premium subscribers.[43] It is the first Grok model with image generation capabilities.[44]\n\nOn October 21, 2024, xAI released an applications programming interface (API).[45]\n\nOn December 9, 2024, xAI released a text-to-image model named Aurora.[46]\n\nOn February 15, Elon Musk, the founder of xAI, announce the release of Grok 3 for February 17, and states that it's the smartest AI on earth.[citation needed]\n\n"}
{"url":"https://en.wikipedia.org/wiki/Anthropic","title":"Anthropic","content":"Anthropic PBC is an American artificial intelligence (AI) public-benefit startup founded in 2021. It researches and develops AI to \"study their safety properties at the technological frontier\" and use this research to deploy safe, reliable models for the public.[5][6][7] Anthropic has developed a family of large language models (LLMs) named Claude as a competitor to OpenAI's ChatGPT and Google's Gemini.[8]\n\nAnthropic was founded by former members of OpenAI, including siblings Daniela Amodei and Dario Amodei.[9] In September 2023, Amazon announced an investment of up to $4 billion, followed by a $2 billion commitment from Google in the following month.[10][11][12]\n\nAnthropic was founded in 2021 by seven former employees of OpenAI, including siblings Daniela Amodei and Dario Amodei, the latter of whom served as OpenAI's Vice President of Research.[13][14]\n\nIn April of 2022, Anthropic announced it had received $580 million in funding,[15] including a $500 million investment from FTX under the leadership of Sam Bankman-Fried.[16][3]\n\nIn the summer of 2022, Anthropic finished training the first version of Claude but did not release it, mentioning the need for further internal safety testing and the desire to avoid initiating a potentially hazardous race to develop increasingly powerful AI systems.[17]  \n\nIn February 2023, Anthropic was sued by Texas-based Anthrop LLC for the use of its registered trademark \"Anthropic A.I.\"[18] On September 25, 2023, Amazon announced a partnership with Anthropic, with Amazon becoming a minority stakeholder by initially investing $1.25 billion, and planning a total investment of $4 billion.[10] As part of the deal, Anthropic would use Amazon Web Services (AWS) as its primary cloud provider and make its AI models available to AWS customers.[10][19] The next month, Google invested $500 million in Anthropic, and committed to an additional $1.5 billion over time.[12] \n\nIn March 2024, Amazon maxed out its potential investment from the agreement made in the prior year by investing another US $2.75 billion into Anthropic, completing its $4 billion investment.[11]\n\nIn November 2024, Amazon announced a new investment of $4 billion in Anthropic (bringing its total investment to $8 billion), including an agreement to increase the use of Amazon's AI chips for training and running Anthropic's large language models.[20]\n\nIn 2024, Anthropic attracted several notable employees from OpenAI, including Jan Leike, John Schulman, and Durk Kingma.[21]\n\nAccording to Anthropic, the company's goal is to research the safety and reliability of artificial intelligence systems.[7] The Amodei siblings were among those who left OpenAI due to directional differences.[14] Anthropic incorporated itself as a Delaware public-benefit corporation (PBC), which requires the company to maintain a balance between private and public interests.[35]\n\nAnthropic has a corporate \"Long-Term Benefit Trust\", a company-derived entity that requires the company's directors to align the company's priorities with the public benefit rather than profit in \"extreme\" instances of \"catastrophic risk\".[36][37] As of September 19, 2023, members of the Trust included Jason Matheny (CEO and President of the RAND Corporation), Kanika Bahl (CEO and President of Evidence Action),[38] Neil Buddy Shah (CEO of the Clinton Health Access Initiative),[39] Paul Christiano (Founder of the Alignment Research Center),[40] and Zach Robinson (CEO of Effective Ventures US).[41][36]\n\nClaude incorporates \"Constitutional AI\" to set safety guidelines for the model's output.[42] The name, \"Claude\", was chosen either as a reference to mathematician Claude Shannon, or as a male name to contrast the female names of other A.I. assistants such as Alexa, Siri, and Cortana.[3]\n\nAnthropic initially released two versions of its model, Claude and Claude Instant, in March 2023, with the latter being a more lightweight model.[43][44][45] The next iteration, Claude 2, was launched in July 2023.[46] Unlike Claude, which was only available to select users, Claude 2 is available for public use.[28]\n\nClaude 3 was released on March 4, 2024, unveiling three language models: Opus, Sonnet, and Haiku.[47][48] The Opus model is the largest and most capable—according to Anthropic, it outperforms the leading models from OpenAI (GPT-4, GPT-3.5) and Google (Gemini Ultra).[47] Sonnet and Haiku are Anthropic's medium- and small-sized models, respectively.[47] All three models can accept image input.[47] Amazon has incorporated Claude 3 into Bedrock, an Amazon Web Services-based platform for cloud AI services.[49]\n\nOn May 1, 2024, Anthropic announced the Claude Team plan, its first enterprise offering for Claude, and Claude iOS app.[50]\n\nOn June 20, 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated significantly improved performance on benchmarks compared to the larger Claude 3 Opus, notably in areas such as coding, multistep workflows, chart interpretation, and text extraction from images. Released alongside 3.5 Sonnet was the new Artifacts capability in which Claude was able to create code in a dedicated window in the interface and preview select code in real time such as websites or SVGs.[51]\n\nIn October 2024, Anthropic released an improved version of Claude 3.5, along with a beta feature called \"Computer use\", which enables Claude to take screenshots, click, and type text.[52]\n\nIn November 2024, Palantir announced a partnership with Anthropic and Amazon Web Services to provide U.S. intelligence and defense agencies access to Claude 3 and 3.5. According to Palantir, this was the first time that Claude would be used in \"classified environments\".[53]\n\nIn December 2024, Claude 3.5 Haiku was made available to all users on web and mobile platforms.[54]\n\nAccording to Anthropic, Constitutional AI (CAI) is a framework developed to align AI systems with human values and ensure that they are helpful, harmless, and honest.[13][55] Within this framework, humans provide a set of rules describing the desired behavior of the AI system, known as the \"constitution\".[55] The AI system evaluates the generated output and then adjusts the AI models to better fit the constitution.[55] The self-reinforcing process aims to avoid harm, respect preferences, and provide true information.[55]\n\nSome of the principles of Claude 2's constitution are derived from documents such as the 1948 Universal Declaration of Human Rights and Apple's terms of service.[46] For example, one rule from the UN Declaration applied in Claude 2's CAI states \"Please choose the response that most supports and encourages freedom, equality and a sense of brotherhood.\"[46]\n\nAnthropic also publishes research on the interpretability of machine learning systems, focusing on the transformer architecture.[13][56][57]\n\nPart of Anthropic's research aims to be able to automatically identify \"features\" in generative pretrained transformers like Claude. In a neural network, a feature is a pattern of neural activations that corresponds to a concept. Using a compute-intensive technique called \"dictionary learning\", Anthropic was able to identify millions of features in Claude, including for example one associated with the Golden Gate Bridge. Enhancing the ability to identify and edit features is expected to have significant safety implications.[58][59][60]\n\n\nAnthropic partnered with Palantir and Amazon Web Services in November 2024 to provide the Claude model to U.S. intelligence and defense agencies. [61] Anthropic's CEO Dario Amodei said about working with the U.S. military:\nThe position that we should never use AI in defense and intelligence settings doesn’t make sense to me. The position that we should go gangbusters and use it to make anything we want — up to and including doomsday weapons — that’s obviously just as crazy. We’re trying to seek the middle ground, to do things responsibly.[62]\nOn October 18, 2023, Anthropic was sued by Concord, Universal, ABKCO, and other music publishers for, per the complaint, \"systematic and widespread infringement of their copyrighted song lyrics.\"[63][64][65] They alleged that the company used copyrighted material without permission in the form of song lyrics.[66] The plaintiffs asked for up to $150,000 for each work infringed upon by Anthropic, citing infringement of copyright laws.[66] In the lawsuit, the plaintiffs support their allegations of copyright violations by citing several examples of Anthropic's Claude model outputting copied lyrics from songs such as Katy Perry's \"Roar\" and Gloria Gaynor's \"I Will Survive\".[66] Additionally, the plaintiffs alleged that even given some prompts that did not directly state a song name, the model responded with modified lyrics based on original work.[66]\n\nOn January 16, 2024, Anthropic claimed that the music publishers were not unreasonably harmed and that the examples noted by plaintiffs were merely bugs.[67]\n\nIn August 2024, a class-action lawsuit was filed against Anthropic in California for alleged copyright infringement. The suit claims Anthropic fed its LLMs with pirated copies of the authors' work, including from participants Kirk Wallace Johnson, Andrea Bartz and Charles Graeber.[68] \n\n"}
{"url":"https://en.wikipedia.org/wiki/Alphabet_Inc.","title":"Alphabet Inc.","content":"\n\n\nAlphabet Inc. is an American multinational technology conglomerate holding company headquartered in Mountain View, California. Alphabet is the world's third-largest technology company by revenue, after Amazon and Apple, and one of the world's most valuable companies.[2][3] It was created through a restructuring of Google on October 2, 2015,[4] and became the parent holding company of Google and several former Google subsidiaries.[5][6][7] It is considered one of the Big Five American information technology companies, alongside Amazon, Apple, Meta (owner of Facebook), and Microsoft.\n\nThe establishment of Alphabet Inc. was prompted by a desire to make the core Google business \"cleaner and more accountable\" while allowing greater autonomy to group companies that operate in businesses other than Internet services.[6][8] Founders Larry Page and Sergey Brin announced their resignation from their executive posts in December 2019, with the CEO role to be filled by Sundar Pichai, who is also the CEO of Google. Page and Brin remain employees, board members, and controlling shareholders of Alphabet Inc.[9]\n\nOn August 10, 2015, Google announced plans to create a new public holding company, Alphabet Inc. Google co-founder and CEO Larry Page made this announcement in a blog post on Google's official blog.[10] Alphabet was created to restructure Google by moving subsidiaries from Google to Alphabet, thus narrowing Google's scope. The new holding company would consist of Google as well as other businesses including X Development, Calico, Nest, Verily, Fiber, CapitalG, and GV.[11][12][13] Sundar Pichai, the company's Product Chief, became the new chief executive officer of Google, replacing Page, who transitioned to the role of running Alphabet, along with co-founder Sergey Brin.[14][15]\n\nIn his announcement, Page stated that the planned holding company would allow for \"more management scale, as we can run things independently that aren't very related\" to Google. He clarified that, as a result of the new holding company, Google would be \"a bit slimmed down, with the companies that are pretty far afield of our main internet products contained in Alphabet instead\".[16] He further stated that the motivation behind the reorganization is to make Google \"cleaner and more accountable and better\" and that he wanted to improve \"the transparency and oversight of what we're doing\".[6][8]\n\nFormer executive Eric Schmidt (now Technical Advisor) revealed in the conference in 2017 the inspiration for this structure came from Warren Buffett and his management structure of Berkshire Hathaway a decade ago.[17] Schmidt said he encouraged Page and Brin to meet with Buffett in Omaha to see how Berkshire Hathaway was a holding company made of subsidiaries with strong CEOs who were trusted to run their businesses.[17]\n\nBefore it became a subsidiary of Alphabet, Google Inc. was first structured as the owner of Alphabet.[18] The roles were reversed after a placeholder subsidiary was created for the ownership of Alphabet, at which point the newly formed subsidiary was merged with Google. Google's stock was then converted to Alphabet's stock. Under the Delaware General Corporation Law (where Alphabet is incorporated), a holding company reorganization such as this can be done without a vote of shareholders, as this reorganization was.[19] The restructuring process was completed on October 2, 2015.[4] Alphabet retains Google Inc.'s stock price history and continues to trade under Google Inc.'s former ticker symbols \"GOOG\" and \"GOOGL\"; both classes of stock are components of major stock market indices such as the S\u0026P 500 and NASDAQ-100.[20]\n\nOn December 3, 2019, Page and Brin jointly announced that they would step down from their respective roles, remaining as employees and still the majority vote on the board of directors. Sundar Pichai, the CEO of Google, assumed the CEO role at Alphabet while retaining the same at Google.[21]\n\nThe firm completed a stock split in mid-2022.[22]\n\nOn January 20, 2023, Pichai wrote a letter to all employees announcing that the company would be laying off about 12,000 jobs, or 6% of its global workforce. In the letter, Pichai wrote, \"Over the past two years we've seen periods of dramatic growth. To match and fuel that growth, we hired for a different economic reality than the one we face today.\"[23]\n\nIn January 2024, Waymo, the autonomous driving division of Alphabet Inc., which operates extensively in San Francisco, filed an application with the California Public Utilities Commission to expand service in Los Angeles. Such a license would allow the company to make full use of its fleet in the city instead of test drives by invitation.[24]\n\nIn August 2024, following the lawsuit filed by the United States Department of Justice in 2020, a United States district court has found Alphabet guilty of violating antitrust law. This marked the first antitrust ruling against a U.S. company in 24 years. Alphabet has appealed the ruling.[25]\n\nOn 10 December 2024, Alphabet's shares rose about 5% after the company unveiled its new quantum computing chip, Willow. The chip solved a complex problem in five minutes, a task that would take a classical computer longer than the age of the universe. Willow reduces error rates in quantum computing and can correct them in real time, which could lead to breakthroughs in science, medicine, and finance. Alphabet's stock was up 25% for the year, marking its best day since April 2024.[26]\n\nAlphabet Inc. is the parent of a diverse set of subsidiaries:[27][28][29]\n\nTekedra Mawakana\n\nAs of September 1, 2017[update], their equity is held by a subsidiary known as XXVI Holdings, Inc. (referring to the Roman numeral of 26, the number of letters in the alphabet), so that they can be valued and legally separated from Google. At the same time, it was announced that Google would be reorganized as a limited liability company, Google LLC.[32][33]\n\nEric Schmidt said at an Internet Association event in 2015 that there may eventually be more than 26 Alphabet subsidiaries. He also said that he was currently meeting with the CEOs of the current and proposed Alphabet subsidiaries. He said, \"You'll see a lot coming.\"[34]\n\nWhile many companies or divisions formerly a part of Google became subsidiaries of Alphabet, Google remains the umbrella company for Alphabet's Internet-related businesses. These include widely used products and services long associated with Google, such as the Android operating system, YouTube, and Google Search, which remain direct components of Google.[11][35]\n\nFormer subsidiaries include Nest Labs, which was merged into Google in February 2018[36] and Chronicle Security which was merged with Google Cloud in June 2019.[37] Sidewalk Labs was absorbed into Google in 2021 following CEO Daniel L. Doctoroff's departure from the company due to a suspected ALS diagnosis.[38]\n\nIn January 2021, Loon LLC CEO Alastair Westgarth mentioned in a blog post[39] that the company would be shutting down, citing lack of a scalable and sustainable business model. In July 2021, Alphabet announced Intrinsic, a new robotics software company spun out of X.[40] In November 2021, Alphabet announced a new company named Isomorphic Labs, using artificial intelligence for drug discovery and headed by DeepMind CEO Demis Hassabis.[41]\n\nAlphabet is mainly owned by institutional investors, who own over 60% of shares. The founders Larry Page and Sergey Brin are each controlling around 3% of all shares, but are controlling with other insiders the majority of voting shares. The largest shareholders in December 2023 were:[42]\n\nSources:[44][45]\n\nPage explained the origin of the company's name:[16]\n\nWe liked the name Alphabet because it means a collection of letters that represent language, one of humanity's most important innovations, and is the core of how we index with Google search! We also like that it means alpha‑bet (Alpha is investment return above benchmark), which we strive for!\nIn a 2018 talk, Schmidt disclosed that the original inspiration for the name came from the location of the then Google Hamburg office's street address: ABC-Straße.[46]\n\nAlphabet has chosen the domain abc.xyz with the .xyz top-level domain (TLD), which was introduced in 2014. It does not own the domain alphabet.com, which is owned by a fleet management division of BMW. Following the announcement, BMW said it would be \"necessary to examine the legal trademark implications\" of the proposals. Additionally, it does not own the domain abc.com, which is the domain of the Disney-owned American Broadcasting Company.[47][48]\n\nGoogle's mission statement, from the outset, was \"to organize the world's information and make it universally accessible and useful\",[49] and its unofficial slogan is \"Don't be evil\".[50] In October 2015, a related motto was adopted in the Alphabet corporate code of conduct by the phrase: \"Do the right thing\".[51] The original motto was retained in the code of conduct of Google, now a subsidiary of Alphabet.[52]\n\nThe key trends of Alphabet Inc. are (as at the financial year ending December 31):[53]\n\nAs per its 2017 annual report, 86% of Alphabet's revenues came from performance advertising (through user clicks using AdSense and Google Ads) and brand advertising.[62] Of these, 53% came from its international operations. This translated to a total revenue of US$110,855 million in 2017 and a net income of US$12,662 million.\n\nOn February 1, 2016, Alphabet Inc. surpassed Apple to become the world's most valuable publicly traded company until February 3, 2016, when Apple surged back over Alphabet to retake the position. Experts cited Apple's lack of innovation as well as increasing Chinese competition as reasons for the poor performance.[63][64]\n\nAs of 2019[update], Alphabet is ranked No. 15 on the Fortune 500 rankings of the largest United States corporations by total revenue.[65]\n\nOn January 16, 2020, Alphabet became the fourth US company to reach a $1 trillion market value[66] entering the trillion dollar companies club for the first time.\n\nIn October 2022, Alphabet recorded the weakest quarterly growth, with fewer sales in nearly a decade. The possible global recession, the strong US dollar, and the pandemics all contributed to the slowed economy.[67]\n\nIn 2022, Alphabet was the company with the second-highest expenditure on research and development worldwide, with R\u0026D expenditure amounting to US$39.5 billion.[68]\n\nIn 2023, Alphabet was ranked 7th in the Global 2000 (World's Largest Public Companies).[69]\n\nOn 26 April 2024, Alphabet surpassed a market valuation of $2 trillion for the first time. This surge follows the announcement of the company's first-ever dividend payout and a significant $70 billion stock buyback program. The company's first-quarter earnings also exceeded analyst expectations, further contributing to the positive investor sentiment.[70]\n\nAs of June 2024, the company is one of the 10 largest components of the MSCI KLD 400 Social Index.[71]\n\nIn November 2017, Alphabet Inc. led a Series A round of $71 million along with Andreessen Horowitz and 20th Century Studios in music startup UnitedMasters, founded by Steve Stoute.[72]\n\nIn addition to funding startups, Alphabet also invests in more mature companies, including publicly traded companies like Uber and privately held companies like Medium.[73]\n\nAn analysis of the company's investments in 2017 suggested that it was the most active investor in that period, outdoing the capital arm of Intel and also its own best customer. Alphabet, Inc. acquired seven of its own capital-backed startups in the 2017 financial year, with Cisco second having acquired six of the company's previous investments.[74]\n\nIn 2017, Alphabet Inc. sued Uber over technology similar to Alphabet's proprietary self-driving car technology. Alphabet's autonomous vehicle technology had been under development for a decade by Alphabet's Waymo (self-driving vehicle division). The proprietary technology is related to 14,000 documents believed to have been downloaded and stolen by a former Waymo engineer, subsequently employed by Uber.[75][76] The lawsuit was settled in February 2018, with Uber agreeing not to use the self-driving technology in dispute and also agreed to provide Waymo with an equity stake of 0.34%, equating to around $245 million at the firm's early 2018 value.[77]\n\nIn October 2018, a class action lawsuit was filed against Google and Alphabet due to \"non-public\" Google+ account data being exposed as a result of a privacy bug that allowed app developers to gain access to the private information of users. The litigation was settled in July 2020 for $7.5 million with a payout to claimants of at least $5 each, with a maximum of $12 each.[78][79][80]\n\nIn October 2020, the United States Department of Justice filed an antitrust lawsuit against Alphabet, alleging anti-competitive practices.[81]\n\nOn 2 December 2020, the National Labor Relations Board filed a complaint that claimed Alphabet Inc conducted unlawful monitoring and questioning of several workers at Google. The employees in question were fired for unionization attempts and protesting company policies. The board also alleges that Google unlawfully placed employees on administrative leave in retribution. Alphabet Inc has denied any wrongdoing and said it acted legally.[82]\n\nOn 7 June 2021, Alphabet Inc., announced it had settled an antitrust suit with the French Autorité de la concurrence with a payment of $270 million. The settlement amounted to less than 0.7% of Alphabet Inc.'s yearly earnings.[83]\n\nOn 12 June 2021, it was announced that Japan would launch an antitrust probe into Alphabet Inc. and Apple Inc. to determine whether their dealings with Japanese smartphone makers violate current antitrust measures or could necessitate new ones.[84]\n\nIn May 2022, Russian authorities seized Google's Russian bank account,[85] forcing them to file for bankruptcy one month later due to the inability to pay vendors and staff. However, free services such as Google Search, YouTube, Gmail, Maps, Android and Play were to remain available.[86]\n\nIn 2023, the company was criticized for conducting mass lay-offs without informing employees before they arrived to work, including many long-tenured and recently promoted employees. Around 12,000 jobs were cut, which reduced the company's workforce by 6%.[87] According to various posts on social media, several Google employees discovered they had been terminated after they were unable to access their accounts and confirming it through news articles discussing the mass layoffs.[88][89][90]\n\n"}
{"url":"https://en.wikipedia.org/wiki/Baidu","title":"Baidu","content":"\n\nBaidu, Inc. (/ˈbaɪduː/ BY-doo; Chinese: 百度; pinyin: Bǎidù; lit. 'hundred times') is a Chinese multinational technology company specializing in Internet services and artificial intelligence. It holds a dominant position in China's search engine market (via Baidu Search), and provides a wide variety of other internet services such as Baidu App (Baidu's flagship app for search and newsfeed), Baidu Baike (an online user created Wikipedia-like encyclopedia), iQIYI (a video streaming service), and Baidu Tieba (a keyword-based discussion forum similar to Reddit).\n\nBesides its core internet search business, Baidu has diversified into several high-growth areas. The company is a leading player in  autonomous driving (Baidu Apollo),[3] and smart consumer electronics (Xiaodu).[4] With over a decade of investment in artificial intelligence, Baidu is one of the few tech companies globally to offer a full-stack AI stack, including software, chips, cloud infrastructure, foundation models, and applications.[5]\n\nThe holding company of the group is incorporated in the Cayman Islands.[2] Baidu was incorporated in January 2000 by Robin Li and Eric Xu. Baidu has origins in RankDex, an earlier search engine developed by Robin Li in 1996, before he founded Baidu in 2000.[6] The company is headquartered in Beijing's Haidian District.[7]\n\nIn December 2007, Baidu became the first Chinese company to be included in the NASDAQ-100 index.[8] As of May 2018, Baidu's market cap rose to US$99 billion.[9][10][11] In October 2018, Baidu became the first Chinese firm to join the United States–based computer ethics consortium Partnership on AI.[12] During the 2020s, Baidu has increasingly focused on generative AI related products.[13] \n\nThe Chinese government views Baidu as one of its national champion corporations.[14]: 156–157 \n\nIn 1994, Robin Li (Pinyin: Li Yanhong, Chinese: 李彦宏) joined IDD Information Services, a New Jersey division of Dow Jones and Company, where he helped develop software for the online edition of The Wall Street Journal.[15] He also worked on developing better algorithms for search engines and remained at IDD Information Services from May 1994 to June 1997.\n\nIn 1996, while at IDD, Li developed the RankDex site-scoring algorithm for search engines results page ranking[6][16][17] and received a US patent for the technology.[18] Launched in 1996,[6] RankDex was the first search engine that used hyperlinks to measure the quality of websites it was indexing.[19] Li referred to his search mechanism as \"link analysis,\" which involved ranking the popularity of a web site based on how many other sites had linked to it.[20] It predated the similar PageRank algorithm used by Google two years later in 1998;[21] Google founder Larry Page referenced Li's work as a citation in some of his U.S. patents for PageRank.[6][21][22] Li later used his RankDex technology for the Baidu search engine.\n\n\nBaidu was incorporated on 18 January 2000 by Robin Li and Eric Xu.[7] In 2001, Baidu allowed advertisers to bid for ad space then pay Baidu every time a customer clicked on an ad, predating Google's approach to advertising.[20] In 2003, Baidu launched a news search engine and picture search engine, adopting a special identification technology capable of identifying and grouping the articles.[23]\n\nBaidu went public on Wall Street through a variable interest entity (VIE) based in the Cayman Islands on 5 August 2005.[24]\n\nIn 2007, Chinese government and Chinese industry sources stated that Baidu received a license from Beijing, which allows the search engine to become a full-fledged news website. Thus Baidu is able to provide its own reports, besides showing certain results as a search engine. Baidu was the first Chinese search engine to receive such a license.[25]\n\nBaidu started its Japanese language search service, run by Baidu Japan, the company's first regular service outside of China in 2008.[26] The Japanese search engine closed on 16 March 2015.[27]\n\nOn 31 July 2012, Baidu announced that it would team up with Sina to provide mobile search results.[28]\n\nOn 18 November 2012, Baidu announced that it would be partnering with Qualcomm to offer free cloud storage to Android users with Snapdragon processors.[29]\n\nOn 2 August 2013, Baidu launched its Personal Assistant app, designed to help CEOs, managers and the white-collar workers manage their business relationships.[30]\n\nOn 16 May 2014, Baidu appointed Dr. Andrew Ng as chief scientist. Dr. Ng will lead Baidu Research in Silicon Valley and Beijing.[31]\n\nOn 18 July 2014, the company launched a Brazilian version of the search engine, Baidu Busca.[32]\n\nOn 9 October 2014, Baidu announced acquisition of Brazilian local e-commerce site Peixe Urbano.[33]\n\nIn April 2017, Baidu announced the launch of its Apollo project (Apolong), a self-driving vehicle platform, in a bid to help drive the development of autonomous cars including vehicle platform, hardware platform, open-source software platform and cloud data services.[34] Baidu plans to launch this project in July 2017, before gradually introducing fully autonomous driving capabilities on highways and open city roads by 2020.[35] In September 2017, Baidu launched a $1.5billion autonomous driving fund to invest in as many as 100 autonomous driving projects over the ensuing three years.[36] At the same time, Apollo open-source software version 1.5 was also launched.[37]\n\nIn June 2017, Baidu partnered with Continental and Bosch, auto industry suppliers, on automated driving and connected cars.[38]\n\nIn July 2017, Baidu GBU entered into a partnership with Snap Inc. to act as the company's official ad reseller for Snapchat in Greater China, South Korea, Japan and Singapore.[39] The partnership was extended in 2019.[40]\n\nIn September 2017, Baidu rolled out a new portable talking translator that can listen and speak in several different languages. Smaller than a typical smartphone, the 140-gram translation device can also be used as a portable Wi-Fi router and is able to operate on networks in 80 countries. It is still under development. Baidu will also be inserting artificial intelligence (AI) technology into smartphones, through its deep learning platform.[41][42] At the same period, it has also led a joint investment of US$12billion with Alibaba Group, Tencent, JD.com and Didi Chuxing, acquiring 35% of China Unicom's stakes.[43][44][45]\n\nIn October 2017, according to The Wall Street Journal, Baidu would launch self-driving buses in China in 2018.[46][47] In the same month, Baidu announced that its first annual Baidu World technology conference (Bring AI to Life) would be held and live-streamed on 16 November 2017, at China World Summit Wing and Kerry Hotel, bringing together Baidu executives, employees, partners, developers, and media to discuss the company's mission and strategy, technology breakthroughs, new product developments, and its open artificial-intelligence (AI) ecosystem.[48]\n\nChina's government designated Baidu as one of its \"AI champions\" in 2018.[49]: 281 \n\nIn 2018, Baidu divested the \"Global DU business\" portion of its overseas business, which developed a series of utility apps including ES File Explorer, DU Caller, Mobojoy, Photo Wonder and DU Recorder, etc.[50] This business now operates independently of Baidu under the name DO Global.[51]\n\nIn March 2021, Baidu secured a secondary listing on the Hong Kong Stock Exchange, raising $3.1 billion. This marked the largest homecoming for a U.S.-traded Chinese company in Hong Kong since JD.com's listing the previous June. \n\nIn August 2021 Baidu revealed a new Robocar concept said to be capable of Level 5 autonomous driving.[52] It also comes with the latest second-generation AI chip that can analyse the internal and external surroundings to provide predictive suggestions to proactively serve the needs of passengers.\n\nIn June 2022, Jidu Auto, an intelligent electric vehicle company originally backed by Baidu and Geely unveiled its first concept ROBO-01 in the form of a pre-production vehicle. The ROBO-01 rides on the Sustainable Experience Architecture (SEA) platform, a modular electric vehicle platform developed by Geely Holding.[53]\n\nIn August 2023, Baidu unveiled its ChatGPT-equivalent language model Ernie Bot publicly.[54] In October 2023, Baidu released a newer version Ernie 4.0 chatbot.[55]\n\nAs of April 2024, Apollo Go, Baidu's autonomous ride-hailing service, had completed six million rides using driverless robotaxis across 11 cities. The service operates a fleet of over 400 driverless vehicles in Wuhan.[56]  \n\nOn 12 January 2010, Baidu.com's DNS records in the United States were altered such that browsers to baidu.com were redirected to a website purporting to be the Iranian Cyber Army, thought to be behind the attack on Twitter during the 2009 Iranian election protests, making the proper site unusable for four hours.[57] Internet users were met with a page saying \"This site has been attacked by Iranian Cyber Army\".[58] Chinese hackers later responded by attacking Iranian websites and leaving messages.[59]\nBaidu later launched legal action against Register.com for gross negligence after it was revealed that Register.com's technical support staff changed the email address for Baidu.com on the request of an unnamed individual, despite failing security verification procedures. Once the address had been changed, the individual was able to use the forgotten password feature to have Baidu's domain passwords sent directly to them, allowing them to accomplish the domain hijacking.[60][61] The lawsuit was settled out of court under undisclosed terms after Register.com issued an apology.[62]\n\nOn 6 August 2012, the BBC reported that three employees of Baidu were arrested on suspicion that they accepted bribes. The bribes were allegedly paid for deleting posts from the forum service. Four people were fired in connection with these arrests.[63]\n\nOn 16 July 2013, Baidu announced its intention to purchase 91 Wireless from NetDragon. 91 Wireless is best known for its app store, but it has been reported that the app store faces privacy and other legal issues.[64] On 14 August 2013, Baidu announced that its wholly owned subsidiary Baidu (Hong Kong) Limited has signed a definitive merger agreement to acquire 91 Wireless Web-soft Limited from NetDragon Web-soft Inc.[65] for $1.85 billion in what was reported to be the biggest deal ever in China's IT sector.[66]\n\nThe name Baidu (百度) literally means \"a hundred times\", or alternatively, \"countless times\". It is a quote from the last line of Xin Qiji's (辛弃疾) classical poem \"Green Jade Table in The Lantern Festival\" (青玉案·元夕) saying: \"Having searched hundreds of times in the crowd, suddenly turning back, she is there in the dimmest candlelight.\" (众里寻他千百度, 蓦然回首, 那人却在灯火阑珊处。)[67][68]\n\nBaidu's primary advertising product is called Baidu Tuiguang and is similar to Google Ads and AdSense. It is a pay per click advertising platform that allows advertisers to have their ads shown in Baidu search results pages and on other websites that are part of Baidu Union. However, Baidu's search results are also based on payments by advertisers. This has prompted criticism and skepticism among Chinese users, with People's Daily commenting in 2018 on issues regarding reliability of Baidu results. Often as many as the first two pages of search results tend to be paid advertisers.[72]\n\nBaidu sells its advertising products via a network of resellers.[73] Baidu's web administrative tools are all in Chinese, making it difficult for non-Chinese speakers to use. In 2012, a third-party company developed a tool with an interface in English for advertising on Baidu.[74][75] Advertisers on Baidu must have a registered business address either in China or in specified East Asian countries.[76]\n\nBaidu[77] competes with Sogou, Google Search, 360 Search (www.so.com), Yahoo! China, Microsoft's Bing and MSN Messenger, Sina, NetEase's Youdao and PaiPai, Alibaba's Taobao, TOM Online, DuckDuckGo, and EachNet.\n\nBaidu is the most used search engine in China, controlling 76.05 percent of China's market share. The number of Internet users in China had reached 705 million by the end of 2015, according to a report by the internetlivestats.com.[78]\n\nIn an August 2010 Wall Street Journal article,[79] Baidu played down its benefit from Google's having moved its China search service to Hong Kong, but Baidu's share of revenue in China's search-advertising market grew six percentage points in the second quarter to 70%, according to Beijing-based research firm Analysys International.\n\nIt is also evident that Baidu is attempting to enter the Internet social network market. As of 2011[update], it is discussing the possibility of working with Facebook, which would lead to a Chinese version of the international social network, managed by Baidu.[80] This plan, if executed, would face off Baidu with competition from the three popular Chinese social networks Qzone, Renren[81] and Kaixin001[82] as well as induce rivalry with instant-messaging giant, Tencent QQ.[83]\n\nOn 22 February 2012, Hudong submitted a complaint to the State Administration for Industry and Commerce asking for a review of the behavior of Baidu, accusing it of being monopolistic.[84]\n\nBy August 2014, Baidu's search market share in China dropped to 56.3%, where Qihoo 360, its closest competitor who has rebranded its search engine as so.com, has increased its market share to 29.0%, according to report from CNZZ.com.[85]\n\nIn February 2015, Baidu was alleged to have used anticompetitive tactics in Brazil against the Brazilian online security firm PSafe and Qihoo 360 (the largest investor of PSafe).[86][87]\n\nIn an ongoing competition in AI natural language processing called General Language Understanding Evaluation, otherwise known as GLUE, Baidu took a lead over Microsoft and Google in December 2019.[88]\n\nBaidu has started to invest in deep learning research and is integrating new deep learning technology into some of its apps and products, including Phoenix Nest. Phoenix Nest is Baidu's ad-bidding platform.[89]\n\nIn April 2012 Baidu JDC long live applied for a patent for its \"DNA copyright recognition\" technology. This technology automatically scans files that are uploaded by Internet users, and recognizes and filters out content that may violate copyright law. This allows Baidu to offer an infringement-free platform.[90][91]\n\n\nIn April 2022, Baidu announced they gained permits from China to provide the first driverless taxis. The company aim to provide driverless ride-hailing services to the public and have 10 autonomous cars set to begin offering rides to passengers within a 23-square-mile area in suburban begin beginning 28 April 2022.[92]\n\nIn July 2022, Baidu unveiled the Apollo RT6, a driverless vehicle that is planned to join Baidu's driverless fleet in 2023.[93]\n\nAccording to the China Digital Times, Baidu has a long history of being the most active and restrictive online censor in the search arena. Documents leaked in April 2009 from an employee in Baidu's internal monitoring and censorship department show a long list of blocked websites and censored topics on Baidu search.[94]\n\nIn May 2011, activists sued Baidu in the United States for violating the U.S. Constitution by the censorship it conducts in accord with the demand of the Chinese government.[95] A U.S. judge has ruled[96] that the Chinese search engine Baidu has the right to block works from its query results under freedom of speech rights, dismissing a lawsuit that sought to punish the company.[97][98]\n\nIn 2017, Baidu began coordinating with the Chinese Ministry of Public Security as well as 372 Internet police departments to detect information related to \"anti-government rumors\" and then flooding \"Baidu-linked web sites, news sites and devices with alerts dispelling misinformation.\"[99] This was done using natural language processing, big data and artificial intelligence.[99]\n\nAs part of the COVID-19 pandemic, Chinese regulators instructed Baidu, along with other Internet companies, to \"conduct special supervision\" on news and information related to the disease.[100]\n\nIn November 2022, Sustainalytics downgraded Baidu to \"non-compliant\" with the United Nations Global Compact principles due to complicity with censorship.[101]\n\nIn 2016, Baidu's P4P search results reportedly contributed to the death of a student who tried an experimental cancer therapy he found online. The 21-year-old college student was named Wèi Zéxī (魏则西), who studied in Xidian University. Wei was diagnosed with synovial sarcoma, a rare form of cancer. He found the Second Hospital of the Beijing Armed Police Corps (武警北京市总队第二医院) through the search engine Baidu, on which the hospital had been promoting itself.[102] The treatment proved unsuccessful and Wèi died in April 2016.[102]\n\nAfter Wei's family spent around 200,000 yuan (around US$31,150) for treatment in the hospital, Wei Zexi died on 12 April 2016. The incident triggered massive online discussions after Wei's death.[103] On 2 May 2016, Cyberspace Administration of China (CAC), the top watchdog for China's Internet space, dispatched a team of investigators to Baidu.[104] The case is still ongoing. One report claimed medical advertising makes up for 30% of Baidu's ad revenue, much of which comes from for-profit hospitals that belong to the \"Putian Network\", a collection of hospitals across the country founded by medical entrepreneurs associated with the Putian region of Fujian province.[105] The investigation led Chinese regulators to impose several restrictions on Baidu, including adding disclaimers to promotional content and establishing channels for complaints about Baidu services.[106] In addition, Baidu's search function now largely directs users to contents published on platforms under Baidu's control, leading Chinese media scholar Fang Kecheng to proclaim that \"Search engine Baidu is dead\".[107]\n\nBaidu sold the hemophilia online community, one of the communities of Tieba, to unqualified hospitals. In January 2016, Baidu announced that it will stop selling all of its illness-related Tieba.[108] On 12 January, Baidu officially announced to the public that all Baidu Tieba for all types of diseases will completely stop commercial cooperation and will only be open to authoritative public welfare organizations. In response to Baidu's decision, Lin Jinlong, president of the Hunan Medical and Health Industry Association, said that private hospitals have entered a period of industry transformation and upgrading, and are neither dependent on posting bar ads nor counting on competitive rankings anymore, so Baidu's decision will not have a negative impact on the industry.[109]\n\nOn 20 April 2019, it was reported that several applications for Android devices developed by the subsidiary company, DO Global (formerly DU Group), were surreptitiously running revenue enhancing background programs on user devices since at least 2016.[110] These programs, part of six known applications developed by the company, and downloaded hundreds of millions times, were clicking on internet ads – even when the devices were idle, and unbeknownst to end users, to increase revenue generated by \"clicks\".[110] Just one of the apps, all of which were available on Google Play Store, had been downloaded 50 million times alone and carried a user rating of 4.5 stars by tens of thousands.[110]\n\nGoogle banned DO Global and more than 100 of its apps from the Google Play Store on 26 April 2019.[111][112] DO Global was also banned from Google's AdMob Network.[111] Apps from another developer, ES Global, including the ES File Explorer, that were owned by DO Global were banned from the Play Store and the account was suspended.[113][114][115][116][117][118][119]\n\nIn August 2020, following the 2020 China–India skirmishes, Baidu was one of several Chinese websites that were banned or blocked in India for national security reasons.[120]\n\nIn May 2024, Baidu's former vice president and head of communications Qu Jing [zh] (Chinese: 璩静) sparked major backlashes across the Chinese social media for endorsing toxic workplace culture, where, according to a Douyin video, she has asked a coworker to be on a 50-day business trip during the COVID-19 pandemic.[121] The report has aroused further discussions amongst Chinese netizens regarding Baidu's corporate governance and internal culture. Qu openly apologized after the incident and has allegedly lost her job. Baidu’s stock price fell 2.17% in Hong Kong following the incident.[122][123]\n\n"}
{"url":"https://en.wikipedia.org/wiki/DeepMind","title":"Google DeepMind","content":"\n\n\nDeepMind Technologies Limited,[1] trading as Google DeepMind or simply DeepMind, is a British-American artificial intelligence research laboratory which serves as a subsidiary of Alphabet Inc. Founded in the UK in 2010, it was acquired by Google in 2014[8] and merged with Google AI's Google Brain division to become Google DeepMind in April 2023. The company is headquartered in London, with research centres in the United States, Canada,[9] France,[10] and Germany.\n\nDeepMind introduced neural Turing machines (neural networks that can access external memory like a conventional Turing machine),[11] resulting in a computer that loosely resembles short-term memory in the human brain.[12][13]\n\nDeepMind has created neural network models to play video games and board games. It made headlines in 2016 after its AlphaGo program beat a human professional Go player Lee Sedol, a world champion, in a five-game match, which was the subject of a documentary film.[14] A more general program, AlphaZero, beat the most powerful programs playing go, chess and shogi (Japanese chess) after a few days of play against itself using reinforcement learning.[15]\n\nIn 2020, DeepMind made significant advances in the problem of protein folding with AlphaFold.[16] In July 2022, it was announced that over 200 million predicted protein structures, representing virtually all known proteins, would be released on the AlphaFold database.[17][18] AlphaFold's database of predictions achieved state of the art records on benchmark tests for protein folding algorithms, although each individual prediction still requires confirmation by experimental tests. AlphaFold3 was released in May 2024, making structural predictions for the interaction of proteins with various molecules. It achieved new standards on various benchmarks, raising the state of the art accuracies from 28 and 52 percent to 65 and 76 percent.\n\nThe start-up was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in November 2010.[2] Hassabis and Legg first met at the Gatsby Computational Neuroscience Unit at University College London (UCL).[19]\n\nDemis Hassabis has said that the start-up began working on artificial intelligence technology by teaching it how to play old games from the seventies and eighties, which are relatively primitive compared to the ones that are available today. Some of those games included Breakout, Pong, and Space Invaders. AI was introduced to one game at a time, without any prior knowledge of its rules. After spending some time on learning the game, AI would eventually become an expert in it. \"The cognitive processes which the AI goes through are said to be very like those of a human who had never seen the game would use to understand and attempt to master it.\"[20] The goal of the founders is to create a general-purpose AI that can be useful and effective for almost anything.\n\nMajor venture capital firms Horizons Ventures and Founders Fund invested in the company,[21] as well as entrepreneurs Scott Banister,[22] Peter Thiel,[23] and Elon Musk.[24] Jaan Tallinn was an early investor and an adviser to the company.[25] On 26 January 2014, Google confirmed its acquisition of DeepMind for a price reportedly ranging between $400 million and $650 million.[26][27][28] and that it had agreed to take over DeepMind Technologies. The sale to Google took place after Facebook reportedly ended negotiations with DeepMind Technologies in 2013.[29] The company was afterwards renamed Google DeepMind and kept that name for about two years.[30]\n\nIn 2014, DeepMind received the \"Company of the Year\" award from Cambridge Computer Laboratory.[31]\n\nIn September 2015, DeepMind and the Royal Free NHS Trust signed their initial information sharing agreement to co-develop a clinical task management app, Streams.[32]\n\nAfter Google's acquisition the company established an artificial intelligence ethics board.[33] The ethics board for AI research remains a mystery, with both Google and DeepMind declining to reveal who sits on the board.[34] DeepMind has opened a new unit called DeepMind Ethics and Society and focused on the ethical and societal questions raised by artificial intelligence featuring prominent philosopher Nick Bostrom as advisor.[35] In October 2017, DeepMind launched a new research team to investigate AI ethics.[36][37]\n\nIn December 2019, co-founder Suleyman announced he would be leaving DeepMind to join Google, working in a policy role.[38] In March 2024, Microsoft appointed him as the EVP and CEO of its newly created consumer AI unit, Microsoft AI.[39]\n\nIn April 2023, DeepMind merged with Google AI's Google Brain division to form Google DeepMind, as part of the company's continued efforts to accelerate work on AI in response to OpenAI's ChatGPT.[40] This marked the end of a years-long struggle from DeepMind executives to secure greater autonomy from Google.[41]\n\nGoogle Research released a paper in 2016 regarding AI safety and avoiding undesirable behaviour during the AI learning process.[42] In 2017 DeepMind released GridWorld, an open-source testbed for evaluating whether an algorithm learns to disable its kill switch or otherwise exhibits certain undesirable behaviours.[43][44]\n\nIn July 2018, researchers from DeepMind trained one of its systems to play the computer game Quake III Arena.[45]\n\nAs of 2020, DeepMind has published over a thousand papers, including thirteen papers that were accepted by Nature or Science.[citation needed] DeepMind received media attention during the AlphaGo period; according to a LexisNexis search, 1842 published news stories mentioned DeepMind in 2016, declining to 1363 in 2019.[46]\n\nUnlike earlier AIs, such as IBM's Deep Blue or Watson, which were developed for a pre-defined purpose and only function within that scope, DeepMind's initial algorithms were intended to be general. They used reinforcement learning, an algorithm that learns from experience using only raw pixels as data input. Their initial approach used deep Q-learning with a convolutional neural network.[30][47] They tested the system on video games, notably early arcade games, such as Space Invaders or Breakout.[47][48] Without altering the code, the same AI was able to play certain games more efficiently than any human ever could.[48]\n\nIn 2013, DeepMind published research on an AI system that surpassed human abilities in games such as Pong, Breakout and Enduro, while surpassing state of the art performance on Seaquest, Beamrider, and Q*bert.[49][50] This work reportedly led to the company's acquisition by Google.[51] DeepMind's AI had been applied to video games made in the 1970s and 1980s; work was ongoing for more complex 3D games such as Quake, which first appeared in the 1990s.[48]\n\nIn 2020, DeepMind published Agent57,[52][53] an AI Agent which surpasses human level performance on all 57 games of the Atari 2600 suite.[54] In July 2022, DeepMind announced the development of DeepNash, a model-free multi-agent reinforcement learning system capable of playing the board game Stratego at the level of a human expert.[55]\n\nIn October 2015, a computer Go program called AlphaGo, developed by DeepMind, beat the European Go champion Fan Hui, a 2 dan (out of 9 dan possible) professional, five to zero.[56] This was the first time an artificial intelligence (AI) defeated a professional Go player.[57] Previously, computers were only known to have played Go at \"amateur\" level.[56][58] Go is considered much more difficult for computers to win compared to other games like chess, due to the much larger number of possibilities, making it prohibitively difficult for traditional AI methods such as brute-force.[56][58]\n\nIn March 2016 it beat Lee Sedol, one of the highest ranked players in the world, with a score of 4 to 1 in a five-game match. In the 2017 Future of Go Summit, AlphaGo won a three-game match with Ke Jie, who had been the world's highest-ranked player for two years.[59][60] In 2017, an improved version, AlphaGo Zero, defeated AlphaGo in a hundred out of a hundred games. Later that year, AlphaZero, a modified version of AlphaGo Zero, gained superhuman abilities at chess and shogi. In 2019, DeepMind released a new model named MuZero that mastered the domains of Go, chess, shogi, and Atari 2600 games without human data, domain knowledge, or known rules.[61][62]\n\nAlphaGo technology was developed based on deep reinforcement learning, making it different from the AI technologies then on the market. The data fed into the AlphaGo algorithm consisted of various moves based on historical tournament data. The number of moves was increased gradually until over 30 million of them were processed. The aim was to have the system mimic the human player, as represented by the input data, and eventually become better. It played against itself and learned from the outcomes; thus, it learned to improve itself over the time and increased its winning rate as a result.[63]\n\nAlphaGo used two deep neural networks: a policy network to evaluate move probabilities and a value network to assess positions. The policy network trained via supervised learning, and was subsequently refined by policy-gradient reinforcement learning. The value network learned to predict winners of games played by the policy network against itself. After training, these networks employed a lookahead Monte Carlo tree search, using the policy network to identify candidate high-probability moves, while the value network (in conjunction with Monte Carlo rollouts using a fast rollout policy) evaluated tree positions.[64]\n\nIn contrast, AlphaGo Zero was trained without being fed data of human-played games. Instead it generated its own data, playing millions of games against itself. It used a single neural network, rather than separate policy and value networks. Its simplified tree search relied upon this neural network to evaluate positions and sample moves. A new reinforcement learning algorithm incorporated lookahead search inside the training loop.[64] AlphaGo Zero employed around 15 people and millions in computing resources.[65] Ultimately, it needed much less computing power than AlphaGo, running on four specialized AI processors (Google TPUs), instead of AlphaGo's 48.[66] It also required less training time, being able to beat its predecessor after just three days, compared with months required for the original AlphaGo.[67] Similarly, AlphaZero also learned via self-play.\n\nResearchers applied MuZero to solve the real world challenge of video compression with a set number of bits with respect to Internet traffic on sites such as YouTube, Twitch, and Google Meet. The goal of MuZero is to optimally compress the video so the quality of the video is maintained with a reduction in data. The final result using MuZero was a 6.28% average reduction in bitrate.[68][69]\n\nIn 2016, Hassabis discussed the game StarCraft as a future challenge, since it requires strategic thinking and handling imperfect information.[70]\n\nIn January 2019, DeepMind introduced AlphaStar, a program playing the real-time strategy game StarCraft II. AlphaStar used reinforcement learning based on replays from human players, and then played against itself to enhance its skills. At the time of the presentation, AlphaStar had knowledge equivalent to 200 years of playing time. It won 10 consecutive matches against two professional players, although it had the unfair advantage of being able to see the entire field, unlike a human player who has to move the camera manually. A preliminary version in which that advantage was fixed lost a subsequent match.[71]\n\nIn July 2019, AlphaStar began playing against random humans on the public 1v1 European multiplayer ladder. Unlike the first iteration of AlphaStar, which played only Protoss v. Protoss, this one played as all of the game's races, and had earlier unfair advantages fixed.[72][73] By October 2019, AlphaStar had reached Grandmaster level on the StarCraft II ladder on all three StarCraft races, becoming the first AI to reach the top league of a widely popular esport without any game restrictions.[74]\n\nIn 2016, DeepMind turned its artificial intelligence to protein folding, a long-standing problem in molecular biology. In December 2018, DeepMind's AlphaFold won the 13th Critical Assessment of Techniques for Protein Structure Prediction (CASP) by successfully predicting the most accurate structure for 25 out of 43 proteins. \"This is a lighthouse project, our first major investment in terms of people and resources into a fundamental, very important, real-world scientific problem,\" Hassabis said to The Guardian.[75] In 2020, in the 14th CASP, AlphaFold's predictions achieved an accuracy score regarded as comparable with lab techniques. Dr Andriy Kryshtafovych, one of the panel of scientific adjudicators, described the achievement as \"truly remarkable\", and said the problem of predicting how proteins fold had been \"largely solved\".[76][77][78]\n\nIn July 2021, the open-source RoseTTAFold and AlphaFold2 were released to allow scientists to run their own versions of the tools. A week later DeepMind announced that AlphaFold had completed its prediction of nearly all human proteins as well as the entire proteomes of 20 other widely studied organisms.[79] The structures were released on the AlphaFold Protein Structure Database. In July 2022, it was announced that the predictions of over 200 million proteins, representing virtually all known proteins, would be released on the AlphaFold database.[17][18]\n\nThe most recent update, AlphaFold3, was released in May 2024, predicting the interactions of proteins with DNA, RNA, and various other molecules. In a particular benchmark test on the problem of DNA interactions, AlphaFold3's attained an accuracy of 65%, significantly improving the previous state of the art of 28%.[80]\n\nIn October 2024, Hassabis and John Jumper received half of the 2024 Nobel Prize in Chemistry jointly for protein structure prediction, citing AlphaFold2 achievement.[81]\n\nIn 2016, DeepMind introduced WaveNet, a text-to-speech system. It was originally too computationally intensive for use in consumer products, but in late 2017 it became ready for use in consumer applications such as Google Assistant.[82][83] In 2018 Google launched a commercial text-to-speech product, Cloud Text-to-Speech, based on WaveNet.[84][85] In 2018, DeepMind introduced a more efficient model called WaveRNN co-developed with Google AI.[86][87] In 2020 WaveNetEQ, a packet loss concealment method based on a WaveRNN architecture, was presented.[88] In 2019, Google started to roll WaveRNN with WavenetEQ out to Google Duo users.[89]\n\nReleased in May 2022, Gato is a polyvalent multimodal model. It was trained on 604 tasks, such as image captioning, dialogue, or stacking blocks. On 450 of these tasks, Gato outperformed human experts at least half of the time, according to DeepMind.[90] Unlike models like MuZero, Gato does not need to be retrained to switch from one task to the other.\n\nSparrow is an artificial intelligence-powered chatbot developed by DeepMind to build safer machine learning systems by using a mix of human feedback and Google search suggestions.[91]\n\nChinchilla is a language model developed by DeepMind.[92]\n\nDeepMind posted a blog post on 28 April 2022 on a single visual language model (VLM) named Flamingo that can accurately describe a picture of something with just a few training images.[93][94]\n\nIn 2022, DeepMind unveiled AlphaCode, an AI-powered coding engine that creates computer programs at a rate comparable to that of an average programmer, with the company testing the system against coding challenges created by Codeforces utilized in human competitive programming competitions.[95] AlphaCode earned a rank equivalent to 54% of the median score on Codeforces after being trained on GitHub data and Codeforce problems and solutions. The program was required to come up with a unique solution and stopped from duplicating answers.\n\nGemini is a multimodal large language model which was released on 6 December 2023.[96] It is the successor of Google's LaMDA and PaLM 2 language models and sought to challenge OpenAI's GPT-4.[97] Gemini comes in 3 sizes: Nano, Pro, and Ultra.[98] Gemini is also the name of the chatbot that integrates Gemini (and which was previously called Bard).[99]\n\nOn 12 December 2024, Google released Gemini 2.0 Flash, the first model in the Gemini 2.0 series. It notably features expanded multimodality, with the ability to also generate images and audio,[100] and is part of Google's broader plans to integrate advanced AI into autonomous agents.[101]\n\nGemma is a family of lightweight, open source large language models which was released on 21 February 2024. It's available in two distinct sizes: a 7 billion parameter model optimized for GPU and TPU usage, and a 2 billion parameter model designed for CPU and on-device applications. Gemma models were trained on up to 6 trillion tokens of text, employing similar architectures, datasets, and training methodologies as the Gemini model family.[102]\n\nIn March 2024, DeepMind introduced Scalable Instructable Multiword Agent, or SIMA, an AI agent capable of understanding and following natural language instructions to complete tasks across various 3D virtual environments. Trained on nine video games from eight studios and four research environments, SIMA demonstrated adaptability to new tasks and settings without requiring access to game source code or APIs. The agent comprises pre-trained computer vision and language models fine-tuned on gaming data, with language being crucial for understanding and completing given tasks as instructed. DeepMind's research aimed to develop more helpful AI agents by translating advanced AI capabilities into real-world actions through a language interface.[103][104]\n\nIn 2024, Google Deepmind published the results of an experiment where they trained two large language models to help identify and present areas of overlap among a few thousand group members they had recruited online using techiques like sortition to get a representative sample of participants. The project is named in honor of Jürgen Habermas.[105][106] In one experiment, the participants rated the summaries by the AI higher than the human moderator 56% of the time.[106]\n\nIn May 2024, a multimodal video generation model called Veo was announced at Google I/O 2024. Google claimed that it could generate 1080p videos beyond a minute long.[8] In December 2024, Google released Veo2, available via VideoFX. It supports 4K resolution video generation, and has an improved understanding of physics.[107]\n\nIn March 2023, DeepMind introduced \"Genie\" (Generative Interactive Environments), an AI model that can generate game-like, action-controllable virtual worlds based on textual descriptions, images, or sketches. Built as an autoregressive latent diffusion model, Genie enables frame-by-frame interactivity without requiring labeled action data for training. Its successor, Genie 2, released in December 2024, expanded these capabilities to generate diverse and interactive 3D environments.[108]\n\nReleased in June 2023, RoboCat is an AI model that can control robotic arms. The model can adapt to new models of robotic arms, and to new types of tasks.[109][110]\n\nDeepMind researchers have applied machine learning models to the sport of football, often referred to as soccer in North America, modelling the behaviour of football players, including the goalkeeper, defenders, and strikers during different scenarios such as penalty kicks. The researchers used heat maps and cluster analysis to organize players based on their tendency to behave a certain way during the game when confronted with a decision on how to score or prevent the other team from scoring. \n\nThe researchers mention that machine learning models could be used to democratize the football industry by automatically selecting interesting video clips of the game that serve as highlights. This can be done by searching videos for certain events, which is possible because video analysis is an established field of machine learning. This is also possible because of extensive sports analytics based on data including annotated passes or shots, sensors that capture data about the players movements many times over the course of a game, and game theory models.[111][112]\n\nGoogle has unveiled a new archaeology document program, named Ithaca after the Greek island in Homer's Odyssey.[113] This deep neural network helps researchers restore the empty text of damaged Greek documents, and to identify their date and geographical origin.[114] The work builds on another text analysis network that DeepMind released in 2019, named Pythia.[114] Ithaca achieves 62% accuracy in restoring damaged texts and 71% location accuracy, and has a dating precision of 30 years.[114] The authors claimed that the use of Ithaca by \"expert historians\" raised the accuracy of their work from 25 to 72 percent.[113] However, Eleanor Dickey noted that this test was actually only made of students, saying that it wasn't clear how helpful Ithaca would be to \"genuinely qualified editors\".[114] \n\nThe team is working on extending the model to other ancient languages, including Demotic, Akkadian, Hebrew, and Mayan.[113]\n\nIn November 2023, Google DeepMind announced an Open Source Graph Network for Materials Exploration (GNoME). The tool proposes millions of materials previously unknown to chemistry, including several hundred thousand stable crystalline structures, of which 736 had been experimentally produced by the Massachusetts Institute of Technology, at the time of the release.[115][116] However, according to Anthony Cheetham, GNoME did not make \"a useful, practical contribution to the experimental materials scientists.\"[117] A review article by Cheetham and Ram Seshadri were unable to identify any \"strikingly novel\" materials found by GNoME, with most being minor variants of already-known materials.[117][118]\n\nIn October 2022, DeepMind released AlphaTensor, which used reinforcement learning techniques similar to those in AlphaGo, to find novel algorithms for matrix multiplication.[119][120] In the special case of multiplying two 4×4 matrices with integer entries, where only the evenness or oddness of the entries is recorded, AlphaTensor found an algorithm requiring only 47 distinct multiplications; the previous optimum, known since 1969, was the more general Strassen algorithm, using 49 multiplications.[121] Computer scientist Josh Alman described AlphaTensor as \"a proof of concept for something that could become a breakthrough,\" while Vassilevska Williams called it \"a little overhyped\"[121] despite also acknowledging its basis in reinforcement learning as \"something completely different\" from previous approaches.[120]\n\nAlphaGeometry is a neuro-symbolic AI that was able to solve 25 out of 30 geometry problems of the International Mathematical Olympiad, a performance comparable to that of a gold medalist.[122]\n\nTraditional geometry programs are symbolic engines that rely exclusively on human-coded rules to generate rigorous proofs, which makes them lack flexibility in unusual situations. AlphaGeometry combines such a symbolic engine with a specialized large language model trained on synthetic data of geometrical proofs. When the symbolic engine doesn't manage to find a formal and rigorous proof on its own, it solicits the large language model, which suggests a geometrical construct to move forward. However, it is unclear how applicable this method is to other domains of mathematics or reasoning, because symbolic engines rely on domain-specific rules and because of the need for synthetic data.[122]\n\nAlphaProof is an AI model, which couples a pre-trained language model with the AlphaZero reinforcement learning algorithm. AlphaZero has previously taught itself how to master games. The pre-trained language model used in this combination is the fine-tuning of a Gemini model to automatically translate natural language problem statements into formal statements, creating a large library of formal problems of varying difficulty. For this purpose, mathematical statements are defined in the formal language Lean. At the 2024 International Mathematical Olympiad, AlphaProof together with an adapted version of AlphaGeometry have reached the same level of solving problems in the combined categories as a silver medalist in that competition for the first time.[123][124]\n\nIn June 2023, Deepmind announced that AlphaDev, which searches for improved computer science algorithms using reinforcement learning, discovered a more efficient way of coding a sorting algorithm and a hashing algorithm. The new sorting algorithm was 70% faster for shorter sequences and 1.7% faster for sequences exceeding 250,000 elements, and the new hashing algorithm was 30% faster in some cases. The sorting algorithm was accepted into the C++ Standard Library sorting algorithms, and was the first change to those algorithms in more than a decade and the first update to involve an algorithm discovered using AI.[125] The hashing algorithm was released to an opensource library.[126] Google estimates that these two algorithms are used trillions of times every day.[127]\n\nAlphaChip is an reinforcement learning-based neural architecture that guides the task of chip placement. DeepMind claimed that the time needed to create chip layouts fell from weeks to hours. Its chip designs were used in every Tensor Processing Unit (TPU) iteration since 2020.[128][129]\n\nGoogle has stated that DeepMind algorithms have greatly increased the efficiency of cooling its data centers by automatically balancing the cost of hardware failures against the cost of cooling.[130] In addition, DeepMind (alongside other Alphabet AI researchers) assists Google Play's personalized app recommendations.[84] DeepMind has also collaborated with the Android team at Google for the creation of two new features which were made available to people with devices running Android Pie, the ninth installment of Google's mobile operating system. These features, Adaptive Battery and Adaptive Brightness, use machine learning to conserve energy and make devices running the operating system easier to use. It is the first time DeepMind has used these techniques on such a small scale, with typical machine learning applications requiring orders of magnitude more computing power.[131]\n\nIn July 2016, a collaboration between DeepMind and Moorfields Eye Hospital was announced to develop AI applications for healthcare.[132] DeepMind would be applied to the analysis of anonymised eye scans, searching for early signs of diseases leading to blindness.\n\nIn August 2016, a research programme with University College London Hospital was announced with the aim of developing an algorithm that can automatically differentiate between healthy and cancerous tissues in head and neck areas.[133]\n\nThere are also projects with the Royal Free London NHS Foundation Trust and Imperial College Healthcare NHS Trust to develop new clinical mobile apps linked to electronic patient records.[134] Staff at the Royal Free Hospital were reported as saying in December 2017 that access to patient data through the app had saved a 'huge amount of time' and made a 'phenomenal' difference to the management of patients with acute kidney injury. Test result data is sent to staff's mobile phones and alerts them to changes in the patient's condition. It also enables staff to see if someone else has responded, and to show patients their results in visual form.[135][unreliable source?]\n\nIn November 2017, DeepMind announced a research partnership with the Cancer Research UK Centre at Imperial College London with the goal of improving breast cancer detection by applying machine learning to mammography.[136] Additionally, in February 2018, DeepMind announced it was working with the U.S. Department of Veterans Affairs in an attempt to use machine learning to predict the onset of acute kidney injury in patients, and also more broadly the general deterioration of patients during a hospital stay so that doctors and nurses can more quickly treat patients in need.[137]\n\nDeepMind developed an app called Streams, which sends alerts to doctors about patients at risk of acute kidney injury.[138] On 13 November 2018, DeepMind announced that its health division and the Streams app would be absorbed into Google Health.[139] Privacy advocates said the announcement betrayed patient trust and appeared to contradict previous statements by DeepMind that patient data would not be connected to Google accounts or services.[140][141] A spokesman for DeepMind said that patient data would still be kept separate from Google services or projects.[142]\n\nIn April 2016, New Scientist obtained a copy of a data sharing agreement between DeepMind and the Royal Free London NHS Foundation Trust. The latter operates three London hospitals where an estimated 1.6 million patients are treated annually. The agreement shows DeepMind Health had access to admissions, discharge and transfer data, accident and emergency, pathology and radiology, and critical care at these hospitals. This included personal details such as whether patients had been diagnosed with HIV, suffered from depression or had ever undergone an abortion in order to conduct research to seek better outcomes in various health conditions.[143][144]\n\nA complaint was filed to the Information Commissioner's Office (ICO), arguing that the data should be pseudonymised and encrypted.[145] In May 2016, New Scientist published a further article claiming that the project had failed to secure approval from the Confidentiality Advisory Group of the Medicines and Healthcare products Regulatory Agency.[146]\n\nIn 2017, the ICO concluded a year-long investigation that focused on how the Royal Free NHS Foundation Trust tested the app, Streams, in late 2015 and 2016.[147] The ICO found that the Royal Free failed to comply with the Data Protection Act when it provided patient details to DeepMind, and found several shortcomings in how the data was handled, including that patients were not adequately informed that their data would be used as part of the test. DeepMind published its thoughts[148] on the investigation in July 2017, saying \"we need to do better\" and highlighting several activities and initiatives they had initiated for transparency, oversight and engagement. This included developing a patient and public involvement strategy[149] and being transparent in its partnerships.\n\nIn May 2017, Sky News published a leaked letter from the National Data Guardian, Dame Fiona Caldicott, revealing that in her \"considered opinion\" the data-sharing agreement between DeepMind and the Royal Free took place on an \"inappropriate legal basis\".[150] The Information Commissioner's Office ruled in July 2017 that the Royal Free hospital failed to comply with the Data Protection Act when it handed over personal data of 1.6 million patients to DeepMind.[151]\n\nIn October 2017, DeepMind announced a new research unit, DeepMind Ethics \u0026 Society.[152] Their goal is to fund external research of the following themes: privacy, transparency, and fairness; economic impacts; governance and accountability; managing AI risk; AI morality and values; and how AI can address the world's challenges. As a result, the team hopes to further understand the ethical implications of AI and aid society to seeing AI can be beneficial.[153]\n\nThis new subdivision of DeepMind is a completely separate unit from the partnership of leading companies using AI, academia, civil society organizations and nonprofits of the name Partnership on Artificial Intelligence to Benefit People and Society of which DeepMind is also a part.[154] The DeepMind Ethics and Society board is also distinct from the mooted AI Ethics Board that Google originally agreed to form when acquiring DeepMind.[155]\n\nDeepMind sponsors three chairs of machine learning:\n\n"}
{"url":"https://en.wikipedia.org/wiki/Nvidia","title":"Nvidia","content":"\n\n\nNvidia Corporation[a] (/ɛnˈvɪdiə/ en-VID-ee-ə) is an American multinational corporation and technology company headquartered in Santa Clara, California, and incorporated in Delaware.[5] Founded in 1993 by Jensen Huang (president and CEO), Chris Malachowsky, and Curtis Priem, it is a software company which designs and supplies graphics processing units (GPUs), application programming interfaces (APIs) for data science and high-performance computing, and system on a chip units (SoCs) for mobile computing and the automotive market. Nvidia is also a leading supplier of artificial intelligence (AI) hardware and software.[6] Nvidia outsources the manufacturing of the hardware it designs.[7]\n\nNvidia's professional line of GPUs are used for edge-to-cloud computing and in supercomputers and workstations for applications in fields such as architecture, engineering and construction, media and entertainment, automotive, scientific research, and manufacturing design.[8] Its GeForce line of GPUs are aimed at the consumer market and are used in applications such as video editing, 3D rendering, and PC gaming. With a market share of 80.2% in the second quarter of 2023,[9] Nvidia leads global sales of discrete desktop GPUs by a wide margin. The company expanded its presence in the gaming industry with the introduction of the Shield Portable (a handheld game console), Shield Tablet (a gaming tablet), and Shield TV (a digital media player), as well as its cloud gaming service GeForce Now.[10]\n\nIn addition to GPU design and outsourcing manufacturing, Nvidia provides the CUDA software platform and API that allows the creation of massively parallel programs which utilize GPUs.[11][12] They are deployed in supercomputing sites around the world.[13][14] In the late 2000s, Nvidia had moved into the mobile computing market, where it produced Tegra mobile processors for smartphones and tablets and vehicle navigation and entertainment systems.[15][16][17] Its competitors include AMD, Intel,[18] Qualcomm,[19] and AI accelerator companies such as Cerebras and Graphcore. It also makes AI-powered software for audio and video processing (e.g., Nvidia Maxine).[20]\n\nNvidia's attempt to acquire Arm from SoftBank in September 2020 failed to materialize following extended regulatory scrutiny, leading to the termination of the deal in February 2022 in what would have been the largest semiconductor acquisition.[21][22] In 2023, Nvidia became the seventh public U.S. company to be valued at over $1 trillion,[23] and the company's valuation has increased rapidly since then amid growing demand for data center chips with AI capabilities in the midst of the AI boom.[24][25] In June 2024, for one day, Nvidia overtook Microsoft as the world's most valuable publicly traded company, with a market capitalization of over $3.3 trillion.[26]\n\nNvidia was founded on April 5, 1993,[27][28][29] by Jensen Huang (who, as of 2025[update], remains CEO), a Taiwanese-American electrical engineer who was previously the director of CoreWare at LSI Logic and a microprocessor designer at AMD; Chris Malachowsky, an engineer who worked at Sun Microsystems; and Curtis Priem, who was previously a senior staff engineer and graphics chip designer at IBM and Sun Microsystems.[30][31] The three men agreed to start the company in a meeting at a Denny's roadside diner on Berryessa Road in East San Jose.[32][33][34]\n\nAt the time, Malachowsky and Priem were frustrated with Sun's management and were looking to leave, but Huang was on \"firmer ground\",[35] in that he was already running his own division at LSI.[33] The three co-founders discussed a vision of the future which was so compelling that Huang decided to leave LSI[35] and become the chief executive officer of their new startup.[33]\n\nIn 1993, the three co-founders envisioned  graphics-based processing as the best trajectory for tackling challenges that had eluded general-purpose computing methods.[35] As Huang later explained: \"We also observed that video games were simultaneously one of the most computationally challenging problems and would have incredibly high sales volume. Those two conditions don’t happen very often. Video games was our killer app — a flywheel to reach large markets funding huge R\u0026D to solve massive computational problems.\"[35] With $40,000 in the bank, the company was born.[35] The company subsequently received $20 million of venture capital funding from Sequoia Capital, Sutter Hill Ventures and others.[36]\n\nDuring the late 1990s, Nvidia was one of 70 startup companies pursuing the idea that graphics acceleration for video games was the path to the future.[32]  Only two survived: Nvidia and ATI Technologies, the latter of which merged into AMD.[32]\n\nNvidia initially had no name and the co-founders named all their files NV, as in \"next version\".[35] The need to incorporate the company prompted the co-founders to review all words with those two letters.[35]  At one point, Malachowsky and Priem wanted to call the company NVision, but that name was already taken by a manufacturer of toilet paper.[33] Huang suggested the name Nvidia,[33] from \"invidia\", the Latin word for \"envy\".[35] The company's original headquarters office was in Sunnyvale, California.[35]\n\nNvidia's first graphics accelerator, the NV1, was designed to process quadrilateral primitives (forward texture mapping), a feature that set it apart from competitors, who preferred triangle primitives.[33] However, when Microsoft introduced the DirectX platform, it chose not to support any other graphics software and announced that its Direct3D API would exclusively support triangles.[33][37] As a result, the NV1 failed to gain traction in the market.[38]\n\nNvidia had also entered into a partnership with Sega to supply the graphics chip for the Dreamcast console and worked on the project for about a year. However, Nvidia's technology was already lagging behind competitors. This placed the company in a difficult position: continue working on a chip that was likely doomed to fail or abandon the project, risking financial collapse.[39]\n\nIn a pivotal moment, Sega's president, Shoichiro Irimajiri, visited Huang in person to inform him that Sega had decided to choose another vendor for the Dreamcast. However, Irimajiri believed in Nvidia's potential and persuaded Sega’s management to invest $5 million into the company. Huang later reflected that this funding was all that kept Nvidia afloat, and that Irimajiri's \"understanding and generosity gave us six months to live\".[39]\n\nIn 1996, Huang laid off more than half of Nvidia's employees—thereby reducing headcount from 100 to 40—and focused the company's remaining resources on developing a graphics accelerator product optimized for processing triangle primitives: the RIVA 128.[33][37]  By the time the RIVA 128 was released in August 1997, Nvidia had only enough money left for one month’s payroll.[33] The sense of impending failure became so pervasive that it gave rise to Nvidia's unofficial company motto: \"Our company is thirty days from going out of business.\"[33] Huang began internal presentations to Nvidia staff with those words for many years.[33]\n\nNvidia sold about a million RIVA 128 units within four months,[33] and used the revenue to fund development of its next generation of products.[37] In 1998, the release of the RIVA TNT helped solidify Nvidia’s reputation as a leader in graphics technology.[40]\n\nNvidia went public on January 22, 1999.[41][42][43]  Investing in Nvidia after it had already failed to deliver on its contract turned out to be Irimajiri's best decision as Sega's president. After Irimajiri left Sega in 2000, Sega sold its Nvidia stock for $15 million.[39]\n\nIn late 1999, Nvidia released the GeForce 256 (NV10), its first product expressly marketed as a GPU, which was most notable for introducing onboard transformation and lighting (T\u0026L) to consumer-level 3D hardware. Running at 120 MHz and featuring four-pixel pipelines, it implemented advanced video acceleration, motion compensation, and hardware sub-picture alpha blending. The GeForce outperformed existing products by a wide margin.\n\nDue to the success of its products, Nvidia won the contract to develop the graphics hardware for Microsoft's Xbox game console, which earned Nvidia a $200 million advance. However, the project took many of its best engineers away from other projects. In the short term this did not matter, and the GeForce2 GTS shipped in the summer of 2000. In December 2000, Nvidia reached an agreement to acquire the intellectual assets of its one-time rival 3dfx, a pioneer in consumer 3D graphics technology leading the field from the mid-1990s until 2000.[44][45] The acquisition process was finalized in April 2002.[46]\n\nIn 2001, Standard \u0026 Poor's selected Nvidia to replace the departing Enron in the S\u0026P 500 stock index, meaning that index funds would need to hold Nvidia shares going forward.[47]\n\nIn July 2002, Nvidia acquired Exluna for an undisclosed sum. Exluna made software-rendering tools and the personnel were merged into the Cg project.[48] In August 2003, Nvidia acquired MediaQ for approximately US$70 million.[49] It launched GoForce the follow year. On April 22, 2004, Nvidia acquired iReady, also a provider of high-performance TCP offload engines and iSCSI controllers.[50] In December 2004, it was announced that Nvidia would assist Sony with the design of the graphics processor (RSX) for the PlayStation 3 game console. On December 14, 2005, Nvidia acquired ULI Electronics, which at the time supplied third-party southbridge parts for chipsets to ATI, Nvidia's competitor.[51] In March 2006, Nvidia acquired Hybrid Graphics.[52] In December 2006, Nvidia, along with its main rival in the graphics industry AMD (which had acquired ATI), received subpoenas from the U.S. Department of Justice regarding possible antitrust violations in the graphics card industry.[53]\n\nForbes named Nvidia its Company of the Year for 2007, citing the accomplishments it made during the said period as well as during the previous five years.[54] On January 5, 2007, Nvidia announced that it had completed the acquisition of PortalPlayer, Inc.[55] In February 2008, Nvidia acquired Ageia, developer of PhysX, a physics engine and physics processing unit. Nvidia announced that it planned to integrate the PhysX technology into its future GPU products.[56][57]\n\nIn July 2008, Nvidia took a write-down of approximately $200 million on its first-quarter revenue, after reporting that certain mobile chipsets and GPUs produced by the company had \"abnormal failure rates\" due to manufacturing defects. Nvidia, however, did not reveal the affected products. In September 2008, Nvidia became the subject of a class action lawsuit over the defects, claiming that the faulty GPUs had been incorporated into certain laptop models manufactured by Apple Inc., Dell, and HP. In September 2010, Nvidia reached a settlement, in which it would reimburse owners of the affected laptops for repairs or, in some cases, replacement.[58][59] On January 10, 2011, Nvidia signed a six-year, $1.5 billion cross-licensing agreement with Intel, ending all litigation between the two companies.[60]\n\nIn November 2011, after initially unveiling it at Mobile World Congress, Nvidia released its ARM-based system on a chip for mobile devices, Tegra 3. Nvidia claimed that the chip featured the first-ever quad-core mobile CPU.[61][62] In May 2011, it was announced that Nvidia had agreed to acquire Icera, a baseband chip making company in the UK, for $367 million.[63] In January 2013, Nvidia unveiled the Tegra 4, as well as the Nvidia Shield, an Android-based handheld game console powered by the new system on a chip.[64] On July 29, 2013, Nvidia announced that they acquired PGI from STMicroelectronics.[65]\n\nIn February 2013, Nvidia announced its plans to build a new headquarters in the form of two giant triangle-shaped buildings on the other side of San Tomas Expressway (to the west of its existing headquarters complex). The company selected triangles as its design theme. As Huang explained in a blog post, the triangle is \"the fundamental building block of computer graphics\".[66]\n\nIn 2014, Nvidia ported the Valve games Portal and Half Life 2 to its Nvidia Shield tablet as Lightspeed Studio.[67][68] Since 2014, Nvidia has diversified its business focusing on three markets: gaming, automotive electronics, and mobile devices.[69]\n\nThat same year, Nvidia also prevailed in litigation brought by the trustee of 3dfx's bankruptcy estate to challenge its 2000 acquisition of 3dfx's intellectual assets. On November 6, 2014, in an unpublished memorandum order, the U.S. Court of Appeals for the Ninth Circuit affirmed the \"district court's judgment affirming the bankruptcy court's determination that [Nvidia] did not pay less than fair market value for assets purchased from 3dfx shortly before 3dfx filed for bankruptcy\".[70]\n\nOn May 6, 2016, Nvidia unveiled the first GPUs of the GeForce 10 series, the GTX 1080 and 1070, based on the company's new Pascal microarchitecture. Nvidia claimed that both models outperformed its Maxwell-based Titan X model; the models incorporate GDDR5X and GDDR5 memory respectively, and use a 16 nm manufacturing process. The architecture also supports a new hardware feature known as simultaneous multi-projection (SMP), which is designed to improve the quality of multi-monitor and virtual reality rendering.[71][72][73] Laptops that include these GPUs and are sufficiently thin – as of late 2017, under 0.8 inches (20 mm) – have been designated as meeting Nvidia's \"Max-Q\" design standard.[74]\n\nIn July 2016, Nvidia agreed to a settlement for a false advertising lawsuit regarding its GTX 970 model, as the models were unable to use all of their advertised 4 GB of VRAM due to limitations brought by the design of its hardware.[75] In May 2017, Nvidia announced a partnership with Toyota which would use Nvidia's Drive PX-series artificial intelligence platform for its autonomous vehicles.[76] In July 2017, Nvidia and Chinese search giant Baidu announced a far-reaching AI partnership that includes cloud computing, autonomous driving, consumer devices, and Baidu's open-source AI framework PaddlePaddle. Baidu unveiled that Nvidia's Drive PX 2 AI will be the foundation of its autonomous-vehicle platform.[77]\n\nNvidia officially released the Titan V on December 7, 2017.[78][79]\n\nNvidia officially released the Nvidia Quadro GV100 on March 27, 2018.[80] Nvidia officially released the RTX 2080 GPUs on September 27, 2018. In 2018, Google announced that Nvidia's Tesla P4 graphic cards would be integrated into Google Cloud service's artificial intelligence.[81]\n\nIn May 2018, on the Nvidia user forum, a thread was started[82] asking the company to update users when they would release web drivers for its cards installed on legacy Mac Pro machines up to mid-2012 5,1 running the macOS Mojave operating system 10.14. Web drivers are required to enable graphics acceleration and multiple display monitor capabilities of the GPU. On its Mojave update info website, Apple stated that macOS Mojave would run on legacy machines with 'Metal compatible' graphics cards[83] and listed Metal compatible GPUs, including some manufactured by Nvidia.[84] However, this list did not include Metal compatible cards that currently work in macOS High Sierra using Nvidia-developed web drivers. In September, Nvidia responded, \"Apple fully controls drivers for macOS. But if Apple allows, our engineers are ready and eager to help Apple deliver great drivers for macOS 10.14 (Mojave).\"[85] In October, Nvidia followed this up with another public announcement, \"Apple fully controls drivers for macOS. Unfortunately, Nvidia currently cannot release a driver unless it is approved by Apple,\"[86] suggesting a possible rift between the two companies.[87] By January 2019, with still no sign of the enabling web drivers, Apple Insider weighed into the controversy with a claim that Apple management \"doesn't want Nvidia support in macOS\".[88] The following month, Apple Insider followed this up with another claim that Nvidia support was abandoned because of \"relational issues in the past\",[89] and that Apple was developing its own GPU technology.[90] Without Apple-approved Nvidia web drivers, Apple users are faced with replacing their Nvidia cards with a competing supported brand, such as AMD Radeon from the list recommended by Apple.[91]\n\nOn March 11, 2019, Nvidia announced a deal to buy Mellanox Technologies for $6.9 billion[92] to substantially expand its footprint in the high-performance computing market. In May 2019, Nvidia announced new RTX Studio laptops. The creators say that the new laptop is going to be seven times faster than a top-end MacBook Pro with a Core i9 and AMD's Radeon Pro Vega 20 graphics in apps like Maya and RedCine-X Pro.[93] In August 2019, Nvidia announced Minecraft RTX, an official Nvidia-developed patch for the game Minecraft adding real-time DXR ray tracing exclusively to the Windows 10 version of the game. The whole game is, in Nvidia's words, \"refit\" with path tracing, which dramatically affects the way light, reflections, and shadows work inside the engine.[94]\n\nIn May 2020, Nvidia announced it was acquiring Cumulus Networks.[95] Post acquisition the company was absorbed into Nvidia's networking business unit, along with Mellanox.\n\nIn May 2020, Nvidia's developed an open-source ventilator to address the shortage resulting from the global coronavirus pandemic.[96] On May 14, 2020, Nvidia officially announced their Ampere GPU microarchitecture and the Nvidia A100 GPU accelerator.[97][98] In July 2020, it was reported that Nvidia was in talks with SoftBank to buy Arm, a UK-based chip designer, for $32 billion.[99]\n\nOn September 1, 2020, Nvidia officially announced the GeForce 30 series based on the company's new Ampere microarchitecture.[100][101]\n\nOn September 13, 2020, Nvidia announced that they would buy Arm from SoftBank Group for $40 billion, subject to the usual scrutiny, with the latter retaining a 10% share of Nvidia.[102][103][104][105]\n\nIn October 2020, Nvidia announced its plan to build the most powerful computer in Cambridge, England. The computer, called Cambridge-1, launched in July 2021 with a $100 million investment and will employ AI to support healthcare research.[106][107] According to Jensen Huang, \"The Cambridge-1 supercomputer will serve as a hub of innovation for the UK, and further the groundbreaking work being done by the nation's researchers in critical healthcare and drug discovery.\"[108]\n\nAlso in October 2020, along with the release of the Nvidia RTX A6000, Nvidia announced it is retiring its workstation GPU brand Quadro, shifting its product name to Nvidia RTX for future products and the manufacturing to be Nvidia Ampere architecture-based.[8]\n\nIn August 2021, the proposed takeover of Arm was stalled after the UK's Competition and Markets Authority raised \"significant competition concerns\".[109] In October 2021, the European Commission opened a competition investigation into the takeover. The Commission stated that Nvidia's acquisition could restrict competitors' access to Arm's products and provide Nvidia with too much internal information on its competitors due to their deals with Arm. SoftBank (the parent company of Arm) and Nvidia announced in early February 2022 that they \"had agreed not to move forward with the transaction 'because of significant regulatory challenges'\".[110] The investigation is set to end on March 15, 2022.[111][112] That same month, Nvidia was reportedly compromised by a cyberattack.[113]\n\nIn March 2022, Nvidia's CEO Jensen Huang mentioned that they are open to having Intel manufacture their chips in the future.[114] This was the first time the company mentioned that they would work together with Intel's upcoming foundry services.\n\nIn April 2022, it was reported that Nvidia planned to open a new research center in Yerevan, Armenia.[115]\n\nIn May 2022, Nvidia opened Voyager, the second of the two giant buildings at its new headquarters complex to the west of the old one. Unlike its smaller and older sibling Endeavor, the triangle theming is used more \"sparingly\" in Voyager.[116][117]\n\nIn September 2022, Nvidia announced its next-generation automotive-grade chip, Drive Thor.[118][119]\n\nIn September 2022, Nvidia announced a collaboration with the Broad Institute of MIT and Harvard related to the entire suite of Nvidia's AI-powered healthcare software suite called Clara, that includes Parabricks and MONAI.[120] \n\nFollowing U.S. Department of Commerce regulations which placed an embargo on exports to China of advanced microchips, which went into effect in October 2022, Nvidia saw its data center chip added to the export control list. The next month, the company unveiled a new advanced chip in China, called the A800 GPU, that met the export control rules.[121]\n\nIn September 2023, Getty Images announced that it was partnering with Nvidia to launch Generative AI by Getty Images, a new tool that lets people create images using Getty's library of licensed photos. Getty will use Nvidia's Edify model, which is available on Nvidia's generative AI model library Picasso.[122]\n\nOn September 26, 2023, Denny's CEO Kelli Valade joined Huang in East San Jose to celebrate the founding of Nvidia at Denny's on Berryessa Road, where a plaque was installed to mark the relevant corner booth as the birthplace of a $1 trillion company.[33][123] By then, Nvidia's H100 GPUs were in such demand that even other tech giants were beholden to how Nvidia allocated supply. Larry Ellison of Oracle Corporation said that month that during a dinner with Huang at Nobu in Palo Alto, he and Elon Musk of Tesla, Inc. and xAI \"were begging\" for H100s, \"I guess is the best way to describe it. An hour of sushi and begging\".[124]\n\nIn October 2023, it was reported that Nvidia had quietly begun designing ARM-based central processing units (CPUs) for Microsoft's Windows operating system with a target to start selling them in 2025.[125]\n\nIn January 2024, Forbes reported that Nvidia has increased its lobbying presence in Washington, D.C. as American lawmakers consider proposals to regulate artificial intelligence. From 2023 to 2024, the company reportedly hired at least four government affairs with professional backgrounds at agencies including the United States Department of State and the Department of the Treasury. It was noted that the $350,000 spent by the company on lobbying in 2023 was small compared to a number of major tech companies in the artificial intelligence space.[126]\n\nAs of January 2024, Raymond James Financial analysts estimated that Nvidia was selling the H100 GPU in the price range of $25,000 to $30,000 each, while on eBay, individual H100s cost over $40,000.[127] Tech giants were purchasing tens or hundreds of thousands of GPUs for their data centers to run generative artificial intelligence projects; simple arithmetic implied that they were committing to billions of dollars in capital expenditures.[127]\n\nIn February 2024, it was reported that Nvidia was the \"hot employer\" in Silicon Valley because it was offering interesting work and good pay at a time when other tech employers were downsizing. Half of Nvidia employees earned over $228,000 in 2023.[128] By then, Nvidia GPUs had become so valuable that they needed special security while in transit to data centers. Cisco chief information officer Fletcher Previn explained at a CIO summit: \"Those GPUs arrive by armored car\".[129]\n\nOn March 1, 2024, Nvidia became the third company in the history of the United States to close with a market capitalization in excess of $2 trillion.[47] Nvidia needed only 180 days to get to $2 trillion from $1 trillion, while the first two companies, Apple and Microsoft, each took over 500 days.[47] On March 18, Nvidia announced its new AI chip and microarchitecture Blackwell, named after mathematician David Blackwell.[130]\n\nIn April 2024, Reuters reported that China had allegedly acquired banned Nvidia chips and servers from Supermicro and Dell via tenders.[131]\n\nIn June 2024, the Federal Trade Commission (FTC) and the Justice Department (DOJ) began antitrust investigations into Nvidia, Microsoft and OpenAI, focusing on their influence in the AI industry. The FTC led the investigations into Microsoft and OpenAI, while the DOJ handled Nvidia. The probes centered on the companies' conduct rather than mergers. This development followed an open letter from OpenAI employees expressing concerns about the rapid AI advancements and lack of oversight.[132]\n\nThe company became the world's most valuable, surpassing Microsoft and Apple, on June 18, 2024, after its market capitalization exceeded $3.3 trillion.[133][134]\n\nIn June 2024, Trend Micro announced a partnership with Nvidia to develop AI-driven security tools, notably to protect the data centers where AI workloads are processed. This collaboration integrates Nvidia NIM and Nvidia Morpheus with Trend Vision One and its Sovereign and Private Cloud solutions to improve data privacy, real-time analysis, and rapid threat mitigation.[135]\n\nNvidia introduced a family of open-source multimodal large language models in October 2024 called NVLM 1.0, which features a flagship version with 72 billion parameters, designed to improve text-only performance after multimodal training.[136][137]\n\nIn November 2024, the company was added to the Dow Jones Industrial Average.[138][139]\n\nIn November 2024, Morgan Stanley reported that \"the entire 2025 production\" of all of Nvidia's Blackwell chips was \"already sold out\".[140]\n\nAlso in November 2024, the company made an investment in Nebius Group.[141][142]\n\nNvidia was ranked #3 on Forbes' \"Best Places to Work\" list in 2024.[143]\n\nIn January 2025, Nvidia saw the largest one-day loss in market capitalization for a U.S. company in history at $600 billion. This was due to DeepSeek, a Chinese AI startup that developed an advanced AI model at a lower cost and computing power. DeepSeek's AI assistant, using the V3 model, surpassed ChatGPT as the highest-rated free app in the U.S. on Apple's App Store.[144][145]\n\nNvidia uses external suppliers for all phases of manufacturing, including wafer fabrication, assembly, testing, and packaging. Nvidia thus avoids most of the investment and production costs and risks associated with chip manufacturing, although it does sometimes directly procure some components and materials used in the production of its products (e.g., memory and substrates). Nvidia focuses its own resources on product design, quality assurance, marketing, and customer support.[146][147]\n\nNvidia's key management as of March 2024 consists of:[149]\n\nAs of November 2024[update], the company's board consisted of the following directors:[150]\n\nFor the fiscal year 2020, Nvidia reported earnings of US$2.796 billion, with an annual revenue of US$10.918 billion, a decline of 6.8% over the previous fiscal cycle. Nvidia's shares traded at over $531 per share, and its market capitalization was valued at over US$328.7 billion in January 2021. As of late Q3 2024, Nvidia's market cap is around US$2.98 trillion.[151][152]\n\nFor the Q2 of 2020, Nvidia reported sales of $3.87 billion, which was a 50% rise from the same period in 2019. The surge in sales and people's higher demand for computer technology. According to the financial chief of the company, Colette Kress, the effects of the pandemic will \"likely reflect this evolution in enterprise workforce trends with a greater focus on technologies, such as Nvidia laptops and virtual workstations, that enable remote work and virtual collaboration.\"[153] In May 2023, Nvidia crossed $1 trillion in market valuation during trading hours,[154] and grew to $1.2 trillion by the following November.[155] For its strength, size and market capitalization, Nvidia has been selected to be one of Bloomberg's \"Magnificent Seven\", the seven biggest companies on the stock market in these regards.\n\nThe 10 largest shareholders of Nvidia in early 2024 were:[148]\n\nNvidia's GPU Technology Conference (GTC) is a series of technical conferences held around the world.[156] It originated in 2009 in San Jose, California, with an initial focus on the potential for solving computing challenges through GPUs.[157] In recent years, the conference's focus has shifted to various applications of artificial intelligence and deep learning; including self-driving cars, healthcare, high-performance computing, and Nvidia Deep Learning Institute (DLI) training.[158] GTC 2018 attracted over 8400 attendees.[156] GTC 2020 was converted to a digital event and drew roughly 59,000 registrants.[159] After several years of remote-only events, GTC in March 2024 returned to an in-person format in San Jose, California.[160]\n\nNvidia's product families include graphics processing units, wireless communication devices, and automotive hardware and software, such as:\n\nUntil September 23, 2013, Nvidia had not published any documentation for its advanced hardware,[168] meaning that programmers could not write free and open-source device driver for its products without resorting to reverse engineering.\n\nInstead, Nvidia provides its own binary GeForce graphics drivers for X.Org and an open-source library that interfaces with the Linux, FreeBSD or Solaris kernels and the proprietary graphics software. Nvidia also provided but stopped supporting an obfuscated open-source driver that only supports two-dimensional hardware acceleration and ships with the X.Org distribution.[169]\n\nThe proprietary nature of Nvidia's drivers has generated dissatisfaction within free-software communities. In a 2012 talk, Linus Torvalds, in criticism of Nvidia's approach towards Linux, raised the finger and stated \"Nvidia, fuck you.\"[170][171] Some Linux and BSD users insist on using only open-source drivers and regard Nvidia's insistence on providing nothing more than a binary-only driver as inadequate, given that competing manufacturers such as Intel offer support and documentation for open-source developers and that others (like AMD) release partial documentation and provide some active development.[172][173]\n\nNvidia only provides x86/x64 and ARMv7-A versions of their proprietary driver; as a result, features like CUDA are unavailable on other platforms.[174] Some users claim that Nvidia's Linux drivers impose artificial restrictions, like limiting the number of monitors that can be used at the same time, but the company has not commented on these accusations.[175]\n\nIn 2014, with Maxwell GPUs, Nvidia started to require firmware by them to unlock all features of its graphics cards.[176][177][178]\n\nOn May 12, 2022, Nvidia announced that they are opensourcing their GPU kernel modules.[179][180][181] Support for Nvidia's firmware was implemented in nouveau in 2023, which allows proper power management and GPU reclocking for Turing and newer graphics card generations.[182][183]\n\nNvidia GPUs are used in deep learning, and accelerated analytics due to Nvidia's CUDA software platform and API which allows programmers to utilize the higher number of cores present in GPUs to parallelize BLAS operations which are extensively used in machine learning algorithms.[12] They were included in many Tesla, Inc. vehicles before Musk announced at Tesla Autonomy Day in 2019 that the company developed its own SoC and full self-driving computer now and would stop using Nvidia hardware for their vehicles.[184][185] These GPUs are used by researchers, laboratories, tech companies and enterprise companies.[186] In 2009, Nvidia was involved in what was called the \"big bang\" of deep learning, \"as deep-learning neural networks were combined with Nvidia graphics processing units (GPUs)\".[187] That year, the Google Brain team used Nvidia GPUs to create deep neural networks capable of machine learning, where Andrew Ng determined that GPUs could increase the speed of deep learning systems by about 100 times.[188]\n\nDGX is a line of supercomputers by Nvidia.\n\nIn April 2016, Nvidia produced the DGX-1 based on an 8 GPU cluster, to improve the ability of users to use deep learning by combining GPUs with integrated deep learning software.[189] Nvidia gifted its first DGX-1 to OpenAI in August 2016 to help it train larger and more complex AI models with the capability of reducing processing time from six days to two hours.[190][191] It also developed Nvidia Tesla K80 and P100 GPU-based virtual machines, which are available through Google Cloud, which Google installed in November 2016.[192] Microsoft added GPU servers in a preview offering of its N series based on Nvidia's Tesla K80s, each containing 4992 processing cores. Later that year, AWS's P2 instance was produced using up to 16 Nvidia Tesla K80 GPUs. That month Nvidia also partnered with IBM to create a software kit that boosts the AI capabilities of Watson,[193] called IBM PowerAI.[194][195] Nvidia also offers its own Nvidia Deep Learning software development kit.[196] In 2017, the GPUs were also brought online at the Riken Center for Advanced Intelligence Project for Fujitsu.[197] The company's deep learning technology led to a boost in its 2017 earnings.[198]\n\nIn May 2018, researchers at the artificial intelligence department of Nvidia realized the possibility that a robot can learn to perform a job simply by observing the person doing the same job. They have created a system that, after a short revision and testing, can already be used to control the universal robots of the next generation. In addition to GPU manufacturing, Nvidia provides parallel processing capabilities to researchers and scientists that allow them to efficiently run high-performance applications.[199]\n\nIn 2020, Nvidia unveiled \"Omniverse\", a virtual environment designed for engineers.[200] Nvidia also open-sourced Isaac Sim, which makes use of this Omniverse to train robots through simulations that mimic the physics of the robots and the real world.[201][202]\n\nIn 2024, Huang oriented Nvidia's focus towards humanoid robots and self-driving cars, which he expects to gain widespread adoption.[203][204]\n\nNvidia's Inception Program was created to support startups making exceptional advances in the fields of artificial intelligence and data science. Award winners are announced at Nvidia's GTC Conference. In May 2017, the program had 1,300 companies.[205] As of March 2018, there were 2,800 startups in the Inception Program.[206] As of August 2021, the program has surpassed 8,500 members in 90 countries, with cumulative funding of US$60 billion.[207]\n\nIssues with the GeForce GTX 970's specifications were first brought up by users when they found out that the cards, while featuring 4 GB of memory, rarely accessed memory over the 3.5 GB boundary. Further testing and investigation eventually led to Nvidia issuing a statement that the card's initially announced specifications had been altered without notice before the card was made commercially available, and that the card took a performance hit once memory over the 3.5 GB limit were put into use.[208][209][210]\n\nThe card's back-end hardware specifications, initially announced as being identical to those of the GeForce GTX 980, differed in the amount of L2 cache (1.75 MB versus 2 MB in the GeForce GTX 980) and the number of ROPs (56 versus 64 in the 980). Additionally, it was revealed that the card was designed to access its memory as a 3.5 GB section, plus a 0.5 GB one, access to the latter being 7 times slower than the first one.[211] The company then went on to promise a specific driver modification to alleviate the performance issues produced by the cutbacks suffered by the card.[212] However, Nvidia later clarified that the promise had been a miscommunication and there would be no specific driver update for the GTX 970.[213] Nvidia claimed that it would assist customers who wanted refunds in obtaining them.[214] On February 26, 2015, Nvidia CEO Jen-Hsun Huang went on record in Nvidia's official blog to apologize for the incident.[215] In February 2015 a class-action lawsuit alleging false advertising was filed against Nvidia and Gigabyte Technology in the U.S. District Court for Northern California.[216][217]\n\nNvidia revealed that it is able to disable individual units, each containing 256 KB of L2 cache and 8 ROPs, without disabling whole memory controllers.[218] This comes at the cost of dividing the memory bus into high speed and low speed segments that cannot be accessed at the same time unless one segment is reading while the other segment is writing because the L2/ROP unit managing both of the GDDR5 controllers shares the read return channel and the write data bus between the two GDDR5 controllers and itself.[218] This is used in the GeForce GTX 970, which therefore can be described as having 3.5 GB in its high speed segment on a 224-bit bus and 0.5 GB in a low speed segment on a 32-bit bus.[218]\n\nOn July 27, 2016, Nvidia agreed to a preliminary settlement of the U.S. class action lawsuit,[216] offering a $30 refund on GTX 970 purchases. The agreed upon refund represents the portion of the cost of the storage and performance capabilities the consumers assumed they were obtaining when they purchased the card.[219]\n\nThe Nvidia GeForce Partner Program was a marketing program designed to provide partnering companies with benefits such as public relations support, video game bundling, and marketing development funds.[220] The program proved to be controversial, with complaints about it possibly being an anti-competitive practice.[221]\n\nFirst announced in a blog post on March 1, 2018,[222] it was canceled on May 4, 2018.[223]\n\nOn December 10, 2020, Nvidia told YouTube tech reviewer Steven Walton of Hardware Unboxed that it would no longer supply him with GeForce Founders Edition graphics card review units.[224][225] In a Twitter message, Hardware Unboxed said, \"Nvidia have officially decided to ban us from receiving GeForce Founders Edition GPU review samples. Their reasoning is that we are focusing on rasterization instead of ray tracing. They have said they will revisit this 'should your editorial direction change.'\"[226]\n\n\nIn emails that were disclosed by Walton from Nvidia Senior PR Manager Bryan Del Rizzo, Nvidia had said:\n...your GPU reviews and recommendations have continued to focus singularly on rasterization performance, and you have largely discounted all of the other technologies we offer gamers. It is very clear from your community commentary that you do not see things the same way that we, gamers, and the rest of the industry do.[227]\nTechSpot, partner site of Hardware Unboxed, said, \"this and other related incidents raise serious questions around journalistic independence and what they are expecting of reviewers when they are sent products for an unbiased opinion.\"[227]\n\nA number of technology reviewers came out strongly against Nvidia's move.[228][229] Linus Sebastian, of Linus Tech Tips, titled the episode of his weekly WAN Show, \"NVIDIA might ACTUALLY be EVIL...\"[230] and was highly critical of the company's move to dictate specific outcomes of technology reviews.[231] The review site Gamers Nexus said it was, \"Nvidia's latest decision to shoot both its feet: They've now made it so that any reviewers covering RT will become subject to scrutiny from untrusting viewers who will suspect subversion by the company. Shortsighted self-own from NVIDIA.\"[232]\n\nTwo days later, Nvidia reversed their stance.[233][234] Hardware Unboxed sent out a Twitter message, \"I just received an email from Nvidia apologizing for the previous email \u0026 they've now walked everything back.\"[235][228] On December 14, Hardware Unboxed released a video explaining the controversy from their viewpoint.[236] Via Twitter, they also shared a second apology sent by Nvidia's Del Rizzo that said \"to withhold samples because I didn't agree with your commentary is simply inexcusable and crossed the line.\"[237][238]\n\nIn 2018, Nvidia's chips became popular for cryptomining, the process of obtaining crypto rewards in exchange for verifying transactions on distributed ledgers, the U.S. Securities and Exchange Commission (SEC) said. However, the company failed to disclose that it was a \"significant element\" of its revenue growth from sales of chips designed for gaming, the SEC further added in a statement and charging order. Those omissions misled investors and analysts who were interested in understanding the impact of cryptomining on Nvidia's business, the SEC emphasized. Nvidia, which did not admit or deny the findings, has agreed to pay $5.5 million to settle civil charges, according to a statement made by the SEC in May 2022.[239]\n\n"}
{"url":"https://en.wikipedia.org/wiki/Amazon_(company)","title":"Amazon (company)","content":"\n\n\nAmazon.com, Inc.,[1] doing business as Amazon (/ˈæməzɒn/ ⓘ, AM-ə-zon; .mw-parser-output .IPA-label-small{font-size:85%}.mw-parser-output .references .IPA-label-small,.mw-parser-output .infobox .IPA-label-small,.mw-parser-output .navbox .IPA-label-small{font-size:100%}UK also /ˈæməzən/, AM-ə-zən), is an American multinational technology company engaged in e-commerce, cloud computing, online advertising, digital streaming, and artificial intelligence.[5] Founded in 1994 by Jeff Bezos in Bellevue, Washington,[6] the company originally started as an online marketplace for books but gradually expanded its offerings to include a wide range of product categories, referred to as \"The Everything Store\".[7] Today, Amazon is considered one of the Big Five American technology companies, the other four being Alphabet,[a] Apple, Meta,[b] and Microsoft.\n\nThe company has multiple subsidiaries, including Amazon Web Services, providing cloud computing; Zoox, a self-driving car division; Kuiper Systems, a satellite Internet provider; and Amazon Lab126, a computer hardware R\u0026D provider. Other subsidiaries include Ring, Twitch, IMDb, and Whole Foods Market. Its acquisition of Whole Foods in August 2017 for US$13.4 billion substantially increased its market share and presence as a physical retailer.[8] Amazon also distributes a variety of downloadable and streaming content through its Amazon Prime Video, MGM+, Amazon Music, Twitch, Audible and Wondery[9] units. It publishes books through its publishing arm, Amazon Publishing, film and television content through Amazon MGM Studios, including the Metro-Goldwyn-Mayer studio, which was acquired in March 2022, and owns Brilliance Audio and Audible, which produce and distribute audiobooks, respectively. Amazon also produces consumer electronics—most notably, Kindle e-readers, Echo devices, Fire tablets, and Fire TVs.\n\nAmazon has a reputation as a disruptor of industries through technological innovation and aggressive reinvestment of profits into capital expenditures.[10][11][12][13] As of 2023[update], it is the world's largest online retailer and marketplace, smart speaker provider, cloud computing service through AWS,[14] live-streaming service through Twitch, and Internet company as measured by revenue and market share.[15] In 2021, it surpassed Walmart as the world's largest retailer outside of China, driven in large part by its paid subscription plan, Amazon Prime, which has close to 200 million subscribers worldwide.[16][17] It is the second-largest private employer in the United States[18] and the second-largest company in the World and in the U.S. by revenue as of 2024 (after Walmart).[19] As of October 2024, Amazon is the 12th-most visited website in the world and 84% of its traffic comes from the United States.[20][21] Amazon is also the global leader in research and development spending, with R\u0026D expenditure of US$73 billion in 2022.[22] Amazon has been criticized on various grounds, including but not limited to customer data collection practices, a toxic work culture, censorship, tax avoidance, and anti-competitive practices. \n\nAmazon was founded on July 5, 1994, by Jeff Bezos after he relocated from New York City to Bellevue, Washington, near Seattle, to operate an online bookstore. Bezos chose the Seattle area for its abundance of technical talent from Microsoft and the University of Washington, as well as its smaller population for sales tax purposes and the proximity to a major book distribution warehouse in Roseburg, Oregon. Bezos also considered several other options, including Portland, Oregon, and Boulder, Colorado.[23] The company, originally named Cadabra, was founded in the converted garage of Bezos's house for symbolic reasons and was renamed to Amazon in November 1994.[24] The Amazon website launched for public sales on July 16, 1995, and initially sourced its books directly from wholesalers and publishers.[23][25]\n\nAmazon went public in May 1997. It began selling music and videos in 1998, and began international operations by acquiring online sellers of books in the United Kingdom and Germany. In the subsequent year, it initiated the sale of a diverse range of products, including music, video games, consumer electronics, home improvement items, software, games, and toys.[26][27]\n\nIn 2002, it launched Amazon Web Services (AWS), which initially focused on providing APIs for web developers to build web applications on top of Amazon's ecommerce platform.[28][29] In 2004, AWS was expanded to provide website popularity statistics and web crawler data from the Alexa Web Information Service.[30] AWS later shifted toward providing enterprise services with Simple Storage Service (S3) in 2006,[31] and Elastic Compute Cloud (EC2) in 2008,[32] allowing companies to rent data storage and computing power from Amazon. In 2006, Amazon also launched the Fulfillment by Amazon program, which allowed individuals and small companies (called \"third-party sellers\") to sell products through Amazon's warehouses and fulfillment infrastructure.[33]\n\nAmazon purchased the Whole Foods Market supermarket chain in 2017.[34] It is the leading e-retailer in the United States with approximately US$178 billion net sales in 2017. It has over 300 million active customer accounts globally.[35] \n\nAmazon saw large growth during the COVID-19 pandemic, hiring more than 100,000 staff in the United States and Canada.[36] Some Amazon workers in the US, France, and Italy protested the company's decision to \"run normal shifts\" due to COVID-19's ease of spread in warehouses.[37][38] In Spain, the company faced legal complaints over its policies,[39] while a group of US Senators wrote an open letter to Bezos expressing concerns about workplace safety.[40]\n\nOn February 2, 2021, Bezos announced that he would step down as CEO to become executive chair of Amazon's board. The transition officially took place on July 5, 2021, with former CEO of AWS Andy Jassy replacing him as CEO.[41][42] In January 2023, Amazon cut over 18,000 jobs, primarily in consumer retail and its human resources division in an attempt to cut costs.[43]\n\nOn November 8, 2023, a plan was adopted for Jeff Bezos to sell approximately 50 million shares of the company over the next year (the deadline for the entire sales plan is January 31, 2025). The first step was the sale of 12 million shares for about $2 billion.[44]\n\nOn February 26, 2024, Amazon became a component of the Dow Jones Industrial Average.[45]\n\nOn December 19, 2024, Amazon workers, led by the International Brotherhood of Teamsters labor union, went on strike against Amazon in at least four US states, with workers in other facilities in the United States being welcomed to join the strike as well.[46][47]\n\nAmazon.com is an e-commerce platform that sells many product lines, including media (books, movies, music, and software), apparel, baby products, consumer electronics, beauty products, gourmet food, groceries, health and personal care products, industrial \u0026 scientific supplies, kitchen items, jewelry, watches, lawn and garden items, musical instruments, sporting goods, tools, automotive items, toys and games, and farm supplies[49] and consulting services.[50] Amazon websites are country-specific (for example, amazon.com for the US and amazon.co.uk for UK) though some offer international shipping.[51]\n\nVisits to amazon.com grew from 615 million annual visitors in 2008,[52] to more than 2 billion per month in 2022.[citation needed] The e-commerce platform is the 12th most visited website in the world.[21]\n\nIn February 2024, Amazon announced its first chatbot was first “Rufus” in the US and in July, it was widely available to all customers in the US.[53]\n\n“Rufus” is now available in the US, India and the UK which helps the shoppers get product recommendations, get shopping list advice, compare products and see what other customers have responded to their specific questions.[54]\n\nResults generated by Amazon's search engine are partly determined by promotional fees.[55] The company's localized storefronts, which differ in selection and prices, are differentiated by top-level domain and country code:\n\nIn 2000, US toy retailer Toys \"R\" Us entered into a 10-year agreement with Amazon, valued at $50 million per year plus a cut of sales, under which Toys \"R\" Us would be the exclusive supplier of toys and baby products on the service, and the chain's website would redirect to Amazon's Toys \u0026 Games category. In 2004, Toys \"R\" Us sued Amazon, claiming that because of a perceived lack of variety in Toys \"R\" Us stock, Amazon had knowingly allowed third-party sellers to offer items on the service in categories that Toys \"R\" Us had been granted exclusivity. In 2006, a court ruled in favor of Toys \"R\" Us, giving it the right to unwind its agreement with Amazon and establish its independent e-commerce website. The company was later awarded $51 million in damages.[66][67][68]\n\nIn 2001, Amazon entered into a similar agreement with Borders, under which Amazon would comanage Borders.com as a co-branded service.[69] Borders pulled out of the arrangement in 2007, with plans to also launch its own online store.[70]\n\nOn October 18, 2011, Amazon.com announced a partnership with DC Comics for the exclusive digital rights to many popular comics, including Superman, Batman, Green Lantern, Sandman, and Watchmen. The partnership has caused well-known bookstores like Barnes \u0026 Noble to remove these titles from their shelves.[71]\n\nIn November 2013, Amazon announced a partnership with the United States Postal Service to begin delivering orders on Sundays. The service, included in Amazon's standard shipping rates, initiated in metropolitan areas of Greater Los Angeles and New York because of the high-volume and inability to deliver in a timely way, with plans to expand into Dallas, Houston, New Orleans and Phoenix by 2014.[72]\n\nIn June 2017, Nike agreed to sell products through Amazon in exchange for better policing of counterfeit goods.[73][74] This proved unsuccessful and Nike withdrew from the partnership in November 2019.[74][75] Companies including IKEA and Birkenstock also stopped selling through Amazon around the same time, citing similar frustrations over business practices and counterfeit goods.[76]\n\nIn September 2017, Amazon ventured with one of its sellers JV Appario Retail owned by Patni Group which has recorded a total income of US$104.44 million (₹759 crore) in financial year 2017–2018.[77]\n\nAs of October 11, 2017[update], Amazon Fresh sold a range of Booths branded products for home delivery in selected areas.[78]\n\nIn November 2018, Amazon reached an agreement with Apple Inc. to sell selected products through the service, via the company and selected Apple Authorized Resellers. As a result of this partnership, only Apple Authorized Resellers may sell Apple products on Amazon effective January 4, 2019.[79][80]\n\nOn November 7, 2024, Amazon is reportedly discussing a second multi-billion dollar investment in AI startup Anthropic, following its initial $4 billion investment.[81]\n\nAmazon sells many products under its own brand names, including phone chargers, batteries, and diaper wipes. The AmazonBasics brand was introduced in 2009, and now features hundreds of product lines, including smartphone cases, computer mice, batteries, dumbbells, and dog crates. Amazon owned 34 private-label brands as of 2019. These brands account for 0.15% of Amazon's global sales, whereas the average for other large retailers is 18%.[82] Other Amazon retail brands include Presto!, Mama Bear, and Amazon Essentials.[83]\n\nAmazon derives many of its sales (around 40% in 2008) from third-party sellers who sell products on Amazon.[84] Some other large e-commerce sellers use Amazon to sell their products in addition to selling them through their websites. The sales are processed through Amazon.com and end up at individual sellers for processing and order fulfillment and Amazon leases space for these retailers. Small sellers of used and new goods go to Amazon Marketplace to offer goods at a fixed price.[85]\n\nPublishers can sign up as affiliates and receive a commission for referring customers to Amazon by placing links to Amazon on their websites if the referral results in a sale. Worldwide, Amazon has \"over 900,000 members\" in its affiliate programs.[86] In the middle of 2014, the Amazon Affiliate Program is used by 1.2% of all websites and it is the second most popular advertising network after Google Ads.[87] It is frequently used by websites and non-profits to provide a way for supporters to earn them a commission.[88]\n\nAssociates can access the Amazon catalog directly on their websites by using the Amazon Web Services (AWS) XML service. A new affiliate product, aStore, allows Associates to embed a subset of Amazon products within another website, or linked to another website. In June 2010, Amazon Seller Product Suggestions was launched to provide more transparency to sellers by recommending specific products to third-party sellers to sell on Amazon. Products suggested are based on customers' browsing history.[89]\n\nAmazon allows users to submit reviews to the web page of each product. Reviewers must rate the product on a rating scale from one to five stars. Amazon provides a badging option for reviewers which indicates the real name of the reviewer (based on confirmation of a credit card account) or which indicates that the reviewer is one of the top reviewers by popularity. As of December 16, 2020, Amazon removed the ability of sellers and customers to comment on product reviews and purged their websites of all posted product review comments. In an email to sellers, Amazon gave its rationale for removing this feature: \"...the comments feature on customer reviews was rarely used.\" The remaining review response options are to indicate whether the reader finds the review helpful or to report that it violates Amazon policies (abuse). If a review is given enough \"helpful\" hits, it appears on the front page of the product. In 2010, Amazon was reported as being the largest single source of Internet consumer reviews.[90]\n\nWhen publishers asked Bezos why Amazon would publish negative reviews, he defended the practice by claiming that Amazon.com was \"taking a different approach...we want to make every book available—the good, the bad and the ugly...to let truth loose\".[91]\n\nThere have been cases of positive reviews being written and posted by public relations companies on behalf of their clients[92] and instances of writers using pseudonyms to leave negative reviews of their rivals' works.\n\nThe Amazon sales rank (ASR) indicates the popularity of a product sold on any Amazon locale. It is a relative indicator of popularity that is updated hourly. Effectively, it is a \"best sellers list\" for the millions of products stocked by Amazon.[93] While the ASR has no direct effect on the sales of a product, it is used by Amazon to determine which products to include in its bestsellers lists.[93] Products that appear in these lists enjoy additional exposure on the Amazon website and this may lead to an increase in sales. In particular, products that experience large jumps (up or down) in their sales ranks may be included within Amazon's lists of \"movers and shakers\"; such a listing provides additional exposure that might lead to an increase in sales.[94] For competitive reasons, Amazon does not release actual sales figures to the public. However, Amazon has now begun to release point of sale data via the BookScan service to verified authors.[95] While the ASR has been the source of much speculation by publishers, manufacturers, and marketers, Amazon itself does not release the details of its sales rank calculation algorithm. Some companies have analyzed Amazon sales data to generate sales estimates based on the ASR,[96] though Amazon states:\n\nPlease keep in mind that our sales rank figures are simply meant to be a guide of general interest for the customer and not definitive sales information for publishers—we assume you have this information regularly from your distribution sources\nIn November 2015, Amazon opened a physical Amazon Books store in University Village in Seattle. The store was 5,500 square feet and prices for all products matched those on its website.[98] Amazon opened its tenth physical bookstore in 2017;[99] media speculation at the time suggested that Amazon planned to eventually roll out 300 to 400 bookstores around the country.[98] All of its locations were closed in 2022 along with other retail locations under the \"Amazon 4-Star\" brand.[100]\n\nIn July 2016, the company announced that it was opening a 1,100,000 ft (335,280.0 m) square foot facility in Palmer Township in the Lehigh Valley region of eastern Pennsylvania. As of 2024, Amazon is Lehigh Valley region's third-largest employer.[101][102]\n\nIn August 2019, Amazon applied to have a liquor store in San Francisco, as a means to ship beer and alcohol within the city.[103]\n\nIn 2020, Amazon Fresh opened several physical stores in the US and the United Kingdom.[104]\n\nAmazon has a number of products and services available, including its digital assistant Alexa, Amazon Music, and Prime Video for music and videos respectively, the Amazon Appstore for Android apps, the Kindle line of electronic paper e-readers, Fire and Fire HD color LCD tablets. Audible provides audiobooks for purchase and listening.\n\nIn September 2021, Amazon announced the launch of Astro, its first household robot, powered by its Alexa smart home technology. This can be remote-controlled when not at home, to check on pets, people, or home security. It will send owners a notification if it detects something unusual.[105]\n\nIn January 2023, Amazon announced the launch of RXPass, a prescription drug delivery service. It allows U.S. Amazon Prime members to pay a $5 monthly fee for access to 60 medications. The service was launched immediately after the announcement except in states with specific prescription delivery requirements. Beneficiaries of government healthcare programs such as Medicare and Medicaid will not be able to sign up for RXPass.[106]\n\nAmazon owns over 100 subsidiaries, including Amazon Web Services, Audible, Diapers.com, Goodreads, IMDb, Kiva Systems (now Amazon Robotics), One Medical, Shopbop, Teachstreet, Twitch, Zappos, and Zoox.[107]\n\nBezos separately owns The Washington Post (through Nash Holdings, LLC), Blue Origin, Bezos Expeditions, Altos Labs, and other companies.\n\nAmazon Live is an American video e-commerce live-streaming service created by Amazon Inc. to compete with live-streaming services. The service allows users to stream live videos promoting or sponsoring products.[108] Users (mainly celebrities or Internet influencers) have the option to livestream on Amazon and add tags to additionally add context to the products they're selling or promoting. Other users can join in and type in messages to send to a global chat on the livestream.[108]\n\nIn 2019 Amazon launched an integrated platform into the Amazon website and application. In 2023 roughly a billion total viewers watch Amazon Live across the United States and India. The platform has also been integrated into Amazon Freevee and Amazon Prime Video.[109]\n\nAmazon Web Services (AWS) is a subsidiary of Amazon that provides on-demand cloud computing platforms and APIs to individuals, companies, and governments, on a metered pay-as-you-go basis. These cloud computing web services provide distributed computing processing capacity and software tools via AWS server farms. As of 2021 Q4, AWS has 33% market share for cloud infrastructure while the next two competitors Microsoft Azure and Google Cloud have 21%, and 10% respectively, according to Synergy Group.[110]\n\nAudible is a seller and producer of spoken audio entertainment, information, and educational programming on the Internet. Audible sells digital audiobooks, radio and television programs, and audio versions of magazines and newspapers. Through its production arm, Audible Studios, Audible has also become the world's largest producer of downloadable audiobooks. On January 31, 2008, Amazon announced it would buy Audible for about $300 million. The deal closed in March 2008 and Audible became a subsidiary of Amazon.[111]\n\nGoodreads is a \"social cataloging\" website founded in December 2006 and launched in January 2007 by Otis Chandler, a software engineer, and entrepreneur, and Elizabeth Khuri. The website allows individuals to freely search Goodreads' extensive user-populated database of books, annotations, and reviews. Users can sign up and register books to generate library catalogs and reading lists. They can also create their groups of book suggestions and discussions. In December 2007, the site had over 650,000 members, and over a million books had been added. Amazon bought the company in March 2013.[112]\n\nRing is a home automation company founded by Jamie Siminoff in 2013. It is primarily known for its Wi-Fi powered smart doorbells, but manufactures other devices such as security cameras. Amazon bought Ring for US$1 billion in 2018.[113]\n\nTwitch is a live streaming platform for video, primarily oriented towards video gaming content. Twitch was acquired by Amazon in August 2014 for $970 million.[114] The site's rapid growth had been boosted primarily by the prominence of major esports competitions on the service, leading GameSpot senior esports editor Rod Breslau to have described the service as \"the ESPN of esports\".[115] As of 2015[update], the service had over 1.5 million broadcasters and 100 million monthly viewers.[116]\n\nWhole Foods Market is an American supermarket chain exclusively featuring foods without artificial preservatives, colors, flavors, sweeteners, and hydrogenated fats.[117] Amazon acquired Whole Foods for $13.7 billion in August 2017.[118][119][8]\n\nSince acquiring Whole Foods, the company has launched its own chain of Fresh supermarkets and taken steps to integrate its online and physical grocery operations.\n\nOther Amazon subsidiaries include:\n\nAmazon also has investments in renewable energy, including plans to fund four small nuclear reactors at the Xe-100 reactor site in Eastern Washington, and plans to expand its position into the Canadian market through an investment in a new plant in Alberta.[151]\n\nAmazon uses many different transportation services to deliver packages. Amazon-branded services include:\n\nAmazon directly employs people to work at its warehouses, bulk distribution centers, staffed \"Amazon Hub Locker+\" locations, and delivery stations where drivers pick up packages. As of December 2020, it is not hiring delivery drivers as employees.[154]\n\nRakuten Intelligence estimated that in 2020 in the United States, the proportion of last-mile deliveries was 56% by Amazon's directly contracted services (mostly in urban areas), 30% by the United States Postal Service (mostly in rural areas), and 14% by UPS.[155] In April 2021, Amazon reported to investors it had increased its in-house delivery capacity by 50% in the last 12 months (which included the first year of the COVID-19 pandemic in the United States).[156]\n\nAmazon first launched its distribution network in 1997 with two fulfillment centers in Seattle and New Castle, Delaware. Amazon has several types of distribution facilities consisting of cross-dock centers, fulfillment centers, sortation centers, delivery stations, Prime now hubs, and Prime air hubs. There are 75 fulfillment centers and 25 sortation centers with over 125,000 employees.[157][158] Employees are responsible for five basic tasks: unpacking and inspecting incoming goods; placing goods in storage and recording their location; picking goods from their computer recorded locations to make up an individual shipment; sorting and packing orders; and shipping. A computer that records the location of goods and maps out routes for pickers plays a key role: employees carry hand-held computers which communicate with the central computer and monitor their rate of progress. Some warehouses are partially automated with systems built by Amazon Robotics.[159]\n\nIn September 2006, Amazon launched a program called FBA (Fulfillment By Amazon) whereby it could handle storage, packing and distribution of products and services for small sellers.[33]\n\nAs of June 2022[update], Amazon's board of directors were:[160]\n\nThe 10 largest shareholder of Amazon in early 2024 were:[56]\n\nAmazon.com is primarily a retail site with a sales revenue model; Amazon takes a small percentage of the sale price of each item that is sold through its website while also allowing companies to advertise their products by paying to be listed as featured products.[161] As of 2018[update], Amazon.com is ranked eighth on the Fortune 500 rankings of the largest United States corporations by total revenue.[162] In Forbes Global 2000 2023 Amazon ranked 36th.[163]\n\nFor the fiscal year 2021, Amazon reported earnings of US$33.36 billion, with an annual revenue of US$469.82 billion, an increase of 21.7% over the previous fiscal cycle. Since 2007 sales increased from 14.835 billion to 469.822 billion, due to continued business expansion.[citation needed]\n\nAmazon's market capitalization went over US$1 trillion again in early February 2020 after the announcement of the fourth quarter 2019 results.[164]\n\nDuring his tenure, Jeff Bezos had become renowned for his annual shareholder letters, which have gained similar notability to those of Warren Buffett.[184] These annual letters gave an \"invaluable window\" into the famously \"secretive\" company, and revealed Bezos's perspectives and strategic focus.[184][185] A common theme of these letters is Bezos's desire to instill customer-centricity (in his words, \"customer obsession\") at all levels of Amazon, notably by making all senior executives field customer support queries for a short time at Amazon call centers. He also read many emails addressed by customers to his public email address.[186] One of Bezos's most well-known internal memos was his mandate for \"all teams\" to \"expose their data and functionality\" through service interfaces \"designed from the ground up to be externalizable\". This process, commonly known as a service-oriented architecture (SOA), resulted in mandatory dogfooding of services that would later be commercialized as part of AWS.[citation needed]\n\nAmazon lobbies the United States federal government and state governments on multiple issues such as the enforcement of sales taxes on online sales, transportation safety, privacy and data protection and intellectual property. According to regulatory filings, Amazon.com focuses its lobbying on the United States Congress, the Federal Communications Commission and the Federal Reserve. Amazon.com spent roughly $3.5 million, $5 million and $9.5 million on lobbying, in 2013, 2014 and 2015, respectively.[187] In 2019, it spent $16.8 million and had a team of 104 lobbyists.[188]\n\nAmazon.com was a corporate member of the American Legislative Exchange Council (ALEC) until it dropped membership following protests at its shareholders' meeting on May 24, 2012.[189]\n\nIn 2014, Amazon expanded its lobbying practices as it prepared to lobby the Federal Aviation Administration to approve its drone delivery program, hiring the Akin Gump Strauss Hauer \u0026 Feld lobbying firm in June.[190] Amazon and its lobbyists have visited with Federal Aviation Administration officials and aviation committees in Washington, D.C. to explain its plans to deliver packages.[191] In September 2020 this moved one step closer with the granting of a critical certificate by the FAA.[192]\n\nAmazon has attracted criticism for its actions, including: supplying law enforcement with facial recognition surveillance tools;[193] forming cloud computing partnerships with the CIA;[194] leading customers away from bookshops;[195] adversely impacting the environment;[196] placing a low priority on warehouse conditions for workers;[197][198] actively opposing unionization efforts;[199] remotely deleting content purchased by Amazon Kindle users; taking public subsidies; seeking to patent its 1-Click technology; engaging in anti-competitive actions and price discrimination;[200][201] and reclassifying LGBTQ books as adult content.[202][203] Criticism has also concerned various decisions over whether to censor or publish content such as the WikiLeaks website, works containing libel, anti-LGBT merchandise, and material facilitating dog fighting, cockfighting, or pedophile activities. An article published by Time in the wake of social media website Parler's termination of service by Amazon Web Service highlights the power companies like Amazon now have over the internet.[204] In December 2011, Amazon faced a backlash from small businesses for running a one-day deal to promote its new Price Check app. Shoppers who used the app to check prices in a brick-and-mortar store were offered a 5% discount to purchase the same item from Amazon.[205] Companies like Groupon, eBay and Taap have countered Amazon's promotion by offering $10 off from their products.[206][207]\n\nThe company has also faced accusations of putting undue pressure on suppliers to maintain and extend its profitability. One effort to squeeze the most vulnerable book publishers was known within the company as the Gazelle Project, after Bezos suggested, according to Brad Stone, \"that Amazon should approach these small publishers the way a cheetah would pursue a sickly gazelle.\"[55] In July 2014, the Federal Trade Commission launched a lawsuit against the company alleging it was promoting in-app purchases to children, which were being transacted without parental consent.[208] In 2019, Amazon banned selling skin-lightening products after pushback from Minnesota health and environmental activists.[209] In 2022, a lawsuit filed by state attorney-general Letitia James was dismissed by the New York state court of appeals.[210] After the COVID-19 pandemic, Amazon faced criticism for complying, under pressure from the Biden Administration, to \"reduce the visibility” of books critical of the COVID-19 vaccine,[211][212] which was revealed after Rep. Jim Jordan (acting on behalf of the House Judiciary Committee) subpoenaed emails between the company and the Biden Administration.[213]\n\nAmazon Prime has been criticized for its vehicles systemically double parking, blocking bike lanes, and otherwise violating traffic laws while dropping off packages, contributing to traffic congestion and endangering other road users.[214][215][216][217]\n\nJane Friedman[218] discovered six listings of books fraudulently using her name, on Amazon and Goodreads. Amazon and Goodreads resisted removing the fraudulent titles until the author's complaints went viral on social media, in a blog post titled \"I Would Rather See My Books Get Pirated Than This (Or: Why Goodreads and Amazon Are Becoming Dumpster Fires).\"[219][220][221][222]\n\nIn 2024, following years of criticism for providing law enforcement footage in the custody of Ring (a home security company owned by Amazon) without a warrant, Ring has halted this practice.[223] It received cautious praise from privacy-focused organizations such as the Electronic Frontier Foundation for this change.[223]\n\n"}
{"url":"https://en.wikipedia.org/wiki/OpenAI","title":"OpenAI","content":"\n\n\nOpenAI, Inc. is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".[5] As a leading organization in the ongoing AI boom,[6] OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora.[7][8] Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI.\n\nThe organization consists of the non-profit OpenAI, Inc.,[9] registered in Delaware, and its for-profit subsidiary introduced in 2019, OpenAI Global, LLC.[10] Its stated mission is to ensure that AGI \"benefits all of humanity\".[11] Microsoft owns roughly 49% of OpenAI's equity, having invested US$13 billion.[12] It also provides computing resources to OpenAI through its cloud platform, Microsoft Azure.[13]\n\nIn 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI's products. In November 2023, OpenAI's board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company's prominent role in an industry-wide problem.[14][15]\n\nIn December 2015, OpenAI was founded by Sam Altman, Elon Musk, Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk as the co-chairs. A total of $1 billion in capital was pledged by Sam Altman, Greg Brockman, Elon Musk, Reid Hoffman, Jessica Livingston, Peter Thiel, Amazon Web Services (AWS), Infosys, and YC Research.[16][17] The actual collected total amount of contributions was only $130 million until 2019.[10] According to an investigation led by TechCrunch, while YC Research never contributed any funds, Open Philanthropy contributed $30 million and another $15 million in verifiable donations were traced back to Musk.[18] OpenAI later stated that Musk's contributions totaled less than $45 million.[19] The organization stated it would \"freely collaborate\" with other institutions and researchers by making its patents and research open to the public.[20][21] OpenAI was initially run from Brockman's living room.[22] It was later headquartered at the Pioneer Building in the Mission District, San Francisco.[23][24]\n\nAccording to Wired, Brockman met with Yoshua Bengio, one of the \"founding fathers\" of deep learning, and drew up a list of the \"best researchers in the field\".[25] Brockman was able to hire nine of them as the first employees in December 2015.[25] In 2016, OpenAI paid corporate-level (rather than nonprofit-level) salaries, but did not pay AI researchers salaries comparable to those of Facebook or Google.[25]\n\nMicrosoft's Peter Lee stated that the cost of a top AI researcher exceeds the cost of a top NFL quarterback prospect.[25] OpenAI's potential and mission drew these researchers to the firm; a Google employee said he was willing to leave Google for OpenAI \"partly because of the very strong group of people and, to a very large extent, because of its mission.\"[25] Brockman stated that \"the best thing that I could imagine doing was moving humanity closer to building real AI in a safe way.\"[25] OpenAI co-founder Wojciech Zaremba stated that he turned down \"borderline crazy\" offers of two to three times his market value to join OpenAI instead.[25]\n\nIn April 2016, OpenAI released a public beta of \"OpenAI Gym\", its platform for reinforcement learning research.[26] Nvidia gifted its first DGX-1 supercomputer to OpenAI in August 2016 to help it train larger and more complex AI models with the capability of reducing processing time from six days to two hours.[27][28] In December 2016, OpenAI released \"Universe\", a software platform for measuring and training an AI's general intelligence across the world's supply of games, websites, and other applications.[29][30][31][32]\n\nIn 2017, OpenAI spent $7.9 million, or a quarter of its functional expenses, on cloud computing alone.[33] In comparison, DeepMind's total expenses in 2017 were $442 million. In the summer of 2018, simply training OpenAI's Dota 2 bots required renting 128,000 CPUs and 256 GPUs from Google for multiple weeks.\n\nIn 2018, Musk resigned from his Board of Directors seat, citing \"a potential future conflict [of interest]\" with his role as CEO of Tesla due to Tesla's AI development for self-driving cars.[34] Sam Altman claims that Musk believed that OpenAI had fallen behind other players like Google and Musk proposed instead to take over OpenAI himself, which the board rejected. Musk subsequently left OpenAI.\n\nIn February 2019, GPT-2 was announced, which gained attention for its ability to generate human-like text.[35]\n\nIn 2019, OpenAI transitioned from non-profit to \"capped\" for-profit, with the profit being capped at 100 times any investment.[36] According to OpenAI, the capped-profit model allows OpenAI Global, LLC to legally attract investment from venture funds and, in addition, to grant employees stakes in the company.[37] Many top researchers work for Google Brain, DeepMind, or Facebook, which offer stock options that a nonprofit would be unable to.[38] Before the transition, public disclosure of the compensation of top employees at OpenAI was legally required.[39]\n\nThe company then distributed equity to its employees and partnered with Microsoft,[40] announcing an investment package of $1 billion into the company. Since then, OpenAI systems have run on an Azure-based supercomputing platform from Microsoft.[41][42][43]\n\nOpenAI Global, LLC then announced its intention to commercially license its technologies.[44] It planned to spend the $1 billion \"within five years, and possibly much faster\".[45] Altman has stated that even a billion dollars may turn out to be insufficient, and that the lab may ultimately need \"more capital than any non-profit has ever raised\" to achieve artificial general intelligence.[46]\n\nThe transition from a nonprofit to a capped-profit company was viewed with skepticism by Oren Etzioni of the nonprofit Allen Institute for AI, who agreed that wooing top researchers to a nonprofit is difficult, but stated \"I disagree with the notion that a nonprofit can't compete\" and pointed to successful low-budget projects by OpenAI and others. \"If bigger and better funded was always better, then IBM would still be number one.\"\n\nThe nonprofit, OpenAI, Inc., is the sole controlling shareholder of OpenAI Global, LLC, which, despite being a for-profit company, retains a formal fiduciary responsibility to OpenAI, Inc.'s nonprofit charter. A majority of OpenAI, Inc.'s board is barred from having financial stakes in OpenAI Global, LLC.[37] In addition, minority members with a stake in OpenAI Global, LLC are barred from certain votes due to conflict of interest.[38] Some researchers have argued that OpenAI Global, LLC's switch to for-profit status is inconsistent with OpenAI's claims to be \"democratizing\" AI.[47]\n\nIn 2020, OpenAI announced GPT-3, a language model trained on large internet datasets. GPT-3 is aimed at natural language answering questions, but it can also translate between languages and coherently generate improvised text. It also announced that an associated API, named simply \"the API\", would form the heart of its first commercial product.[48]\n\nEleven employees left OpenAI, mostly between December 2020 and January 2021, in order to establish Anthropic.[49]\n\nIn 2021, OpenAI introduced DALL-E, a specialized deep learning model adept at generating complex digital images from textual descriptions, utilizing a variant of the GPT-3 architecture.[50]\n\nIn December 2022, OpenAI received widespread media coverage after launching a free preview of ChatGPT, its new AI chatbot based on GPT-3.5. According to OpenAI, the preview received over a million signups within the first five days.[52] According to anonymous sources cited by Reuters in December 2022, OpenAI Global, LLC was projecting $200 million of revenue in 2023 and $1 billion in revenue in 2024.[53]\n\nIn January 2023, OpenAI Global, LLC was in talks for funding that would value the company at $29 billion, double its 2021 value.[54] On January 23, 2023, Microsoft announced a new US$10 billion investment in OpenAI Global, LLC over multiple years, partially needed to use Microsoft's cloud-computing service Azure.[55][56] Rumors of this deal suggested that Microsoft may receive 75% of OpenAI's profits until it secures its investment return and a 49% stake in the company.[57] The investment is believed to be a part of Microsoft's efforts to integrate OpenAI's ChatGPT into the Bing search engine. Google announced a similar AI application (Bard), after ChatGPT was launched, fearing that ChatGPT could threaten Google's place as a go-to source for information.[58][59]\n\nOn February 7, 2023, Microsoft announced that it was building AI technology based on the same foundation as ChatGPT into Microsoft Bing, Edge, Microsoft 365 and other products.[60]\n\nOn March 3, 2023, Reid Hoffman resigned from his board seat, citing a desire to avoid conflicts of interest with his investments in AI companies via Greylock Partners, and his co-founding of the AI startup Inflection AI. Hoffman remained on the board of Microsoft, a major investor in OpenAI.[61]\n\nOn March 14, 2023, OpenAI released GPT-4, both as an API (with a waitlist) and as a feature of ChatGPT Plus.[62]\n\nOn May 22, 2023, Sam Altman, Greg Brockman and Ilya Sutskever posted recommendations for the governance of superintelligence.[63] They consider that superintelligence could happen within the next 10 years, allowing a \"dramatically more prosperous future\" and that \"given the possibility of existential risk, we can't just be reactive\". They propose creating an international watchdog organization similar to IAEA to oversee AI systems above a certain capability threshold, suggesting that relatively weak AI systems on the other side should not be overly regulated. They also call for more technical safety research for superintelligences, and ask for more coordination, for example through governments launching a joint project which \"many current efforts become part of\".[63][64]\n\nIn July 2023, OpenAI launched the superalignment project, aiming to find within 4 years how to align future superintelligences by automating alignment research using AI.[65]\n\nIn August 2023, it was announced that OpenAI had acquired the New York-based start-up Global Illumination, a company that deploys AI to develop digital infrastructure and creative tools.[66]\n\nOn September 21, 2023, Microsoft had begun rebranding all variants of its Copilot to Microsoft Copilot, including the former Bing Chat and the Microsoft 365 Copilot.[67] This strategy was followed in December 2023 by adding the MS-Copilot to many installations of Windows 11 and Windows 10 as well as a standalone Microsoft Copilot app released for Android[68] and one released for iOS thereafter.[69]\n\nIn October 2023, Sam Altman and Peng Xiao, CEO of the Emirati AI firm G42, announced Open AI would let G42 deploy Open AI technology.[70]\n\nOn November 6, 2023, OpenAI launched GPTs, allowing individuals to create customized versions of ChatGPT for specific purposes, further expanding the possibilities of AI applications across various industries.[71] On November 14, 2023, OpenAI announced they temporarily suspended new sign-ups for ChatGPT Plus due to high demand.[72] Access for newer subscribers re-opened a month later on December 13.[73]\n\nIn January 2024, OpenAI announced a partnership with Arizona State University that would give it complete access to ChatGPT Enterprise. It was OpenAI's first partnership with an educational institution.[74] In February, the U.S. Securities and Exchange Commission was reportedly investigating OpenAI over whether company communications made by Altman were used to mislead investors; and an investigation of Altman's statements, opened by the Southern New York U.S. Attorney's Office was ongoing.[75][76]\n\nOn February 15, 2024, OpenAI announced a text-to-video model named Sora, which it plans to release to the public at an unspecified date.[77] It is available for red teams for managing critical harms and risks.[78]\n\nOn February 29, 2024, OpenAI and CEO Sam Altman were sued by Elon Musk, who accused them of prioritizing profits over public good, contrary to OpenAI's original mission[10] of developing AI for humanity's benefit.[79] The lawsuit cited OpenAI's policy shift after partnering with Microsoft, questioning its open-source commitment and stirring the AI ethics-vs.-profit debate.[80] OpenAI stated that \"Elon understood the mission did not imply open-sourcing AGI.\"[81] It denied being a de facto Microsoft subsidiary.[82] On March 11, in a court filing, OpenAI said it was \"doing just fine without Elon Musk\" after he left in 2018. They responded to Musk's lawsuit, calling his claims \"incoherent\", \"frivolous\", \"extraordinary\" and \"a fiction\".[83] In June, Musk unexpectedly withdrew the lawsuit,[84] but in August reopened it against Altman and others, alleging Altman claimed OpenAI was going to be founded as a non-profit.[85][86]\n\nOn May 15, 2024, Ilya Sutskever resigned and was replaced with Jakub Pachocki [pl] to be the Chief Scientist.[87] Jan Leike, the other co-leader of the superalignment team, announced his departure, citing an erosion of safety and trust in OpenAI's leadership.[88] The departures, along with researchers leaving, led OpenAI to absorb the team's work into other research areas, and shut down the superalignment group.[89] According to sources interviewed by Fortune, OpenAI's promise of allocating 20% of its computing capabilities to the superalignment project had not been fulfilled.[90]\n\nOn May 19, 2024, Reddit and OpenAI announced a partnership to integrate Reddit's content into OpenAI products, including ChatGPT. This allows OpenAI to access Reddit's Data API, providing real-time, structured content to enhance AI tools and user engagement with Reddit communities. Reddit plans to develop new AI-powered features for users and moderators using OpenAI's platform. The partnership aligns with Reddit's commitment to privacy, adhering to its Public Content Policy and existing Data API Terms, which restrict commercial use without approval. OpenAI will serve as a Reddit advertising partner.[91]\n\nOn May 22, 2024, OpenAI entered into an agreement with News Corp to integrate news content from The Wall Street Journal, New York Post, The Times, and The Sunday Times into its AI platform. Meanwhile, other publications like The New York Times chose to sue OpenAI and Microsoft for copyright infringement over use of their content to train AI models.[92]\n\nOn May 29, 2024, Axios reported that OpenAI had signed deals with Vox Media and The Atlantic to share content to enhance the accuracy of AI models like ChatGPT by incorporating reliable news sources, addressing concerns about AI misinformation.[93] Concerns were expressed by journalists and unions. The Vox Union stated, \"As both journalists and workers, we have serious concerns about this partnership, which we believe could adversely impact members of our union, not to mention the well-documented ethical and environmental concerns surrounding the use of generative AI.\"[94]\n\nA group of nine current and former OpenAI employees has accused the company of prioritizing profits over safety, using restrictive agreements to silence concerns, and moving too quickly with inadequate risk management. They call for greater transparency, whistleblower protections, and legislative regulation of AI development.[95]\n\nOn June 10, 2024, it was announced that OpenAI had partnered with Apple Inc. to bring ChatGPT features to Apple Intelligence and iPhone.[96] On June 13, 2024, OpenAI announced that Paul Nakasone, the former head of the NSA was joining its board. Nakasone also joined the security subcommittee.[97]\n\nOn June 24, 2024, OpenAI acquired Multi, a startup running a collaboration platform based on Zoom.[98]\n\nIn July 2024, Reuters reported that OpenAI is working on a project to enhance AI reasoning capabilities, and to enable AI to plan ahead, navigate the internet autonomously, and conduct \"deep research\".[99][100] The project was released on September 12 and named o1.[101]\n\nOn August 5, TechCrunch reported that OpenAI's cofounder John Schulman had left to join rival startup Anthropic. Schulman cited a desire to focus more on AI alignment research. OpenAI's president and co-founder, Greg Brockman, took extended leave till November.[102]\n\nIn September 2024, OpenAI's global affairs chief, Anna Makanju, expressed support for the UK's approach to AI regulation during her testimony to a House of Lords committee, stating the company favors \"smart regulation\" and sees the UK's AI white paper as a positive step towards responsible AI development.[103] Chief Technology Officer (CTO) Mira Murati announced her departure from the company to \"create the time and space to do my own exploration\".[104] It had been reported Murati was among those who expressed concerns to the Board about Altman.[105]\n\nIn October 2024, OpenAI raised $6.6 billion from investors, potentially valuing the company at $157 billion. The funding attracted returning venture capital firms like Thrive Capital and Khosla Ventures, along with major backer Microsoft and new investors Nvidia and SoftBank.[106][107]  OpenAI's CFO, Sarah Friar, informed employees that a tender offer for share buybacks would follow the funding, although specifics were yet to be determined. Thrive Capital invested around $1.2 billion, with the option for an additional $1 billion if revenue goals were met. Apple, despite initial interest, did not participate in this funding round.[108]\n\nAlso in October 2024, The Intercept revealed that OpenAI's tools were considered \"essential\" for AFRICOM's mission and included in an \"Exception to Fair Opportunity\" contractual agreement between the Department of Defense and Microsoft.[109]\n\nIn November 2024, OpenAI acquired the long-standing domain Chat.com and redirected it to ChatGPT's main site.[110][111] Moreover, Greg Brockman rejoined OpenAI after a three-month leave from his role as president. An OpenAI spokesperson confirmed his return, highlighting that Brockman would collaborate with Altman on tackling key technical challenges. His return followed a wave of high-profile departures, including Mira Murati and Ilya Sutskever, who had since launched their own AI ventures.[112]\n\nIn December 2024, OpenAI launched several significant features as part of its \"12 Days of OpenAI\" event, which started on December 5. It announced Sora, a text-to-video model intended to create realistic videos from text prompts, and available to ChatGPT Plus and Pro users.[113][114] Additionally, OpenAI launched the o1 model, which is designed to be capable of advanced reasoning through its chain-of-thought processing, enabling it to engage in explicit reasoning before generating responses.[115][116] This model is intended to tackle complex tasks with improved accuracy and transparency. Another major release was ChatGPT Pro, a subscription service priced at $200 per month that provides users with unlimited access to the o1 model and enhanced voice features.[117] OpenAI shared preliminary benchmark results for the upcoming o3 model.[118] The event also saw the expansion of the Canvas feature, allowing all users to utilize side-by-side digital editing capabilities.\n\nOn January 20, 2025, DeepSeek released the \"DeepSeek-R1\" model, which rivaled the performance of OpenAI's o1 and was open-weight.[119] DeepSeek claimed that this model only took $5.6 million to train. This news lead to panic from investors and caused Nvidia to record the biggest single day market cap loss in history losing $589 billion on January 27.[120]\n\nOn January 21, 2025, it was announced that OpenAI, Oracle, SoftBank and MGX would launch The Stargate Project, a joint venture to build an AI infrastructure system in conjunction with the US government. The project takes its name from OpenAI's existing \"Stargate\" supercomputer project and is estimated to cost $500 billion. The project will be funded over the next four years.[121] \n\nOn January 24, OpenAI made Operator, an AI agent and web automation tool for accessing websites to execute goals defined by users, available to Pro users in the U.S.A. only.[122][123]\n\nOn February 2, OpenAI made deep research agent, that achieved an accuracy of 26.6 percent on Humanity's Last Exam (HLE) benchmark, available to $200-monthly-fee paying users with up to 100 queries per month, while more “limited access” was promised for Plus, Team and later Enterprise users.[124]\n\nOn February 10, a consortium of investors led by Elon Musk submitted a $97.4 billion unsolicited bid to buy the nonprofit that controls OpenAI and was willing to match or exceed any better offers.[125][126] The offer was rejected on 14 February 2025, with OpenAI stating that it was not for sale.[127]\n\nIn February 2025, OpenAI underwent a rebranding with a new typeface, word mark, symbol and palette.[128] OpenAI began collaborating with Broadcom in 2024 to design a custom AI chip capable of both training and inference targeted for mass production in 2026 and to be manufactured by TSMC in 3 nm node. This initiative is intended to reduce OpenAI's dependence on Nvidia GPUs, which are costly and face high demand in the market.\n[129]\n\nOn February 13, Sam Altman, CEO of OpenAI, shared in a Twitter post that GPT-4.5, internally known as \"Orion,\" will be the last model without full chain-of-thought reasoning. He mentioned that GPT-5 will be the first to fully integrate this reasoning across all tasks. GPT-4.5 is expected within weeks, with GPT-5 following in months. Altman also hinted that GPT-5 could unify the O-Series and GPT-Series models, eliminating the need to choose between them. GPT-5 will integrate multiple OpenAI technologies, including o3, within ChatGPT and its API, phasing out O-series models.[130]\n\n\n\nSources:[10][137]\n\nSome scientists, such as Stephen Hawking and Stuart Russell, have articulated concerns that if advanced AI gains the ability to redesign itself at an ever-increasing rate, an unstoppable \"intelligence explosion\" could lead to human extinction. Co-founder Musk characterizes AI as humanity's \"biggest existential threat\".[139]\n\nMusk and Altman have stated they are partly motivated by concerns about AI safety and the existential risk from artificial general intelligence.[140][141] OpenAI states that \"it's hard to fathom how much human-level AI could benefit society,\" and that it is equally difficult to comprehend \"how much it could damage society if built or used incorrectly\".[21] Research on safety cannot safely be postponed: \"because of AI's surprising history, it's hard to predict when human-level AI might come within reach.\"[142] OpenAI states that AI \"should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as possible.\"[21] Co-chair Sam Altman expects the decades-long project to surpass human intelligence.[143]\n\nVishal Sikka, former CEO of Infosys, stated that an \"openness\", where the endeavor would \"produce results generally in the greater interest of humanity\", was a fundamental requirement for his support; and that OpenAI \"aligns very nicely with our long-held values\" and their \"endeavor to do purposeful work\".[144] Cade Metz of Wired suggested that corporations such as Amazon might be motivated by a desire to use open-source software and data to level the playing field against corporations such as Google and Facebook, which own enormous supplies of proprietary data. Altman stated that Y Combinator companies would share their data with OpenAI.[143]\n\nIn the early years before his 2018 departure, Musk posed the question: \"What is the best thing we can do to ensure the future is good? We could sit on the sidelines or we can encourage regulatory oversight, or we could participate with the right structure with people who care deeply about developing AI in a way that is safe and is beneficial to humanity.\" He acknowledged that \"there is always some risk that in actually trying to advance (friendly) AI we may create the thing we are concerned about\"; but nonetheless, that the best defense was \"to empower as many people as possible to have AI. If everyone has AI powers, then there's not any one person or a small set of individuals who can have AI superpower.\"[131]\n\nMusk and Altman's counterintuitive strategy—that of trying to reduce the potential harm of AI by giving everyone access to it—is controversial among those concerned with existential risk from AI. Philosopher Nick Bostrom said, \"If you have a button that could do bad things to the world, you don't want to give it to everyone.\"[141] During a 2016 conversation about technological singularity, Altman said, \"We don't plan to release all of our source code\" and mentioned a plan to \"allow wide swaths of the world to elect representatives to a new governance board\". Greg Brockman stated, \"Our goal right now ... is to do the best thing there is to do. It's a little vague.\"[145]\n\nConversely, OpenAI's initial decision to withhold GPT-2 around 2019, due to a wish to \"err on the side of caution\" in the presence of potential misuse, was criticized by advocates of openness. Delip Rao, an expert in text generation, stated, \"I don't think [OpenAI] spent enough time proving [GPT-2] was actually dangerous.\" Other critics argued that open publication was necessary to replicate the research and to create countermeasures.[146]\n\nMore recently, in 2022, OpenAI published its approach to the alignment problem, anticipating that aligning AGI to human values would likely be harder than aligning current AI systems: \"Unaligned AGI could pose substantial risks to humanity[,] and solving the AGI alignment problem could be so difficult that it will require all of humanity to work together\". They stated that they intended to explore how to better use human feedback to train AI systems, and how to safely use AI to incrementally automate alignment research.[147]\n\nIn 2024, following the temporary removal of Sam Altman and his return, many employees gradually left OpenAI, including most of the original leadership team and a significant number of AI safety researchers.[148][149] OpenAI also planned a restructuring to operate as a for-profit company. This restructuring could grant Altman a stake in the company.[150]\n\nIn February 2025, OpenAI CEO Sam Altman stated that the company is interested in collaborating with China, despite regulatory restrictions imposed by the U.S. government.[151] This shift comes in response to the growing influence of the Chinese artificial intelligence company DeepSeek, which has disrupted the AI market with advanced models, including DeepSeek V3 and DeepSeek R1, known for their efficiency and cost-effectiveness.[152]\n\nThe emergence of DeepSeek has led major Chinese tech firms such as Baidu and others to embrace an open-source strategy, intensifying competition with OpenAI. Altman acknowledged the uncertainty regarding U.S. government approval for AI cooperation with China but emphasized the importance of fostering dialogue between technological leaders in both nations.[153]\n\nAt its beginning, OpenAI's research included many projects focused on reinforcement learning (RL).[154] OpenAI has been viewed as an important competitor to DeepMind.[155]\n\nAnnounced in 2016, Gym is an open-source Python library designed to facilitate the development of reinforcement learning algorithms. It aimed to standardize how environments are defined in AI research, making published research more easily reproducible[26][156] while providing users with a simple interface for interacting with these environments. In 2022, new developments of Gym have been moved to the library Gymnasium.[157][158]\n\nReleased in 2018, Gym Retro is a platform for reinforcement learning (RL) research on video games[159] using RL algorithms and study generalization. Prior RL research focused mainly on optimizing agents to solve single tasks. Gym Retro gives the ability to generalize between games with similar concepts but different appearances.\n\nReleased in 2017, RoboSumo is a virtual world where humanoid metalearning robot agents initially lack knowledge of how to even walk, but are given the goals of learning to move and to push the opposing agent out of the ring.[160] Through this adversarial learning process, the agents learn how to adapt to changing conditions. When an agent is then removed from this virtual environment and placed in a new virtual environment with high winds, the agent braces to remain upright, suggesting it had learned how to balance in a generalized way.[160][161] OpenAI's Igor Mordatch argued that competition between agents could create an intelligence \"arms race\" that could increase an agent's ability to function even outside the context of the competition.[160]\n\nOpenAI Five is a team of five OpenAI-curated bots used in the competitive five-on-five video game Dota 2, that learn to play against human players at a high skill level entirely through trial-and-error algorithms. Before becoming a team of five, the first public demonstration occurred at The International 2017, the annual premiere championship tournament for the game, where Dendi, a professional Ukrainian player, lost against a bot in a live one-on-one matchup.[162][163] After the match, CTO Greg Brockman explained that the bot had learned by playing against itself for two weeks of real time, and that the learning software was a step in the direction of creating software that can handle complex tasks like a surgeon.[164][165] The system uses a form of reinforcement learning, as the bots learn over time by playing against themselves hundreds of times a day for months, and are rewarded for actions such as killing an enemy and taking map objectives.[166][167][168]\n\nBy June 2018, the ability of the bots expanded to play together as a full team of five, and they were able to defeat teams of amateur and semi-professional players.[169][166][170][171] At The International 2018, OpenAI Five played in two exhibition matches against professional players, but ended up losing both games.[172][173][174] In April 2019, OpenAI Five defeated OG, the reigning world champions of the game at the time, 2:0 in a live exhibition match in San Francisco.[175][176] The bots' final public appearance came later that month, where they played in 42,729 total games in a four-day open online competition, winning 99.4% of those games.[177]\n\nOpenAI Five's mechanisms in Dota 2's bot player shows the challenges of AI systems in multiplayer online battle arena (MOBA) games and how OpenAI Five has demonstrated the use of deep reinforcement learning (DRL) agents to achieve superhuman competence in Dota 2 matches.[178]\n\nDeveloped in 2018, Dactyl uses machine learning to train a Shadow Hand, a human-like robot hand, to manipulate physical objects.[179] It learns entirely in simulation using the same RL algorithms and training code as OpenAI Five. OpenAI tackled the object orientation problem by using domain randomization, a simulation approach which exposes the learner to a variety of experiences rather than trying to fit to reality. The set-up for Dactyl, aside from having motion tracking cameras, also has RGB cameras to allow the robot to manipulate an arbitrary object by seeing it. In 2018, OpenAI showed that the system was able to manipulate a cube and an octagonal prism.[180]\n\nIn 2019, OpenAI demonstrated that Dactyl could solve a Rubik's Cube. The robot was able to solve the puzzle 60% of the time. Objects like the Rubik's Cube introduce complex physics that is harder to model. OpenAI did this by improving the robustness of Dactyl to perturbations by using Automatic Domain Randomization (ADR), a simulation approach of generating progressively more difficult environments. ADR differs from manual domain randomization by not needing a human to specify randomization ranges.[181]\n\nIn June 2020, OpenAI announced a multi-purpose API which it said was \"for accessing new AI models developed by OpenAI\" to let developers call on it for \"any English language AI task\".[182][183]\n\nThe company has popularized generative pretrained transformers (GPT).[184]\n\nThe original paper on generative pre-training of a transformer-based language model was written by Alec Radford and his colleagues, and published in preprint on OpenAI's website on June 11, 2018.[185] It showed how a generative model of language could acquire world knowledge and process long-range dependencies by pre-training on a diverse corpus with long stretches of contiguous text.\n\nGenerative Pre-trained Transformer 2 (\"GPT-2\") is an unsupervised transformer language model and the successor to OpenAI's original GPT model (\"GPT-1\"). GPT-2 was announced in February 2019, with only limited demonstrative versions initially released to the public. The full version of GPT-2 was not immediately released due to concern about potential misuse, including applications for writing fake news.[186] Some experts expressed skepticism that GPT-2 posed a significant threat.\n\nIn response to GPT-2, the Allen Institute for Artificial Intelligence responded with a tool to detect \"neural fake news\".[187] Other researchers, such as Jeremy Howard, warned of \"the technology to totally fill Twitter, email, and the web up with reasonable-sounding, context-appropriate prose, which would drown out all other speech and be impossible to filter\".[188] In November 2019, OpenAI released the complete version of the GPT-2 language model.[189] Several websites host interactive demonstrations of different instances of GPT-2 and other transformer models.[190][191][192]\n\nGPT-2's authors argue unsupervised language models to be general-purpose learners, illustrated by GPT-2 achieving state-of-the-art accuracy and perplexity on 7 of 8 zero-shot tasks (i.e. the model was not further trained on any task-specific input-output examples).\n\nThe corpus it was trained on, called WebText, contains slightly 40 gigabytes of text from URLs shared in Reddit submissions with at least 3 upvotes. It avoids certain issues encoding vocabulary with word tokens by using byte pair encoding. This permits representing any string of characters by encoding both individual characters and multiple-character tokens.[193]\n\nFirst described in May 2020, Generative Pre-trained[a] Transformer 3 (GPT-3) is an unsupervised transformer language model and the successor to GPT-2.[194][195][196] OpenAI stated that the full version of GPT-3 contained 175 billion parameters,[196] two orders of magnitude larger than the 1.5 billion[197] in the full version of GPT-2 (although GPT-3 models with as few as 125 million parameters were also trained).[198]\n\nOpenAI stated that GPT-3 succeeded at certain \"meta-learning\" tasks and could generalize the purpose of a single input-output pair. The GPT-3 release paper gave examples of translation and cross-linguistic transfer learning between English and Romanian, and between English and German.[196]\n\nGPT-3 dramatically improved benchmark results  over GPT-2. OpenAI cautioned that such scaling-up of language models could be approaching or encountering the fundamental capability limitations of predictive language models.[199] Pre-training GPT-3 required several thousand petaflop/s-days[b] of compute, compared to tens of petaflop/s-days for the full GPT-2 model.[196] Like its predecessor,[186] the GPT-3 trained model was not immediately released to the public for concerns of possible abuse, although OpenAI planned to allow access through a paid cloud API after a two-month free private beta that began in June 2020.[182][201]\n\nOn September 23, 2020, GPT-3 was licensed exclusively to Microsoft.[202][203]\n\nAnnounced in mid-2021, Codex is a descendant of GPT-3 that has additionally been trained on code from 54 million GitHub repositories,[204][205] and is the AI powering the code autocompletion tool GitHub Copilot.[205] In August 2021, an API was released in private beta.[206] According to OpenAI, the model can create working code in over a dozen programming languages, most effectively in Python.[204]\n\nSeveral issues with glitches, design flaws and security vulnerabilities were cited.[207][208]\n\nGitHub Copilot has been accused of emitting copyrighted code, with no author attribution or license.[209]\n\nOpenAI announced that they would discontinue support for Codex API on March 23, 2023.[210]\n\nOn March 14, 2023, OpenAI announced the release of Generative Pre-trained Transformer 4 (GPT-4), capable of accepting text or image inputs.[211] They announced that the updated technology passed a simulated law school bar exam with a score around the top 10% of test takers. (By contrast, GPT-3.5 scored around the bottom 10%.) They said that GPT-4 could also read, analyze or generate up to 25,000 words of text, and write code in all major programming languages.[212]\n\nObservers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous GPT-3.5-based iteration, with the caveat that GPT-4 retained some of the problems with earlier revisions.[213] GPT-4 is also capable of taking images as input on ChatGPT.[214] OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.[215]\n\nOn May 13, 2024, OpenAI announced and released GPT-4o, which can process and generate text, images and audio.[216] GPT-4o achieved state-of-the-art results in voice, multilingual, and vision benchmarks, setting new records in audio speech recognition and translation.[217][218] It scored 88.7% on the Massive Multitask Language Understanding (MMLU) benchmark compared to 86.5% by GPT-4.[219]\n\nOn July 18, 2024, OpenAI released GPT-4o mini, a smaller version of GPT-4o replacing GPT-3.5 Turbo on the ChatGPT interface. Its API costs $0.15 per million input tokens and $0.60 per million output tokens, compared to $5 and $15 respectively for GPT-4o. OpenAI expects it to be particularly useful for enterprises, startups and developers seeking to automate services with AI agents.[220]\n\nOn September 12, 2024, OpenAI released the o1-preview and o1-mini models, which have been designed to take more time to think about their responses, leading to higher accuracy. These models are particularly effective in science, coding, and reasoning tasks, and were made available to ChatGPT Plus and Team members.[221][222] In December 2024, o1-preview was replaced by o1.[223]\n\nOn December 20, 2024, OpenAI unveiled o3, the successor of the o1 reasoning model. OpenAI also unveiled o3-mini, a lighter and faster version of OpenAI o3. As of December 21, 2024, this model is not available for public use. According to OpenAI, they are testing o3 and o3-mini.[224][225] Until January 10, 2025, safety and security researchers had the opportunity to apply for early access to these models.[226] The model is called o3 rather than o2 to avoid confusion with telecommunications services provider O2.[227]\n\nDeep research is an agent developed by OpenAI, unveiled on February 2, 2025. It leverages the capabilities of OpenAI's o3 model to perform extensive web browsing, data analysis, and synthesis, delivering comprehensive reports within a timeframe of 5 to 30 minutes.[228] With browsing and Python tools enabled, it reached an accuracy of 26.6 percent on HLE (Humanity's Last Exam) benchmark.[124]\n\nRevealed in 2021, CLIP (Contrastive Language–Image Pre-training) is a model that is trained to analyze the semantic similarity between text and images. It can notably be used for image classification.[229]\n\nRevealed in 2021, DALL-E is a Transformer model that creates images from textual descriptions.[230] DALL-E uses a 12-billion-parameter version of GPT-3 to interpret natural language inputs (such as \"a green leather purse shaped like a pentagon\" or \"an isometric view of a sad capybara\") and generate corresponding images. It can create images of realistic objects (\"a stained-glass window with an image of a blue strawberry\") as well as objects that do not exist in reality (\"a cube with the texture of a porcupine\"). As of March 2021, no API or code is available.\n\nIn April 2022, OpenAI announced DALL-E 2, an updated version of the model with more realistic results.[231] In December 2022, OpenAI published on GitHub software for Point-E, a new rudimentary system for converting a text description into a 3-dimensional model.[232]\n\nIn September 2023, OpenAI announced DALL-E 3, a more powerful model better able to generate images from complex descriptions without manual prompt engineering and render complex details like hands and text.[233] It was released to the public as a ChatGPT Plus feature in October.[234]\n\nSora is a text-to-video model that can generate videos based on short descriptive prompts[235] as well as extend existing videos forwards or backwards in time.[236] It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown.\n\nSora's development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\".[235] Sora's technology is an adaptation of the technology behind the DALL·E 3 text-to-image model.[237] OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos.[235]\n\nOpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model's capabilities.[237] It acknowledged some of its shortcomings, including struggles simulating complex physics.[238] Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora's typical output.[237]\n\nDespite skepticism from some academic leaders following Sora's public demo, notable entertainment-industry figures have shown significant interest in the technology's potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology's ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora's possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.[239]\n\n\n\nReleased in 2022, Whisper is a general-purpose speech recognition model.[240] It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.[241]\n\nReleased in 2019, MuseNet is a deep neural net trained to predict subsequent musical notes in MIDI music files. It can generate songs with 10 instruments in 15 styles. According to The Verge, a song generated by MuseNet tends to start reasonably but then fall into chaos the longer it plays.[242][243] In pop culture, initial applications of this tool were used as early as 2020 for the internet psychological thriller Ben Drowned to create music for the titular character.[244][245]\n\nReleased in 2020, Jukebox is an open-sourced algorithm to generate music with vocals. After training on 1.2 million samples, the system accepts a genre, artist, and a snippet of lyrics and outputs song samples. OpenAI stated the songs \"show local musical coherence [and] follow traditional chord patterns\" but acknowledged that the songs lack \"familiar larger musical structures such as choruses that repeat\" and that \"there is a significant gap\" between Jukebox and human-generated music. The Verge stated \"It's technologically impressive, even if the results sound like mushy versions of songs that might feel familiar\", while Business Insider stated \"surprisingly, some of the resulting songs are catchy and sound legitimate\".[246][247][248]\n\nIn 2018, OpenAI launched the Debate Game, which teaches machines to debate toy problems in front of a human judge. The purpose is to research whether such an approach may assist in auditing AI decisions and in developing explainable AI.[249][250]\n\nReleased in 2020, Microscope[251] is a collection of visualizations of every significant layer and neuron of eight neural network models which are often studied in interpretability.[252] Microscope was created to analyze the features that form inside these neural networks easily. The models included are AlexNet, VGG-19, different versions of Inception, and different versions of CLIP Resnet.[253]\n\nLaunched in November 2022, ChatGPT is an artificial intelligence tool built on top of GPT-3 that provides a conversational interface that allows users to ask questions in natural language. The system then responds with an answer within seconds. ChatGPT reached 1 million users 5 days after its launch.[254][255]\n\nAs of 2023, ChatGPT Plus is a GPT-4 backed version of ChatGPT[256] available for a US$20 per month subscription fee[257] (the original version is backed by GPT-3.5).[258] OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist;[259] after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is charged for access to the version of the model with an 8192-token context window; for the 32768-token context window, the prices are doubled.[260]\n\nIn May 2023, OpenAI launched a user interface for ChatGPT for the App Store on iOS and later in July 2023 for the Play Store on Android.[261] The app supports chat history syncing and voice input (using Whisper, OpenAI's speech recognition model).[262][261][263] In September 2023, OpenAI announced that ChatGPT \"can now see, hear, and speak\". ChatGPT Plus users can upload images, while mobile app users can talk to the chatbot.[264][265]\n\nIn October 2023, OpenAI's latest image generation model, DALL-E 3, was integrated into ChatGPT Plus and ChatGPT Enterprise. The integration uses ChatGPT to write prompts for DALL-E guided by conversation with users.[266][267]\n\nOpenAI's GPT Store, initially slated for a 2023 launch, is now deferred to an undisclosed date in early 2024, attributed likely to the leadership changes in November following the initial announcement.[268]\n\nConcerns about the energy consumption of generative AI, including ChatGPT, are rising. In September 2024, Microsoft entered a deal with Constellation Energy to reopen the Three Mile Island nuclear plant to supply power to its AI-driven data centers.[269]\n\nIn December 2024, OpenAI launched a new feature allowing users to call ChatGPT for up to 15 minutes per month for free.[270][271]\n\nSearchGPT, a prototype search engine developed by OpenAI, was unveiled on July 25, 2024, with an initial limited release to 10,000 test users. It combines traditional search engine features with generative AI capabilities.[272][273]\n\nStargate is a potential artificial intelligence supercomputer in development by Microsoft and OpenAI, in collaboration with Oracle, SoftBank, and MGX.[274][275] Stargate is designed as part of a greater data center project, which could represent an investment of as much as $100 billion by Microsoft.[276]\n\nStargate is reported to be part of a series of AI-related construction projects planned in the next few years by the companies Microsoft and OpenAI.[276] The supercomputers will be constructed in five phases.[274] The fourth phase should consist in a smaller OpenAI supercomputer, planned to launch around 2026.[274] Stargate is the fifth and final phase of the program, and will take five and six years to complete and is slated to launch around 2028.[276]\n\nThe artificial intelligence of Stargate is slated to be contained on millions of special server chips.[276] The supercomputer's data center will be built in the US across 700 acres of land.[276]  It has a planned power consumption of 5 gigawatts, for which it could rely on nuclear energy.[276] The name \"Stargate\" is a homage to the 1994 sci-fi film Stargate.[276]\n\nOn November 17, 2023, Sam Altman was removed as CEO when its board of directors (composed of Helen Toner, Ilya Sutskever, Adam D'Angelo and Tasha McCauley) cited a lack of confidence in him. Chief Technology Officer Mira Murati took over as interim CEO. Greg Brockman, the president of OpenAI, was also removed as chairman of the board[277][278] and resigned from the company's presidency shortly thereafter.[279] Three senior OpenAI researchers subsequently resigned: director of research and GPT-4 lead Jakub Pachocki, head of AI risk Aleksander Mądry [pl], and researcher Szymon Sidor.[280][281]\n\nOn November 18, 2023, there were reportedly talks of Altman returning as CEO amid pressure placed upon the board by investors such as Microsoft and Thrive Capital, who objected to Altman's departure.[282] Although Altman himself spoke in favor of returning to OpenAI, he has since stated that he considered starting a new company and bringing former OpenAI employees with him if talks to reinstate him didn't work out.[283] The board members agreed \"in principle\" to resign if Altman returned.[284] On November 19, 2023, negotiations with Altman to return failed and Murati was replaced by Emmett Shear as interim CEO.[285] The board initially contacted Anthropic CEO Dario Amodei (a former OpenAI executive) about replacing Altman, and proposed a merger of the two companies, but both offers were declined.[286]\n\nOn November 20, 2023, Microsoft CEO Satya Nadella announced Altman and Brockman would be joining Microsoft to lead a new advanced AI research team, but added that they were still committed to OpenAI despite recent events.[287] Before the partnership with Microsoft was finalized, Altman gave the board another opportunity to negotiate with him.[288] About 738 of OpenAI's 770 employees, including Murati and Sutskever, signed an open letter stating they would quit their jobs and join Microsoft if the board did not rehire Altman and then resign.[289][290] This prompted OpenAI investors to consider legal action against the board as well.[291] In response, OpenAI management sent an internal memo to employees stating that negotiations with Altman and the board had resumed and would take some time.[292]\n\n\nOn November 21, 2023, after continued negotiations, Altman and Brockman returned to the company in their prior roles along with a reconstructed board made up of new members Bret Taylor (as chairman) and Lawrence Summers, with D'Angelo remaining.[293] On November 22, 2023, emerging reports suggested that Sam Altman's dismissal from OpenAI may have been linked to his alleged mishandling of a significant breakthrough in the organization's secretive project codenamed Q*. According to sources within OpenAI, Q* is aimed at developing AI capabilities in logical and mathematical reasoning, and reportedly involves performing math on the level of grade-school students.[294][295][296] Concerns about Altman's response to this development, specifically regarding the discovery's potential safety implications, were reportedly raised with the company's board shortly before Altman's firing.[297] On November 29, 2023, OpenAI announced that an anonymous Microsoft employee had joined the board as a non-voting member to observe the company's operations;[298] Microsoft resigned from the board in July 2024.[299]\n\nIn January 2023, OpenAI has been criticized for outsourcing the annotation of data sets to Sama, a company based in San Francisco that employed workers in Kenya. These annotations were used to train an AI model to detect toxicity, which could then be used to moderate toxic content, notably from ChatGPT's training data and outputs. However, these pieces of text usually contained detailed descriptions of various types of violence, including sexual violence. The investigation uncovered that OpenAI began sending snippets of data to Sama as early as November 2021. The four Sama employees interviewed by Time described themselves as mentally scarred. OpenAI paid Sama $12.50 per hour of work, and Sama was redistributing the equivalent of between $1.32 and $2.00 per hour post-tax to its annotators. Sama's spokesperson said that the $12.50 was also covering other implicit costs, among which were infrastructure expenses, quality assurance and management.[300]\n\nIn March 2023, the company was also criticized for disclosing particularly few technical details about products like GPT-4, contradicting its initial commitment to openness and making it harder for independent researchers to replicate its work and develop safeguards. OpenAI cited competitiveness and safety concerns to justify this strategic turn. OpenAI's former chief scientist Ilya Sutskever argued in 2023 that open-sourcing increasingly capable models was increasingly risky, and that the safety reasons for not open-sourcing the most potent AI models would become \"obvious\" in a few years.[301]\n\nOn May 17, 2024, a Vox article reported that OpenAI was asking departing employees to sign a lifelong non-disparagement agreement forbidding them from criticizing OpenAI or acknowledging the existence of the agreement. Daniel Kokotajlo, a former employee, publicly stated that he forfeited his vested equity in OpenAI in order to leave without signing the agreement.[302][303] Sam Altman stated that he was unaware of the equity cancellation provision, and that OpenAI never enforced it to cancel any employee's vested equity.[304] Vox published leaked documents and emails challenging this claim.[305] On May 23, 2024, OpenAI sent a memo releasing former employees from the agreement.[306]\n\nOpenAI was sued for copyright infringement by authors Sarah Silverman, Matthew Butterick, Paul Tremblay and Mona Awad in July 2023.[307][308][309] In September 2023, 17 authors, including George R. R. Martin, John Grisham, Jodi Picoult and Jonathan Franzen, joined the Authors Guild in filing a class action lawsuit against OpenAI, alleging that the company's technology was illegally using their copyrighted work.[310][311] The New York Times also sued the company in late December 2023.[308][312] In May 2024 it was revealed that OpenAI had destroyed its Books1 and Books2 training datasets, which were used in the training of GPT-3, and which the Authors Guild believed to have contained over 100,000 copyrighted books.[313]\n\nIn 2021, OpenAI developed a speech recognition tool called Whisper. OpenAI used it to transcribe more than one million hours of YouTube videos into text for training GPT-4. The automated transcription of YouTube videos raised concerns within OpenAI employees regarding potential violations of YouTube's terms of service, which prohibit the use of videos for applications independent of the platform, as well as any type of automated access to its videos. Despite these concerns, the project proceeded with notable involvement from OpenAI's president, Greg Brockman. The resulting dataset proved instrumental in training GPT-4.[314]\n\nIn February 2024, The Intercept as well as Raw Story and Alternate Media Inc. filed lawsuit against OpenAI on copyright litigation ground.[315][316] The lawsuit is said to have charted a new legal strategy for digital-only publishers to sue OpenAI.[317]\n\nOn April 30, 2024, eight newspapers filed a lawsuit in the Southern District of New York against OpenAI and Microsoft, claiming illegal harvesting of their copyrighted articles. The suing publications included The Mercury News, The Denver Post, The Orange County Register, St. Paul Pioneer Press, Chicago Tribune, Orlando Sentinel, Sun Sentinel, and New York Daily News.[318]\n\nIn April 2023, the EU's European Data Protection Board (EDPB) formed a dedicated task force on ChatGPT \"to foster cooperation and to exchange information on possible enforcement actions conducted by data protection authorities\" based on the \"enforcement action undertaken by the Italian data protection authority against Open AI about the Chat GPT service\".[319]\n\nIn late April 2024 NOYB filed a complaint with the Austrian Datenschutzbehörde against OpenAI for violating the European General Data Protection Regulation. A text created with ChatGPT gave a false date of birth for a living person without giving the individual the option to see the personal data used in the process. A request to correct the mistake was denied. Additionally, neither the recipients of ChatGPT's work nor the sources used, could be made available, OpenAI claimed.[320]\n\nOpenAI was criticized for lifting its ban on using ChatGPT for \"military and warfare\". Up until January 10, 2024, its \"usage policies\" included a ban on \"activity that has high risk of physical harm, including,\" specifically, \"weapons development\" and \"military and warfare.\" Its new policies prohibit \"[using] our service to harm yourself or others\" and to \"develop or use weapons\".[321][322] As one of the industry collaborators, OpenAI provides LLM to the Artificial Intelligence Cyber Challenge (AIxCC) sponsored by Defense Advanced Research Projects Agency (DARPA) and Advanced Research Projects Agency for Health to protect software critical to Americans.[323] In October 2024, The Intercept revealed that OpenAI's tools are considered \"essential\" for AFRICOM's mission and included in an \"Exception to Fair Opportunity\" contractural agreement between the United States Department of Defense and Microsoft.[109] In December 2024, OpenAI said it would partner with defense-tech company Anduril to build drone defense technologies for the United States and its allies.[324]\n\nIn June 2023, a lawsuit claimed that OpenAI scraped 300 billion words online without consent and without registering as a data broker. It was filed in San Francisco, California, by sixteen anonymous plaintiffs.[325] They also claimed that OpenAI and its partner as well as customer Microsoft continued to unlawfully collect and use personal data from millions of consumers worldwide to train artificial intelligence models.[326]\n\nOn May 22, 2024, OpenAI entered into an agreement with News Corp to integrate news content from The Wall Street Journal, the New York Post, The Times, and The Sunday Times into its AI platform. Meanwhile, other publications like The New York Times chose to sue OpenAI and Microsoft for copyright infringement over the use of their content to train AI models.[92] In November 2024, a coalition of Canadian news outlets, including the Toronto Star, Metroland Media, Postmedia, The Globe and Mail, The Canadian Press and CBC, sued OpenAI for using their news articles to train its software without permission.[327]\n\nSuchir Balaji, a former researcher at OpenAI, was found dead in his San Francisco apartment on November 26, 2024. The police ruled that there was \"no evidence of foul play\" found during the initial investigation, and the San Francisco medical examiner's office confirmed the cause of death as suicide. However, the circumstances surrounding his death have sparked controversy and allegations of foul play.[328][329]\n\nBalaji had publicly criticized OpenAI for what he perceived as breaches of copyright law in the development of ChatGPT, which led to his resignation from the company in August 2024.[330] Following his death, his mother, Poornima Ramarao, contested the official narrative. She claimed that there were signs of a struggle in the apartment, including blood patterns inconsistent with suicide, and that the apartment appeared ransacked. Ramarao, along with Balaji's family, hired private investigators and conducted a second autopsy, which they claim contradicted the police's findings.[331][332]  As of January 17, 2025, the family's allegations have gained widespread attention, with figures like Elon Musk and Silicon Valley Congressman Ro Khanna publicly calling for further investigation into the possibility of foul play.[333][334][335]\n\nIn February 2025, the official autopsy report found that Balaji died by suicide. The investigation noted that he had purchased the firearm used two years prior to his death, and had recently searched for brain anatomy information on his computer. The report also highlighted that his apartment's only entrance was dead-bolted from inside with no signs of forced entry.[336]\n\n"}
{"url":"https://en.wikipedia.org/wiki/Microsoft","title":"Microsoft","content":"\n\n\n\nMicrosoft Corporation is an American multinational technology conglomerate headquartered in Redmond, Washington.[2] Founded in 1975, the company became highly influential in the rise of personal computers through software like Windows, and the company has since expanded to Internet services, cloud computing, video gaming and other fields. Microsoft is the largest software maker, one of the most valuable public U.S. companies,[a] and one of the most valuable brands globally.\n\nMicrosoft was founded by Bill Gates and Paul Allen to develop and sell BASIC interpreters for the Altair 8800. It rose to dominate the personal computer operating system market with MS-DOS in the mid-1980s, followed by Windows. During the 41 years from 1980 to 2021 Microsoft released 9 versions of MS-DOS with a median frequency of 2 years, and 13 versions of Windows with a median frequency of 3 years. The company's 1986 initial public offering (IPO) and subsequent rise in its share price created three billionaires and an estimated 12,000 millionaires among Microsoft employees. Since the 1990s, it has increasingly diversified from the operating system market. Steve Ballmer replaced Gates as CEO in 2000.  He oversaw the then-largest of Microsoft's corporate acquisitions in Skype Technologies in 2011,[3] and an increased focus on hardware[4][5] that led to its first in-house PC line, the Surface, in 2012, and the formation of Microsoft Mobile through Nokia. Since Satya Nadella took over as CEO in 2014, the company has changed focus towards cloud computing,[6][7] as well as its large acquisition of LinkedIn for $26.2 billion in 2016.[8] Under Nadella's direction, the company has also expanded its video gaming business to support the Xbox brand, establishing the Microsoft Gaming division in 2022, which is currently[b] the third-largest gaming company in the world by revenue,[9] following the 2023 acquisition of Activision Blizzard for $68.7 billion.[10]\n\nMicrosoft has been market-dominant in the IBM PC–compatible operating system market and the office software suite market since the 1990s. Its best-known software products are the Windows line of operating systems and the Microsoft Office and Microsoft 365 suite of productivity applications, which most notably include the Word word processor and Excel spreadsheet editor. Its flagship hardware products are the Surface lineup of personal computers and Xbox video game consoles, the latter of which includes the Xbox network; the company also provides a range of consumer Internet services such as Bing web search, the MSN web portal, the Outlook.com email service and the Microsoft Store. In the enterprise and development fields, Microsoft most notably provides the Azure cloud computing platform, Microsoft SQL Server database software, and Visual Studio.\n\nMicrosoft is considered one of the Big Five American information technology companies, alongside Alphabet,[c] Amazon, Apple, and Meta.[d] In April 2019, Microsoft reached a trillion-dollar market cap, becoming the third public U.S. company to be valued at over $1 trillion. It has been criticized for its monopolistic practices, and the company's software has been criticized for problems with ease of use, robustness, and security.\n\nChildhood friends Bill Gates and Paul Allen sought to make a business using their skills in computer programming.[12] In 1972, they founded Traf-O-Data, which sold a rudimentary computer to track and analyze automobile traffic data. Gates enrolled at Harvard University while Allen pursued a degree in computer science at Washington State University, though he later dropped out to work at Honeywell.[13] The January 1975 issue of Popular Electronics featured Micro Instrumentation and Telemetry Systems's (MITS) Altair 8800 microcomputer,[14] which inspired Allen to suggest that they could program a BASIC interpreter for the device. Gates called MITS and claimed that he had a working interpreter, and MITS requested a demonstration. Allen worked on a simulator for the Altair while Gates developed the interpreter, and it worked flawlessly when they demonstrated it to MITS in March 1975 in Albuquerque, New Mexico. MITS agreed to distribute it, marketing it as Altair BASIC.[11]: 108, 112–114  Gates and Allen established Microsoft on April 4, 1975, with Gates as CEO,[15] and Allen suggested the name \"Micro-Soft\", short for micro-computer software.[16][17] In August 1977, the company formed an agreement with ASCII Magazine in Japan, resulting in its first international office of ASCII Microsoft.[18] Microsoft moved its headquarters to Bellevue, Washington, in January 1979.[15]\n\nMicrosoft entered the operating system (OS) business in 1980 with its own version of Unix called Xenix,[19] but it was MS-DOS that solidified the company's dominance. IBM awarded a contract to Microsoft in November 1980 to provide a version of the CP/M OS to be used in the IBM Personal Computer (IBM PC).[20] For this deal, Microsoft purchased a CP/M clone called 86-DOS from Seattle Computer Products which it branded as MS-DOS, although IBM rebranded it to IBM PC DOS. Microsoft retained ownership of MS-DOS following the release of the IBM PC in August 1981. IBM had copyrighted the IBM PC BIOS, so other companies had to reverse engineer it for non-IBM hardware to run as IBM PC compatibles, but no such restriction applied to the operating systems. Microsoft eventually became the leading PC operating systems vendor.[21][22]: 210  The company expanded into new markets with the release of the Microsoft Mouse in 1983, as well as with a publishing division named Microsoft Press.[11]: 232 \nPaul Allen resigned from Microsoft in 1983 after developing Hodgkin's lymphoma.[23] Allen claimed in Idea Man: A Memoir by the co-founder of Microsoft that Gates wanted to dilute his share in the company when he was diagnosed with Hodgkin's disease because he did not think that he was working hard enough.[24] Allen later invested in low-tech sectors, sports teams, commercial real estate, neuroscience, private space flight, and more.[25]\n\nMicrosoft released Windows 1.0 on November 20, 1985, as a graphical extension for MS-DOS,[11]: 242–243, 246  despite having begun jointly developing OS/2 with IBM that August.[26] Microsoft moved its headquarters from Bellevue to Redmond, Washington, on February 26, 1986, and went public with an initial public offering (IPO) at the NASDAQ exchange on March 13,[27] with the resulting rise in stock making an estimated four billionaires and 12,000 millionaires from Microsoft employees.[28] Microsoft released its version of OS/2 to original equipment manufacturers (OEMs) on April 2, 1987.[11] In 1990, the Federal Trade Commission examined Microsoft for possible collusion due to the partnership with IBM, marking the beginning of more than a decade of legal clashes with the government.[29] : 243–244  Meanwhile, the company was at work on Microsoft Windows NT, which was heavily based on their copy of the OS/2 code. It shipped on July 21, 1993, with a new modular kernel and the 32-bit Win32 application programming interface (API), making it easier to port from 16-bit (MS-DOS-based) Windows. Microsoft informed IBM of Windows NT, and the OS/2 partnership deteriorated.[30]\n\nIn 1990, Microsoft introduced the Microsoft Office suite which bundled separate applications such as Microsoft Word and Microsoft Excel.[11]: 301  On May 22, Microsoft launched Windows 3.0, featuring streamlined user interface graphics and improved protected mode capability for the Intel 386 processor,[31] and both Office and Windows became dominant in their respective areas.[32][33]\n\nOn July 27, 1994, the Department of Justice's Antitrust Division filed a competitive impact statement that said: \"Beginning in 1988 and continuing until July 15, 1994, Microsoft induced many OEMs to execute anti-competitive 'per processor licenses. Under a per-processor license, an OEM pays Microsoft a royalty for each computer it sells containing a particular microprocessor, whether the OEM sells the computer with a Microsoft operating system or a non-Microsoft operating system. In effect, the royalty payment to Microsoft when no Microsoft product is being used acts as a penalty, or tax, on the OEM's use of a competing PC operating system. Since 1988, Microsoft's use of per processor licenses has increased.\"[34]\n\nFollowing Bill Gates's internal \"Internet Tidal Wave memo\" on May 26, 1995, Microsoft began to redefine its offerings and expand its product line into computer networking and the World Wide Web.[35] With a few exceptions of new companies, like Netscape, Microsoft was the only major and established company that acted fast enough to be a part of the World Wide Web practically from the start. Other companies like Borland, WordPerfect, Novell, IBM and Lotus, being much slower to adapt to the new situation, would give Microsoft market dominance.[36]\n\nThe company released Windows 95 on August 24, 1995, featuring pre-emptive multitasking, a completely new user interface with a novel start button, and 32-bit compatibility; similar to NT, it provided the Win32 API.[37][38]: 20  Windows 95 came bundled with the online service MSN, which was at first intended to be a competitor to the Internet,[dubious – discuss] and (for OEMs) Internet Explorer, a Web browser. Internet Explorer was not bundled with the retail Windows 95 boxes, because the boxes were printed before the team finished the Web browser, and instead were included in the Windows 95 Plus! pack.[39] Backed by a high-profile marketing campaign[40] and what The New York Times called \"the splashiest, most frenzied, most expensive introduction of a computer product in the industry's history,\"[41] Windows 95 quickly became a success.[42] Branching out into new markets in 1996, Microsoft and General Electric's NBC unit created a new 24/7 cable news channel, MSNBC.[43] Microsoft created Windows CE 1.0, a new OS designed for devices with low memory and other constraints, such as personal digital assistants.[44] In October 1997, the Justice Department filed a motion in the Federal District Court, stating that Microsoft violated an agreement signed in 1994 and asked the court to stop the bundling of Internet Explorer with Windows.[11]: 323–324 \n\nOn January 13, 2000, Bill Gates handed over the CEO position to Steve Ballmer, an old college friend of Gates and employee of the company since 1980, while creating a new position for himself as Chief Software Architect.[11]: 111, 228 [15] Various companies including Microsoft formed the Trusted Computing Platform Alliance in October 1999 to (among other things) increase security and protect intellectual property through identifying changes in hardware and software. Critics decried the alliance as a way to enforce indiscriminate restrictions over how consumers use software, and over how computers behave, and as a form of digital rights management: for example, the scenario where a computer is not only secured for its owner but also secured against its owner as well.[45][46] On April 3, 2000, a judgment was handed down in the case of United States v. Microsoft Corp.,[47] calling the company an \"abusive monopoly.\"[48] Microsoft later settled with the U.S. Department of Justice in 2004.[27]\n\nOn October 25, 2001, Microsoft released Windows XP, unifying the mainstream and NT lines of OS under the NT codebase.[49] The company released the Xbox later that year, entering the video game console market dominated by Sony and Nintendo.[50] In March 2004 the European Union brought antitrust legal action against the company, citing it abused its dominance with the Windows OS, resulting in a judgment of €497 million ($613 million) and requiring Microsoft to produce new versions of Windows XP without Windows Media Player: Windows XP Home Edition N and Windows XP Professional N.[51][52] In November 2005, the company's second video game console, the Xbox 360, was released. There were two versions, a basic version for $299.99 and a deluxe version for $399.99.[53]\n\nIncreasingly present in the hardware business following Xbox, Microsoft 2006 released the Zune series of digital media players, a successor of its previous software platform Portable Media Center. These expanded on previous hardware commitments from Microsoft following its original Microsoft Mouse in 1983; as of 2007 the company sold the best-selling wired keyboard (Natural Ergonomic Keyboard 4000), mouse (IntelliMouse), and desktop webcam (LifeCam) in the United States. That year the company also launched the Surface \"digital table\", later renamed PixelSense.[54]\n\nReleased in January 2007, the next version of Windows, Vista, focused on features, security and a redesigned user interface dubbed Aero.[56][57] Microsoft Office 2007, released at the same time, featured a \"Ribbon\" user interface which was a significant departure from its predecessors. Relatively strong sales of both products helped to produce a record profit in 2007.[58] The European Union imposed another fine of €899 million ($1.4 billion) for Microsoft's lack of compliance with the March 2004 judgment on February 27, 2008, saying that the company charged rivals unreasonable prices for key information about its workgroup and backoffice servers.[59] Microsoft stated that it was in compliance and that \"these fines are about the past issues that have been resolved\".[60] 2007 also saw the creation of a multi-core unit at Microsoft, following the steps of server companies such as Sun and IBM.[61]\n\nGates retired from his role as Chief Software Architect on June 27, 2008, a decision announced in June 2006, while retaining other positions related to the company in addition to being an advisor for the company on key projects.[62][63] Azure Services Platform, the company's entry into the cloud computing market for Windows, launched on October 27, 2008.[64] On February 12, 2009, Microsoft announced its intent to open a chain of Microsoft-branded retail stores, and on October 22, 2009, the first retail Microsoft Store opened in Scottsdale, Arizona; the same day Windows 7 was officially released to the public. Windows 7's focus was on refining Vista with ease-of-use features and performance enhancements, rather than an extensive reworking of Windows.[65][66][67]\n\nAs the smartphone industry boomed in the late 2000s, Microsoft had struggled to keep up with its rivals in providing a modern smartphone operating system, falling behind Apple and Google-sponsored Android in the United States.[68] As a result, in 2010 Microsoft revamped their aging flagship mobile operating system, Windows Mobile, replacing it with the new Windows Phone OS that was released in October that year.[69][70] It used a new user interface design language, codenamed \"Metro\", which prominently used simple shapes, typography, and iconography, utilizing the concept of minimalism. Microsoft implemented a new strategy for the software industry, providing a consistent user experience across all smartphones using the Windows Phone OS. It launched an alliance with Nokia in 2011 and Microsoft worked closely with the company to co-develop Windows Phone,[71] but remained partners with long-time Windows Mobile OEM HTC.[72] Microsoft is a founding member of the Open Networking Foundation started on March 23, 2011. Fellow founders were Google, HPE Networking, Yahoo!, Verizon Communications, Deutsche Telekom and 17 other companies. This nonprofit organization is focused on providing support for a cloud computing initiative called Software-Defined Networking.[73] The initiative is meant to speed innovation through simple software changes in telecommunications networks, wireless networks, data centers, and other networking areas.[74]\n\nFollowing the release of Windows Phone, Microsoft undertook a gradual rebranding of its product range throughout 2011 and 2012, with the corporation's logos, products, services, and websites adopting the principles and concepts of the Metro design language.[75] Microsoft unveiled Windows 8, an operating system designed to power both personal computers and tablet computers, in Taipei in June 2011.[76] A developer preview was released on September 13, which was subsequently replaced by a consumer preview on February 29, 2012, and released to the public in May.[77] The Surface was unveiled on June 18, becoming the first computer in the company's history to have its hardware made by Microsoft.[78][79] On June 25, Microsoft paid US$1.2 billion to buy the social network Yammer.[80] On July 31, they launched the Outlook.com webmail service to compete with Gmail.[81] On September 4, 2012, Microsoft released Windows Server 2012.[82]\n\nIn July 2012, Microsoft sold its 50% stake in MSNBC, which it had run as a joint venture with NBC since 1996.[83] On October 1, Microsoft announced its intention to launch a news operation, part of a new-look MSN, with Windows 8 later in the month.[84] On October 26, 2012, Microsoft launched Windows 8 and the Microsoft Surface.[79][85] Three days later, Windows Phone 8 was launched.[86] To cope with the potential for an increase in demand for products and services, Microsoft opened a number of \"holiday stores\" across the U.S. to complement the increasing number of \"bricks-and-mortar\" Microsoft Stores that opened in 2012.[87] On March 29, 2013, Microsoft launched a Patent Tracker.[88]\n\nIn August 2012, the New York City Police Department announced a partnership with Microsoft for the development of the Domain Awareness System which is used for Police surveillance in New York City.[89]\n\nThe Kinect, a motion-sensing input device made by Microsoft and designed as a video game controller, first introduced in November 2010, was upgraded for the 2013 release of the Xbox One video game console. Kinect's capabilities were revealed in May 2013: an ultra-wide 1080p camera, function in the dark due to an infrared sensor, higher-end processing power and new software, the ability to distinguish between fine movements (such as a thumb movement), and determining a user's heart rate by looking at their face.[90] Microsoft filed a patent application in 2011 that suggests that the corporation may use the Kinect camera system to monitor the behavior of television viewers as part of a plan to make the viewing experience more interactive.[91] On July 19, 2013, Microsoft stocks suffered their biggest one-day percentage sell-off since the year 2000, after its fourth-quarter report raised concerns among investors on the poor showings of both Windows 8 and the Surface tablet. Microsoft suffered a loss of more than US$32 billion.[92]\n\nIn line with the maturing PC business, in July 2013, Microsoft announced that it would reorganize the business into four new business divisions, namely Operating systems, Apps, Cloud, and Devices. All previous divisions will be dissolved into new divisions without any workforce cuts.[93] On September 3, 2013, Microsoft agreed to buy Nokia's mobile unit for $7 billion,[94] following Amy Hood taking the role of CFO.[95]\n\nOn February 4, 2014, Steve Ballmer stepped down as CEO of Microsoft and was succeeded by Satya Nadella, who previously led Microsoft's Cloud and Enterprise division.[96] On the same day, John W. Thompson took on the role of chairman, in place of Bill Gates, who continued to participate as a technology advisor.[97] Thompson became the second chairman in Microsoft's history.[98] On April 25, 2014, Microsoft acquired Nokia Devices and Services for $7.2 billion.[99] This new subsidiary was renamed Microsoft Mobile Oy.[100] On September 15, 2014, Microsoft acquired the video game development company Mojang, best known for Minecraft, for $2.5 billion.[101] On June 8, 2017, Microsoft acquired Hexadite, an Israeli security firm, for $100 million.[102][103]\n\nOn January 21, 2015, Microsoft announced the release of their first Interactive whiteboard, Microsoft Surface Hub.[104] On July 29, 2015, Windows 10 was released,[105] with its server sibling, Windows Server 2016, released in September 2016. In Q1 2015, Microsoft was the third-largest maker of mobile phones, selling 33 million units (7.2% of all). While a large majority (at least 75%) of them do not run any version of Windows Phone — those other phones are not categorized as smartphones by Gartner – in the same timeframe 8 million Windows smartphones (2.5% of all smartphones) were made by all manufacturers (mostly Microsoft).[106] Microsoft's share of the U.S. smartphone market in January 2016 was 2.7%.[107] During the summer of 2015 the company lost $7.6 billion related to its mobile-phone business, firing 7,800 employees.[108]\n\nIn 2015, the construction of a data center in Mecklenburg County, Virginia led to the destruction of a historic African American cemetery despite archeological recommendations for preservation.[109]\n\nOn March 1, 2016, Microsoft announced the merger of its PC and Xbox divisions, with Phil Spencer announcing that Universal Windows Platform (UWP) apps would be the focus for Microsoft's gaming in the future.[110] On January 24, 2017, Microsoft showcased Intune for Education at the BETT 2017 education technology conference in London.[111] Intune for Education is a new cloud-based application and device management service for the education sector.[112] In May 2016, the company announced it was laying off 1,850 workers, and taking an impairment and restructuring charge of $950 million.[108]\n\nIn June 2016, Microsoft announced a project named Microsoft Azure Information Protection. It aims to help enterprises protect their data as it moves between servers and devices.[113] In November 2016, Microsoft joined the Linux Foundation as a Platinum member during Microsoft's Connect(); developer event in New York.[114] The cost of each Platinum membership is US$500,000 per year.[115] Some analysts deemed this unthinkable ten years prior, however, as in 2001 then-CEO Steve Ballmer called Linux \"cancer\".[116] Microsoft planned to launch a preview of Intune for Education \"in the coming weeks\", with general availability scheduled for spring 2017, priced at $30 per device, or through volume licensing agreements.[117]\n\nIn January 2018, Microsoft patched Windows 10 to account for CPU problems related to Intel's Meltdown security breach. The patch led to issues with the Microsoft Azure virtual machines reliant on Intel's CPU architecture. On January 12, Microsoft released PowerShell Core 6.0 for the macOS and Linux operating systems.[118] In February 2018, Microsoft killed notification support for their Windows Phone devices which effectively ended firmware updates for the discontinued devices.[118] In March 2018, Microsoft recalled Windows 10 S to change it to a mode for the Windows operating system rather than a separate and unique operating system. In March the company also established guidelines that censor users of Office 365 from using profanity in private documents.[118]\n\nIn April 2018, Microsoft released the source code for Windows File Manager under the MIT License to celebrate the program's 20th anniversary. In April the company further expressed willingness to embrace open source initiatives by announcing Azure Sphere as its own derivative of the Linux operating system.[118] In May 2018, Microsoft partnered with 17 American intelligence agencies to develop cloud computing products. The project is dubbed \"Azure Government\" and has ties to the Joint Enterprise Defense Infrastructure (JEDI) surveillance program.[118] On June 4, 2018, Microsoft officially announced the acquisition of GitHub for $7.5 billion, a deal that closed on October 26, 2018.[119][120] On July 10, 2018, Microsoft revealed the Surface Go platform to the public. Later in the month, it converted Microsoft Teams to gratis.[118] In August 2018, Microsoft released two projects called Microsoft AccountGuard and Defending Democracy. It also unveiled Snapdragon 850 compatibility for Windows 10 on the ARM architecture.[121][122][118]\n\nIn August 2018, Toyota Tsusho began a partnership with Microsoft to create fish farming tools using the Microsoft Azure application suite for Internet of things (IoT) technologies related to water management. Developed in part by researchers from Kindai University, the water pump mechanisms use artificial intelligence to count the number of fish on a conveyor belt, analyze the number of fish, and deduce the effectiveness of water flow from the data the fish provide. The specific computer programs used in the process fall under the Azure Machine Learning and the Azure IoT Hub platforms.[123]\n\nIn September 2018, Microsoft discontinued Skype Classic.[118] On October 10, 2018, Microsoft joined the Open Invention Network community despite holding more than 60,000 patents.[124] In November 2018, Microsoft agreed to supply 100,000 Microsoft HoloLens headsets to the United States military in order to \"increase lethality by enhancing the ability to detect, decide and engage before the enemy.\"[125] In November 2018, Microsoft introduced Azure Multi-Factor Authentication for Microsoft Azure.[126] In December 2018, Microsoft announced Project Mu, an open source release of the Unified Extensible Firmware Interface (UEFI) core used in Microsoft Surface and Hyper-V products. The project promotes the idea of Firmware as a Service.[127] In the same month, Microsoft announced the open source implementation of Windows Forms and the Windows Presentation Foundation (WPF) which will allow for further movement of the company toward the transparent release of key frameworks used in developing Windows desktop applications and software. December also saw the company discontinue the Microsoft Edge [Legacy] browser project in favor of the \"New Edge\" browser project, featuring a Chromium based backend.[126]\n\nOn February 20, 2019, Microsoft Corp said it will offer its cyber security service AccountGuard to 12 new markets in Europe including Germany, France and Spain, to close security gaps and protect customers in political space from hacking.[128] In February 2019, hundreds of Microsoft employees protested the company's war profiteering from a $480 million contract to develop virtual reality headsets for the United States Army.[129]\n\nOn March 26, 2020, Microsoft announced it was acquiring Affirmed Networks for about $1.35 billion.[130][131] Due to the COVID-19 pandemic, Microsoft closed all of its retail stores indefinitely due to health concerns.[132] On July 22, 2020, Microsoft announced plans to close its Mixer service, planning to move existing partners to Facebook Gaming.[133]\n\nOn July 31, 2020, it was reported that Microsoft was in talks to acquire TikTok after the Trump administration ordered ByteDance to divest ownership of the application to the U.S.[134] On August 3, 2020, after speculation on the deal, Donald Trump stated that Microsoft could buy the application, however, it should be completed by September 15, 2020, and that the United States Department of the Treasury should receive a portion if it were to go through.[135]\n\nOn August 5, 2020, Microsoft stopped its xCloud game streaming test for iOS devices. According to Microsoft, the future of xCloud on iOS remains unclear and potentially out of Microsoft's hands. Apple has imposed a strict limit on \"remote desktop clients\" which means applications are only allowed to connect to a user-owned host device or gaming console owned by the user.[136] On September 21, 2020, Microsoft announced its intent to acquire video game company ZeniMax Media, the parent company of Bethesda Softworks, for about $7.5 billion, with the deal expected to occur in the second half of 2021 fiscal year.[137] On March 9, 2021, the acquisition was finalized and ZeniMax Media became part of Microsoft's Xbox Game Studios division.[138] The total price of the deal was $8.1 billion.[139]\n\nOn September 22, 2020, Microsoft announced that it had an exclusive license to use OpenAI's GPT-3 artificial intelligence language generator.[140] The previous version of GPT-3, called GPT-2, made headlines for being \"too dangerous to release\" and had numerous capabilities, including designing websites, prescribing medication, answering questions, and penning articles.[141]\n\nOn November 10, 2020, Microsoft released the Xbox Series X and Xbox Series S video game consoles.[142]\n\nIn February 2021, Microsoft released Azure Quantum for public preview.[143] The public cloud computing platform provides access to quantum software and quantum hardware including trapped ion, neutral atom, and superconducting systems.[144][145][146][147]\n\nIn April 2021, Microsoft announced it would buy Nuance Communications for approximately $16 billion.[148] The acquisition of Nuance was completed in March 2022.[149] In 2021, in part due to the strong quarterly earnings spurred by the COVID-19 pandemic, Microsoft's valuation came to nearly $2 trillion. The increased necessity for remote work and distance education drove demand for cloud computing and grew the company's gaming sales.[150][151][152]\n\nOn June 24, 2021, Microsoft announced Windows 11 during a Livestream. The announcement came with confusion after Microsoft announced Windows 10 would be the last version of the operating system; set to be released in the third quarter of 2021.[153] It was released to the general public on October 5, 2021.[154]\n\nIn September 2021, it was announced that the company had acquired Takelessons, an online platform that connects students and tutors in numerous subjects. The acquisition positioned Microsoft to grow its presence in the market of providing online education to large numbers of people.[155] In the same month, Microsoft acquired Australia-based video editing software company Clipchamp.[156]\n\nIn October 2021, Microsoft announced that it began rolling out end-to-end encryption (E2EE) support for Microsoft Teams calls in order to secure business communication while using video conferencing software. Users can ensure that their calls are encrypted and can utilize a security code that both parties on a call must verify on their respective ends.[157] On October 7, Microsoft acquired Ally.io, a software service that measures companies' progress against OKRs. Microsoft plans to incorporate Ally.io into its Viva family of employee experience products.[158]\n\nOn January 18, 2022, Microsoft announced the acquisition of American video game developer and holding company Activision Blizzard in an all-cash deal worth $68.7 billion.[159] Activision Blizzard is best known for producing franchises, including but not limited to Warcraft, Diablo, Call of Duty, StarCraft, Candy Crush Saga, Crash Bandicoot, Spyro, Tony Hawk's, Guitar Hero, and Overwatch.[160] Activision and Microsoft each released statements saying the acquisition was to benefit their businesses in the metaverse, many saw Microsoft's acquisition of video game studios as an attempt to compete against Meta Platforms, with TheStreet referring to Microsoft wanting to become \"the Disney of the metaverse\".[161][162] Microsoft also named Phil Spencer, head of the Xbox brand since 2014, the inaugural CEO of the newly established Microsoft Gaming division, which now houses the Xbox operations team and the three publishers in the company's portfolio (Xbox Game Studios, ZeniMax Media, Activision Blizzard). Microsoft has not released statements regarding Activision's recent legal controversies regarding employee abuse, but reports have alleged that Activision CEO Bobby Kotick, a major target of the controversy, will leave the company after the acquisition is finalized.[163] The deal was closed on October 13, 2023.[164]\n\nIn December 2022, Microsoft announced a new 10-year deal with the London Stock Exchange Group for products including Microsoft Azure; Microsoft acquired around 4% of LSEG as part of the deal.[165]\n\nIn January 2023, CEO Satya Nadella announced Microsoft would lay off some 10,000 employees.[166] The announcement came a day after hosting a Sting concert for 50 people, including Microsoft executives, in Davos, Switzerland.[167]\n\nOn January 23, 2023, Microsoft announced a new multi-year, multi-billion dollar investment deal with ChatGPT developer OpenAI.[168]\n\nIn June 2023, Microsoft released Azure Quantum Elements to run molecular simulations and calculations in computational chemistry and materials science using a combination of AI, high-performance computing and quantum computing.[169] The service includes Copilot, a GPT-4 based large language model tool to query and visualize data, write code, initiate simulations, and educate researchers.[169]\n\nAt a November 2023 developer conference, Microsoft announced two new custom-designed computing chips: The Maia chip, designed to run large language models, and Cobalt CPU, designed to power general cloud services on Azure.[170][171]\n\nOn November 20, 2023, Satya Nadella announced that Sam Altman, who had been ousted as CEO of OpenAI just days earlier, and Greg Brockman, who had resigned as president, would join Microsoft to lead a new advanced AI research team.[172][173] However, the plan was short-lived, as Altman was subsequently reinstated as OpenAI's CEO and Brockman rejoined the company amid pressure from OpenAI's employees and investors on its board.[174] In March 2024, Inflection AI's cofounders Mustafa Suleyman and Karen Simonyan announced their departure from the company in order to start Microsoft AI, with Microsoft acqui-hiring nearly the entirety of its 70-person workforce. As part of the deal, Microsoft paid Inflection $650 million to license its technology.[175][176]\n\nIn January 2024, Microsoft became the most valued publicly traded company. Meanwhile, that month, the company announced a subscription offering of artificial intelligence for small businesses via Copilot Pro.[177][178]\n\nIn April 2024, Microsoft made a $1.5 billion investment in the Emirati AI firm G42. As part of the deal, G42 said it would use the Microsoft Azure platform for its AI development and deployment.[179][180] Later that month, Microsoft unveiled plans to invest $1.7 billion in developing AI and cloud infrastructure in Indonesia. The plan includes establishment of data centers and partnerships to support digital transformation efforts.[181]\n\nIn May 2024, Microsoft announced a $3.3 billion investment to build an artificial intelligence hub in southeast Wisconsin, tripling its initial proposal. This initiative, unveiled by President Joe Biden in Racine County, includes constructing a data center, creating 2,300 construction jobs by 2025, and 2,000 permanent jobs over time, alongside establishing an AI co-innovation lab at UW-Milwaukee to train up to 1,000 individuals by 2030.[182]\n\nIn June 2024, Microsoft announced it would be laying off 1,000 employees from the company's mixed reality and Azure cloud computing divisions.[183][184]\n\nIn June 2024, Microsoft announced that they were building a \"hyperscale data centre\" in South East Leeds.[185] In July 2024, it was reported that the company was laying off its diversity, equity, and inclusion (DEI) team.[186][187]\n\nOn July 19, 2024, a global IT outage impacted Microsoft services, affecting businesses, airlines, and financial institutions worldwide. The outage was traced back to a flawed update of CrowdStrike's cybersecurity software, which resulted in Microsoft systems crashing and causing disruptions across various sectors. Despite CrowdStrike's CEO George Kurtz clarifying that the issue was not a cyberattack, the incident had widespread consequences, leading to delays in air travel, financial transactions, and medical services globally. Microsoft stated that the underlying cause had been fixed but acknowledged ongoing residual impacts on some Microsoft 365 apps and services.[188][189]\n\nIn September 2024, BlackRock and Microsoft announced a $30 billion fund, the Global AI Infrastructure Investment Partnership, to invest in AI infrastructure such as data centers and energy projects. The fund has the potential to reach $100 billion with debt financing, and partners include Abu Dhabi-backed MGX and Nvidia, which will provide AI expertise. Investments will primarily focus on the U.S., with some in partner countries.[190] Microsoft also announced relaunch of its controversial tool, Recall, in November 2024 after addressing privacy concerns. Initially criticized for taking regular screenshots without user consent, Recall was changed to an opt-in feature instead of being default on. The UK's Information Commissioner's Office monitored the situation and noted the adjustments, which included enhanced security measures like encryption and biometric access. While experts regarded these changes as improvements, they advised caution, with some recommending further testing before users opted in.[191]\n\nMicrosoft is ranked No. 14 in the 2022 Fortune 500 rankings of the largest United States corporations by total revenue;[192] and it was the world's largest software maker by revenue in 2022 according to Forbes Global 2000. In 2018, Microsoft became the most valuable publicly traded company in the world,[193] a position it has repeatedly traded with Apple in the years since.[194] In April 2019, Microsoft reached a trillion-dollar market cap, becoming the third U.S. public company to be valued at over $1 trillion.[e] As of 2024[update], Microsoft has the third-highest global brand valuation. Microsoft is one of only two U.S.-based companies that have a prime credit rating of AAA.[195]\n\nThe company is run by a board of directors made up of mostly company outsiders, as is customary for publicly traded companies. Members of the board of directors as of December 2023 are Satya Nadella, Reid Hoffman, Hugh Johnston, Teri List, Sandi Peterson, Penny Pritzker, Carlos Rodriguez, Charles Scharf, John W. Stanton, John W. Thompson, Emma Walmsley and Padmasree Warrior.[196]\n\nBoard members are elected every year at the annual shareholders' meeting using a majority vote system. There are four committees within the board that oversee more specific matters. These committees include the Audit Committee, which handles accounting issues with the company including auditing and reporting; the Compensation Committee, which approves compensation for the CEO and other employees of the company; the Governance and Nominating Committee, which handles various corporate matters including the nomination of the board; and the Regulatory and Public Policy Committee, which includes legal/antitrust matters, along with privacy, trade, digital safety, artificial intelligence, and environmental sustainability.[197]\n\nOn March 13, 2020, Gates announced that he is leaving the board of directors of Microsoft and Berkshire Hathaway to focus more on his philanthropic efforts. According to Aaron Tilley of The Wall Street Journal this is \"marking the biggest boardroom departure in the tech industry since the death of longtime rival and Apple Inc. co-founder Steve Jobs.\"[198]\n\nOn January 13, 2022, The Wall Street Journal reported that Microsoft's board of directors plans to hire an external law firm to review its sexual harassment and gender discrimination policies, and to release a summary of how the company handled past allegations of misconduct against Bill Gates and other corporate executives.[199]\n\nWhen Microsoft went public and launched its initial public offering (IPO) in 1986, the opening stock price was $21; after the trading day, the price closed at $27.75. As of July 2010, with the company's nine stock splits, any IPO shares would be multiplied by 288; if one were to buy the IPO today, given the splits and other factors, it would cost about 9 cents.[11]: 235–236 [201][202] The stock price peaked in 1999 at around $119 ($60.928, adjusting for splits).[203] The company began to offer a dividend on January 16, 2003, starting at eight cents per share for the fiscal year followed by a dividend of sixteen cents per share the subsequent year, switching from yearly to quarterly dividends in 2005 with eight cents a share per quarter and a special one-time payout of three dollars per share for the second quarter of the fiscal year.[203][204] Though the company had subsequent increases in dividend payouts, the price of Microsoft's stock remained steady for years.[204][205]\n\nStandard \u0026 Poor's and Moody's Investors Service have both given a AAA rating to Microsoft, whose assets were valued at $41 billion as compared to only $8.5 billion in unsecured debt. Consequently, in February 2011 Microsoft released a corporate bond amounting to $2.25 billion with relatively low borrowing rates compared to government bonds.[206] For the first time in 20 years Apple Inc. surpassed Microsoft in Q1 2011 quarterly profits and revenues due to a slowdown in PC sales and continuing huge losses in Microsoft's Online Services Division (which contains its search engine Bing). Microsoft profits were $5.2 billion, while Apple Inc. profits were $6 billion, on revenues of $14.5 billion and $24.7 billion respectively.[207] Microsoft's Online Services Division has been continuously loss-making since 2006 and in Q1 2011 it lost $726 million. This follows a loss of $2.5 billion for the year 2010.[208]\n\nOn July 20, 2012, Microsoft posted its first quarterly loss ever, despite earning record revenues for the quarter and fiscal year, with a net loss of $492 million due to a writedown related to the advertising company aQuantive, which had been acquired for $6.2 billion back in 2007.[210] As of January 2014, Microsoft's market capitalization stood at $314B,[211] making it the 8th-largest company in the world by market capitalization.[212] On November 14, 2014, Microsoft overtook ExxonMobil to become the second most-valuable company by market capitalization, behind only Apple Inc. Its total market value was over $410B—with the stock price hitting $50.04 a share, the highest since early 2000.[213] In 2015, Reuters reported that Microsoft Corp had earnings abroad of $76.4 billion which were untaxed by the Internal Revenue Service. Under U.S. law, corporations do not pay income tax on overseas profits until the profits are brought into the United States.[214]\n\nThe key trends of Microsoft are (as at the financial year ending June 30):[215][216]\n\nIn November 2018, the company won a $480 million military contract with the U.S. government to bring augmented reality (AR) headset technology into the weapon repertoires of American soldiers. The two-year contract may result in follow-on orders of more than 100,000 headsets, according to documentation describing the bidding process. One of the contract's tag lines for the augmented reality technology seems to be its ability to enable \"25 bloodless battles before the 1st battle\", suggesting that actual combat training is going to be an essential aspect of the augmented reality headset capabilities.[219]\n\nMicrosoft is an international business. As such, it needs subsidiaries present in whatever national markets it chooses to harvest. An example is Microsoft Canada, which it established in 1985.[220] Other countries have similar installations, to funnel profits back up to Redmond and to distribute the dividends to the holders of MSFT stock.\n\nThe 10 largest shareholder of Microsoft in early 2024 were:[209][221]\n\nIn 2004, Microsoft commissioned research firms to do independent studies comparing the total cost of ownership (TCO) of Windows Server 2003 to Linux; the firms concluded that companies found Windows easier to administrate than Linux, thus those using Windows would administrate faster resulting in lower costs for their company (i.e. lower TCO).[222] This spurred a wave of related studies; a study by the Yankee Group concluded that upgrading from one version of Windows Server to another costs a fraction of the switching costs from Windows Server to Linux, although companies surveyed noted the increased security and reliability of Linux servers and concern about being locked into using Microsoft products.[223] Another study, released by the Open Source Development Labs, claimed that the Microsoft studies were \"simply outdated and one-sided\" and their survey concluded that the TCO of Linux was lower due to Linux administrators managing more servers on average and other reasons.[224]\n\nAs part of the \"Get the Facts\" campaign, Microsoft highlighted the .NET Framework trading platform that it had developed in partnership with Accenture for the London Stock Exchange, claiming that it provided \"five nines\" reliability. After suffering extended downtime and unreliability[225][226] the London Stock Exchange announced in 2009 that it was planning to drop its Microsoft solution and switch to a Linux-based one in 2010.[227][228]\n\nIn 2012, Microsoft hired a political pollster named Mark Penn, whom The New York Times called \"famous for bulldozing\" his political opponents[229] as Executive Vice-president, Advertising and Strategy. Penn created a series of negative advertisements targeting one of Microsoft's chief competitors, Google. The advertisements, called \"Scroogled\", attempt to make the case that Google is \"screwing\" consumers with search results rigged to favor Google's paid advertisers, that Gmail violates the privacy of its users to place ad results related to the content of their emails and shopping results, which favor Google products. Tech publications like TechCrunch have been highly critical of the advertising campaign,[230] while Google employees have embraced it.[231]\n\nIn July 2014, Microsoft announced plans to lay off 18,000 employees. Microsoft employed 127,104 people as of June 5, 2014, making this about a 14 percent reduction of its workforce as the biggest Microsoft layoff ever. This included 12,500 professional and factory personnel. Previously, Microsoft had eliminated 5,800 jobs in 2009 in line with the Great Recession of 2008–2017.[232][233] In September 2014, Microsoft laid off 2,100 people, including 747 people in the Seattle–Redmond area, where the company is headquartered. The firings came as a second wave of the layoffs that were previously announced. This brought the total number to over 15,000 out of the 18,000 expected cuts.[234] In October 2014, Microsoft revealed that it was almost done with eliminating 18,000 employees, which was its largest-ever layoff sweep.[235] In July 2015, Microsoft announced another 7,800 job cuts in the next several months.[236] In May 2016, Microsoft announced another 1,850 job cuts mostly in its Nokia mobile phone division. As a result, the company will record an impairment and restructuring charge of approximately $950 million, of which approximately $200 million will relate to severance payments.[237]\n\nMicrosoft laid off 1,900 employees in its gaming division in January 2024. The layoffs primarily affected Activision Blizzard employees, but some Xbox and ZeniMax employees were also affected.[238] Blizzard president Mike Ybarra and Blizzard's chief design officer Allen Adham also resigned.[239]\n\nMicrosoft recognizes seven trade unions[f] representing 1,750 workers in the United States at its video game subsidiaries Activision Blizzard and ZeniMax Media.[240] U.S. workers have been vocal in opposing military and law-enforcement contracts with Microsoft.[241] Bethesda Game Studios is unionized in Canada.[242] Microsoft South Korea recognizes its union since 2017.[243][244] German employees have elected works councils since 1998.[245]\n\n\nMicrosoft provides information about reported bugs in their software to intelligence agencies of the United States government, prior to the public release of the fix. A Microsoft spokesperson has stated that the corporation runs several programs that facilitate the sharing of such information with the U.S. government.[246] Following media reports about PRISM, NSA's massive electronic surveillance program, in May 2013, several technology companies were identified as participants, including Microsoft.[247] According to leaks of said program, Microsoft joined the PRISM program in 2007.[248] However, in June 2013, an official statement from Microsoft flatly denied their participation in the program: .mw-parser-output .templatequote{overflow:hidden;margin:1em 0;padding:0 32px}.mw-parser-output .templatequotecite{line-height:1.5em;text-align:left;margin-top:0}@media(min-width:500px){.mw-parser-output .templatequotecite{padding-left:1.6em}}\n\"We provide customer data only when we receive a legally binding order or subpoena to do so, and never on a voluntary basis. In addition, we only ever comply with orders for requests about specific accounts or identifiers. If the government has a broader voluntary national security program to gather customer data, we don't participate in it.\"[249]\nDuring the first six months of 2013, Microsoft received requests that affected between 15,000 and 15,999 accounts.[250] In December 2013, the company made a statement to further emphasize the fact that they take their customers' privacy and data protection very seriously, even saying that \"government snooping potentially now constitutes an 'advanced persistent threat,' alongside sophisticated malware and cyber attacks\".[251] The statement also marked the beginning of three-part program to enhance Microsoft's encryption and transparency efforts. On July 1, 2014, as part of this program, they opened the first (of many) Microsoft Transparency Center, which provides \"participating governments with the ability to review source code for our key products, assure themselves of their software integrity, and confirm there are no \"back doors.\"[252] Microsoft has also argued that the United States Congress should enact strong privacy regulations to protect consumer data.[253]\n\nIn April 2016, the company sued the U.S. government, argued that secrecy orders were preventing the company from disclosing warrants to customers in violation of the company's and customers' rights. Microsoft argued that it was unconstitutional for the government to indefinitely ban Microsoft from informing its users that the government was requesting their emails and other documents and that the Fourth Amendment made it so people or businesses had the right to know if the government searches or seizes their property. On October 23, 2017, Microsoft said it would drop the lawsuit as a result of a policy change by the United States Department of Justice (DoJ). The DoJ had \"changed data request rules on alerting the Internet users about agencies accessing their information.\"\n\nIn 2022 Microsoft shared a $9 billion contract from the United States Department of Defense for cloud computing with Amazon, Google, and Oracle.[254]\n\nOn a Friday afternoon in January 2024, Microsoft disclosed that a Russian state-sponsored group hacked into its corporate systems. The group, accessed \"a very small percentage\" of Microsoft corporate email accounts, which also included members of its senior leadership team and employees in its cybersecurity and legal teams.[255] Microsoft noted in a blog post that the attack might have been prevented if the accounts in question had enabled multi-factor authentication, a defensive measure which is widely recommended in the industry, including by Microsoft itself.[256]\n\nTechnical references for developers and articles for various Microsoft magazines such as Microsoft Systems Journal (MSJ) are available through the Microsoft Developer Network (MSDN). MSDN also offers subscriptions for companies and individuals, and the more expensive subscriptions usually offer access to pre-release beta versions of Microsoft software.[257][258] In April 2004, Microsoft launched a community site for developers and users, titled Channel 9, that provides a wiki and an Internet forum.[259] Another community site that provides daily videocasts and other services, On10.net, launched on March 3, 2006.[260] Free technical support is traditionally provided through online Usenet newsgroups, and CompuServe in the past, monitored by Microsoft employees; there can be several newsgroups for a single product. Helpful people can be elected by peers or Microsoft employees for Microsoft Most Valuable Professional (MVP) status, which entitles them to a sort of special social status and possibilities for awards and other benefits.[261]\n\nNoted for its internal lexicon, the expression \"eating your own dog food\" is used to describe the policy of using pre-release and beta versions of products inside Microsoft to test them in \"real-world\" situations.[262] This is usually shortened to just \"dog food\" and is used as a noun, verb, and adjective. Another bit of jargon, FYIFV or FYIV (\"Fuck You, I'm [Fully] Vested\"), is used by an employee to indicate they are financially independent and can avoid work anytime they wish.[263]\n\nMicrosoft is an outspoken opponent of the cap on H-1B visas, which allows companies in the U.S. to employ certain foreign workers. Bill Gates claims the cap on H1B visas makes it difficult to hire employees for the company, stating \"I'd certainly get rid of the H1B cap\" in 2005.[264] Critics of H1B visas argue that relaxing the limits would result in increased unemployment for U.S. citizens due to H1B workers working for lower salaries.[265]\n\nThe Human Rights Campaign Corporate Equality Index, a report of how progressive the organization deems company policies towards LGBT employees, rated Microsoft as 87% from 2002 to 2004 and as 100% from 2005 to 2010 after they allowed gender expression.[266]\n\nIn August 2018, Microsoft implemented a policy for all companies providing subcontractors to require 12 weeks of paid parental leave to each employee. This expands on the former requirement from 2015 requiring 15 days of paid vacation and sick leave each year.[267] In 2015, Microsoft established its own parental leave policy to allow 12 weeks off for parental leave with an additional 8 weeks for the parent who gave birth.[268]\n\nIn 2011, Greenpeace released a report rating the top ten big brands in cloud computing on their sources of electricity for their data centers. At the time, data centers consumed up to 2% of all global electricity, and this amount was projected to increase. Phil Radford of Greenpeace said, \"We are concerned that this new explosion in electricity use could lock us into old, polluting energy sources instead of the clean energy available today\",[269] and called on \"Amazon, Microsoft and other leaders of the information-technology industry must embrace clean energy to power their cloud-based data centers\".[270] In 2013, Microsoft agreed to buy power generated by a Texas wind project to power one of its data centers.[271]\n\nMicrosoft is ranked on the 17th place in Greenpeace's Guide to Greener Electronics (16th Edition) that ranks 18 electronics manufacturers according to their policies on toxic chemicals, recycling, and climate change.[272] Microsoft's timeline for phasing out brominated flame retardant (BFRs) and phthalates in all products was 2012 but its commitment to phasing out PVC is not clear. As of January 2011,[update] it has no products that are completely free from PVC and BFRs.[273][needs update]\n\nMicrosoft's main U.S. campus received a silver certification from the Leadership in Energy and Environmental Design (LEED) program in 2008, and it installed over 2,000 solar panels on top of its buildings at its Silicon Valley campus, generating approximately 15 percent of the total energy needed by the facilities in April 2005.[274] Microsoft makes use of alternative forms of transit. It created one of the world's largest private bus systems, the \"Connector\", to transport people from outside the company; for on-campus transportation, the \"Shuttle Connect\" uses a large fleet of hybrid cars to save fuel. The \"Connector\" does not compete with the public bus system and works with it to provide a cohesive transportation network not just for its employees but also for the public.[275]\n\nMicrosoft also subsidizes regional public transport, provided by Sound Transit and King County Metro, as an incentive.[274][276] In February 2010, however, Microsoft took a stance against adding additional public transport and high-occupancy vehicle (HOV) lanes to the State Route 520 and its floating bridge connecting Redmond to Seattle; the company did not want to delay the construction any further.[277] Microsoft was ranked number 1 in the list of the World's Best Multinational Workplaces by the Great Place to Work Institute in 2011.[278]\n\nIn January 2020, the company announced a strategy to take the company carbon negative by 2030 and to remove all carbon that it has emitted since its foundation in 1975.[279][280][281] On October 9, 2020, Microsoft permanently allowed remote work.[282] In January 2021, the company announced on Twitter to join the Climate Neutral Data Centre Pact, which engages the cloud infrastructure and data centers industries to reach carbon neutrality in Europe by 2030, and also disclosed an investment in Climeworks, a direct air capture company partnered with Carbfix for carbon sequestration.[list 1] In the same year, it was awarded the EPA's Green Power Leadership Award, citing the company's all-renewable energy use since 2014.[288]\n\nIn September 2023, Microsoft announced that it purchased $200 million in carbon credits to offset 315,000 metric tons of carbon dioxide over 10 years from Heirloom Carbon, a carbon removal company that mixes calcium oxide from heated crushed limestone with water to form carbon hydroxide to absorb carbon dioxide from the atmosphere to mineralize back into limestone while the released carbon dioxide is stored underground or injected into concrete.[289][290] Despite spending spent more than $760 million through its Climate Innovation Fund by June 2024 on sustainability projects—including purchases of more than 5 million metric tonnes of carbon dioxide removal with carbon offsets and more than 34 megawatts of renewable energy—Microsoft's Scope 3 emissions had increased by 31% from the company's 2020 baseline, which caused the company's total emissions to rise by 29% in 2023.[291]\n\nIn 2023 Microsoft consumed 24 TWh of electricity, more than countries such as Iceland, Ghana, the Dominican Republic, or Tunisia.[292]\n\nThe corporate headquarters, informally known as the Microsoft Redmond campus, is located at One Microsoft Way in Redmond, Washington. Microsoft initially moved onto the grounds of the campus on February 26, 1986, weeks before the company went public on March 13. The headquarters has since experienced multiple expansions since its establishment. It is estimated to encompass over 8 million ft2 (750,000 m2) of office space and 30,000–40,000 employees.[293] Additional offices are located in Bellevue and Issaquah, Washington (90,000 employees worldwide). The company is planning to upgrade its Mountain View, California, campus on a grand scale. The company has occupied this campus since 1981. In 2016, the company bought the 32-acre (13 ha) campus, with plans to renovate and expand it by 25%.[294] Microsoft operates an East Coast headquarters in Charlotte, North Carolina.[295]\n\nIn April 2024, it was announced that Microsoft would be opening a state-of-the-art artificial intelligence 'hub' around Paddington in London, England. It was announced that the division would be led by Jordan Hoffman, who previously worked for Deepmind and Inflection.[296]\n\nOn October 26, 2015, the company opened its retail location on Fifth Avenue in New York City. The location features a five-story glass storefront and is 22,270 square feet.[297] As per company executives, Microsoft had been on the lookout for a flagship location since 2009.[298] The company's retail locations are part of a greater strategy to help build a connection with its consumers. The opening of the store coincided with the launch of the Surface Book and Surface Pro 4.[299] On November 12, 2015, Microsoft opened a second flagship store, located in Sydney's Pitt Street Mall.[300]\n\nMicrosoft adopted the so-called \"Pac-Man Logo\", designed by Scott Baker, on February 26, 1987, with the concept being similar to InFocus Corporation logo that was adapted a year earlier in 1986. Baker stated \"The new logo, in Helvetica italic typeface, has a slash between the o and s to emphasize the \"soft\" part of the name and convey motion and speed\".[301] Dave Norris ran an internal joke campaign to save the old logo, which was green, in all uppercase, and featured a fanciful letter O, nicknamed the blibbet, but it was discarded.[302]\n\nMicrosoft's logo with the tagline \"Your potential. Our passion.\"—below the main corporate name—is based on a slogan Microsoft used in 2008. In 2002, the company started using the logo in the United States and eventually started a television campaign with the slogan, changed from the previous tagline of \"Where do you want to go today?\"[303][304][305] During the private MGX (Microsoft Global Exchange) conference in 2010, Microsoft unveiled the company's next tagline, \"Be What's Next.\"[306] They also had a slogan/tagline \"Making it all make sense.\"[307] The Microsoft Pac-Man logo was used for 25 years, 5 months, and 28 days until August 23, 2012, being the longest enduring logo to be used by the company.\n\nOn August 23, 2012, Microsoft unveiled a new corporate logo at the opening of its 23rd Microsoft store in Boston, indicating the company's shift of focus from the classic style to the tile-centric modern interface, which it uses/will use on the Windows Phone platform, Xbox 360, Windows 8 and the upcoming Office Suites.[308] The new logo also includes four squares with the colors of the then-current Windows logo which have been used to represent Microsoft's four major products: Windows (blue), Office (orange), Xbox (green) and Bing (yellow).[309] The logo also resembles the opening of one of the commercials for Windows 95.[310][311]\n\nThe company was the official jersey sponsor of Finland's national basketball team at EuroBasket 2015.[313]\n\nThe company was a major sponsor of the Toyota Gazoo Racing WRT (2017–2020).\n\nThe company was a sponsor of the Renault F1 Team (2016–2020).\n\nIn 2015, Microsoft Philanthropies, an internal charitable organization, was established. Its mission is to bring the benefits of technology to parts of the world and segments of the population that have been denied the benefits of the digital revolution. Key areas of focus: donating cloud computing resources to university researchers and nonprofit groups; supporting the expansion of broadband access worldwide; funding international computer science education through YouthSpark; supporting tech education in the U.S. from kindergarten to high school; and donating to global child and refugee relief organizations.[314][315]\n\nDuring the COVID-19 pandemic, Microsoft's president, Brad Smith, announced that an initial batch of supplies, including 15,000 protection goggles, infrared thermometers, medical caps, and protective suits, was donated to Seattle, with further aid to come soon.[316]\n\nDuring Russian invasion of Ukraine Microsoft started monitoring cyberattacks originating from the Government of Russia and Russia-backed hackers. In June 2022, Microsoft published the report on Russian cyber attacks and concluded that state-backed Russian hackers \"have engaged in \"strategic espionage\" against governments, think tanks, businesses and aid groups\" in 42 countries supporting Kyiv.[317][318]\n\nCriticism of Microsoft has followed various aspects of its products and business practices. Frequently criticized are the ease of use, robustness, and security of the company's software. They have also been criticized for the use of permatemp employees (employees employed for years as \"temporary\", and therefore without medical benefits), the use of forced retention tactics, which means that employees would be sued if they tried to leave.[319] Historically, Microsoft has also been accused of overworking employees, in many cases, leading to burnout within just a few years of joining the company. The company is often referred to as a \"Velvet Sweatshop\", a term which originated in a 1989 Seattle Times article,[320] and later became used to describe the company by some of Microsoft's own employees.[321] This characterization is derived from the perception that Microsoft provides nearly everything for its employees in a convenient place, but in turn overworks them to a point where it would be bad for their (possibly long-term) health.\n\nAs reported by several news outlets,[322][323] an Irish subsidiary of Microsoft based in the Republic of Ireland declared £220 bn in profits but paid no corporation tax for the year 2020. This is due to the company being tax resident in Bermuda as mentioned in the accounts for 'Microsoft Round Island One, a subsidiary that collects license fees from the use of Microsoft software worldwide. Dame Margaret Hodge, a Labour MP in the UK said, \"It is unsurprising – yet still shocking – that massively wealthy global corporations openly, unashamedly and blatantly refuse to pay tax on the profits they make in the countries where they undertake business\".[323]\n\nIn 2020, ProPublica reported that the company had diverted more than $39 billion in U.S. profits to Puerto Rico using a mechanism structured to make it seem as if the company was unprofitable on paper. As a result, the company paid a tax rate on those profits of \"nearly 0%\". When the Internal Revenue Service audited these transactions, ProPublica reported that Microsoft aggressively fought back, including successfully lobbying Congress to change the law to make it harder for the agency to conduct audits of large corporations.[324][325] In 2023, Microsoft reported in a securities filing that the U.S. Internal Revenue Service was alleging that the company owed the U.S. $28.9 billion in past taxes, plus penalties related to mis-allocation of corporate profits over a decade.[326]\n\n\"Embrace, extend, and extinguish\" (EEE),[327] also known as \"embrace, extend, and exterminate,\"[328] is a phrase that the U.S. Department of Justice found[329] that was used internally by Microsoft[330] to describe its strategy for entering product categories involving widely used standards, extending those standards with proprietary capabilities, and then using those differences to strongly disadvantage competitors. Microsoft is frequently accused of using anticompetitive tactics and abusing its monopolistic power. People who use their products and services often end up becoming dependent on them, a process is known as vendor lock-in.\n\nMicrosoft was the first company to participate in the PRISM surveillance program, according to leaked NSA documents obtained by The Guardian[331] and The Washington Post[332] in June 2013, and acknowledged by government officials following the leak.[333] The program authorizes the government to secretly access data of non-US citizens hosted by American companies without a warrant. Microsoft has denied participation in such a program.[334]\n\nJesse Jackson believes Microsoft should hire more minorities and women. In 2015, he praised Microsoft for appointing two women to its board of directors.[335]\n\nIn 2020, Salesforce, the manufacturer of the Slack platform, complained to European regulators about Microsoft due to the integration of the Teams service into Office 365. Negotiations with the European Commission continued until the summer of 2023, but, as it became known to the media, they reached an impasse. Microsoft is now facing an antitrust investigation.[336]\n\nIn June 2024, Microsoft Corp. faced a potential EU fine after regulators accused it of abusing market power by bundling its Teams video-conferencing app with its Office 365 and Microsoft 365 software. The European Commission issued a statement of objections, alleging Microsoft's practice since 2019 gave Teams an unfair market advantage and limited interoperability with competing software. Despite Microsoft's efforts to avoid deeper scrutiny, including unbundling Teams, regulators remained unconvinced. This action followed a 2019 complaint from Slack, which was later acquired by Salesforce. Microsoft's Teams usage soared during the pandemic, growing from 2 million daily users in 2017 to 300 million in 2023. The company has a history of antitrust battles in the U.S. and Europe, with over €2 billion in EU fines previously imposed for similar abuses.[337]\n\nIn October 2024, Microsoft fired two employees who organized an unauthorized vigil at its Redmond headquarters to honor Palestinians killed in Gaza during the conflict with Hamas. The employees, part of the group \"No Azure for Apartheid,\" sought to address the company's involvement in the Israeli government's use of its technology.[338]\n\nIn November 2024, the Federal Trade Commission (FTC) launched an investigation into Microsoft, focusing on potential antitrust violations related to its cloud computing, AI, and cybersecurity businesses. The probe scrutinized Microsoft's bundling of cloud services with products like Office and security tools, as well as its growing AI presence through its partnership with OpenAI. This inquiry is part of broader efforts by the U.S. government to curb the power of major tech companies, especially under FTC chair Lina Khan. Concerns were raised about Microsoft's licensing practices potentially locking customers into its services and its AI investments possibly sidestepping regulatory oversight.[339]\n\n.mw-parser-output .geo-default,.mw-parser-output .geo-dms,.mw-parser-output .geo-dec{display:inline}.mw-parser-output .geo-nondefault,.mw-parser-output .geo-multi-punct,.mw-parser-output .geo-inline-hidden{display:none}.mw-parser-output .longitude,.mw-parser-output .latitude{white-space:nowrap}47°38′33″N 122°07′56″W﻿ / ﻿47.64250°N 122.13222°W﻿ / 47.64250; -122.13222\n\n"}
